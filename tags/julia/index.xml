<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Julia on Jose Storopoli, PhD</title>
  <link rel="alternate" href="https://storopoli.io/tags/julia/" />
  <link rel="self" href="https://storopoli.io/tags/julia/index.xml" />
  <subtitle>Recent content in Julia on Jose Storopoli, PhD</subtitle>
  <id>https://storopoli.io/tags/julia/</id>
  <generator uri="http://gohugo.io" version="0.124.0">Hugo</generator>
  <language>en-us</language>
  <updated>2023-11-28T18:19:36-03:00</updated>
  <author>
    <name>Jose Storopoli</name>
    
  </author>
  <rights>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)</rights>
      <entry>
        <title>Zero-cost Abstractions</title>
        <link rel="alternate" href="https://storopoli.io/2023-11-28-zero_cost_abstractions/" />
        <id>https://storopoli.io/2023-11-28-zero_cost_abstractions/</id>
        <published>2023-11-28T18:19:36-03:00</published>
        <updated>2024-02-11T15:55:02-03:00</updated>
        <summary type="html">In programming language circles there&amp;rsquo;s a recently trend of discussing a concept called zero-cost abstractions: the ability to use higher-levels abstractions without suffering any loss of performance.
Zero-cost abstractions allows you to write performant code without having to give up a single drop of convenience and expressiveness:
You want for-loops? You can have it. Generics? Yeah, why not? Data structures? Sure, keep&amp;rsquo;em coming. Async operations? You bet ya! Multi-threading? Hell yes!</summary>
          <content type="html"><![CDATA[<p>In programming language circles there&rsquo;s a recently trend of discussing a concept
called <strong>zero-cost abstractions</strong>:
the ability to use higher-levels abstractions without suffering any loss of performance.</p>
<p>Zero-cost abstractions allows you to write performant code without having to
give up a single drop of convenience and expressiveness:</p>
<p>You want for-loops?
<em>You can have it</em>.
Generics?
<em>Yeah, why not</em>?
Data structures?
<em>Sure, keep&rsquo;em coming</em>.
Async operations?
<em>You bet ya</em>!
Multi-threading?
<em>Hell yes</em>!</p>
<p>To put more formally,
I like <a href="https://stackoverflow.com/a/69178445">this definition from StackOverflow</a>:</p>
<blockquote>
<p>Zero Cost Abstractions means adding higher-level programming concepts, like generics,
collections and so on do not come with a run-time cost,
only compile time cost (the code will be slower to compile).
Any operation on zero-cost abstractions is as fast as you would write out
matching functionality by hand using lower-level programming concepts like
for loops, counters, ifs and using raw pointers.</p>
</blockquote>
<p>Here&rsquo;s an analogy:</p>
<blockquote>
<p>Imagine that you are going to buy a car.
The sales person offers you a fancy car praising how easy it is to drive it,
that you don&rsquo;t need to think about RPM, clutch and stick shift,
parking maneuver, fuel type, and other shenanigans.
You just turn it on and drive.
However, once you take a look at the car&rsquo;s data sheet, you are horrified.
The car is bad in every aspect except easy of use.
It has dreadful fuel consumption,
atrocious safety ratings,
disastrous handling, and so on&hellip;</p>
</blockquote>
<p>Believe me, you wouldn&rsquo;t want to own that car.</p>
<p>Metaphors aside, that&rsquo;s <strong>exactly what professional developers<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> and whole teams
choose to use every day: unacceptable inferior tools</strong>.
Tools that, not only don&rsquo;t have <strong>zero-cost abstractions</strong>,
rather don&rsquo;t allow you to even have non-zero-cost anything!</p>
<p>Let&rsquo;s do some Python bashing in the meantime.
I know that&rsquo;s easy to bash Python,
but that&rsquo;s not the point.
If Python wasn&rsquo;t used so widely in production,
I would definitely leave it alone.
Don&rsquo;t get me wrong, Python is the second-best language for everything<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<h2 id="the-curious-case-of-the-python-boolean">The curious case of the Python boolean</h2>
<p><img loading="lazy" src="non-zero-cost-abstraction.png#center" alt="non-zero-cost-abstraction"  />
</p>
<p>I wish this meme was a joke, but it isn&rsquo;t.
A boolean is one of the simplest data type taking only two possible values:
true or false.
Just grab your nearest Python REPL:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sys</span> <span class="kn">import</span> <span class="n">getsizeof</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">getsizeof</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mi">28</span>
</span></span></code></pre></div><p>The function <a href="https://docs.python.org/3/library/sys.html#sys.getsizeof"><code>sys.getsizeof</code></a>
returns the size of an object in bytes.
<strong>How the hell Python needs 28 bytes to represent something that needs at most 1 byte</strong><sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>?
Imagine incurring a 28x penalty in memory size requirements for every boolean
that you use.
Now multiply this by every operation that your code is going to run in production
over time.
Again: <strong>unacceptable</strong>.</p>
<p>That&rsquo;s because all objects in Python,
in the sense that everything that you can instantiate,
i.e. everything that you can put on the left hand-side of the <code>=</code> assignment,
is a <a href="https://docs.python.org/3/c-api/structures.html#c.PyObject"><code>PyObject</code></a>:</p>
<blockquote>
<p>All Python objects ultimately share a small number of fields at the
beginning of the objectâ€™s representation in memory.
These are represented by the <code>PyObject</code> and <code>PyVarObject</code> types.</p>
</blockquote>
<p>Python is dynamically-typed, which means that you don&rsquo;t have primitives like
8-, 16-, 32-bit (un)signed integers and so on.
Everything is a huge mess allocated in the heap that must carry not only its value,
but also information about its type.</p>
<p>Most important, everything that is fast in Python is <em>not Python-based</em>.
Take a look at the image below,
I grabbed some popular Python libraries from GitHub,
namely <a href="https://github.com/numpy/numpy">NumPy</a> (linear algebra package)
and <a href="https://github.com/pytorch/pytorch">PyToch</a> (deep learning package),
and checked the
language codebase percentage.</p>
<p><img loading="lazy" src="python-my-ass.jpg#center" alt="python-my-ass"  />
</p>
<p>Surprise, they are <strong><em>not</em> Python libraries</strong>.
They are <strong>C/C++ codebases</strong>.
Even if Python is the main language used in these codebases<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>,
I still think that this is not the case due to the nature of the Python code:
<strong>all docstrings are written in Python</strong>.
If you have a very fast C function in your codebase that takes 50 lines of code,
followed by a Python wrapper function that calls it using 10 lines of code,
<em>but</em> with a docstring that is 50 lines of code;
you have a &ldquo;Python&rdquo;-majority codebase.</p>
<p>In a sense the most efficient Python programmer is a C/C++ programmer&hellip;</p>
<p>Here&rsquo;s <a href="https://julialang.org">Julia</a>, which is also dynamically-typed:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="n">Base</span><span class="o">.</span><span class="n">summarysize</span><span class="p">(</span><span class="nb">true</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mi">1</span>
</span></span></code></pre></div><p>And to your surprise,
Julia is coded in &hellip;. Julia!
Check the image below for the language codebase percentage of
<a href="https://github.com/JuliaLang/julia">Julia</a>
and <a href="https://github.com/LuxDL/Lux.jl"><code>Lux.jl</code></a><sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> (deep learning package).</p>
<p><img loading="lazy" src="julia.jpg#center" alt="julia"  />
</p>
<p>Finally, here&rsquo;s <a href="https://rust-lang.org">Rust</a>, which is not dynamically-,
but static-typed:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="c1">// main.rs
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">use</span><span class="w"> </span><span class="n">std</span>::<span class="n">mem</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">fn</span> <span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="fm">println!</span><span class="p">(</span><span class="s">&#34;Size of bool: </span><span class="si">{}</span><span class="s"> byte&#34;</span><span class="p">,</span><span class="w"> </span><span class="n">mem</span>::<span class="n">size_of</span>::<span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">$ cargo run --release
</span></span><span class="line"><span class="cl">   Compiling size_of_bool v0.1.0
</span></span><span class="line"><span class="cl">    Finished release <span class="o">[</span>optimized<span class="o">]</span> target<span class="o">(</span>s<span class="o">)</span> in 0.00s
</span></span><span class="line"><span class="cl">     Running <span class="sb">`</span>target/release/size_of_bool<span class="sb">`</span>
</span></span><span class="line"><span class="cl">Size of bool: <span class="m">1</span> byte
</span></span></code></pre></div><h2 id="more-zero-costs-abstractions">More zero-costs abstractions</h2>
<p>Let&rsquo;s cover two more zero-costs abstractions, both in Julia and in Rust:
<strong>for-loops</strong> and <strong>enums</strong>.</p>
<h3 id="for-loops">For-loops</h3>
<p>A friend and a Julia-advocate once told me that Julia&rsquo;s master plan is to secretly
&ldquo;make everyone aware about <em>compilers</em>&rdquo;.
The <a href="https://en.wikipedia.org/wiki/Compiler">compiler</a>
is a program that translate source code from a high-level programming language
to a low-level programming language
(e.g. assembly language, object code, or machine code) to create an
executable program.</p>
<p>Python uses <a href="https://github.com/python/cpython">CPython</a> as the compiler.
If you search around on why CPython/Python is so slow and inefficient,
you&rsquo;ll find that the culprits are:</p>
<ol>
<li>Python is <strong>dynamic-typed language</strong>.</li>
<li>Python&rsquo;s <strong>Global Interpreter Lock (GIL) restricts multi-threading capabilities</strong>.</li>
<li>Python is <strong>interpreted</strong>, which means that Python code is executed sequentially:
line-by-line.</li>
<li>Python is <strong>garbage-collected</strong>: all memory its tracked,
and allocated or deallocated which introduces overhead.</li>
</ol>
<p>I completely disagree with almost all the above reasons, except the GIL.
<strong>Python is slow because of its design decisions</strong>,
more specifically the way CPython works under the hood.
It is not built for performance in mind.
Actually, the main objective of Python was to be a
&ldquo;language that would be easy to read, write, and maintain&rdquo;.
I salute that: Python has remained true to its main objective.</p>
<p>Now let&rsquo;s switch to Julia:</p>
<ol>
<li>Julia is <strong>dynamic-typed language</strong>.</li>
<li>Julia is <strong>interpreted</strong>, which means that Julia code is executed sequentially:
line-by-line.</li>
<li>Julia is <strong>garbage-collected</strong>: all memory its tracked,
and allocated or deallocated which introduces overhead.</li>
</ol>
<p>I&rsquo;ve copy-pasted all Python&rsquo;s arguments for inefficiency, except the GIL.
And, contrary to Python, <a href="https://julialang.org/benchmarks/">Julia is fast</a>!
Sometimes even faster than C<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.
Actually, that was the goal all along since Julia&rsquo;s inception.
If you check the <a href="https://julialang.org/blog/2012/02/why-we-created-julia/">notorious Julia announcement blog post from 2012</a>:</p>
<blockquote>
<p>We want a language that&rsquo;s open source, with a liberal license.
We want the speed of C with the dynamism of Ruby.
We want a language that&rsquo;s homoiconic, with true macros like Lisp,
but with obvious, familiar mathematical notation like Matlab.
We want something as usable for general programming as Python,
as easy for statistics as R, as natural for string processing as Perl,
as powerful for linear algebra as Matlab, as good at gluing programs together as the shell.
Something that is dirt simple to learn,
yet keeps the most serious hackers happy.
We want it interactive and we want it compiled.</p>
<p>(Did we mention it should be as fast as C?)</p>
</blockquote>
<p>It mentions &ldquo;speed&rdquo; twice.
Not only that, but also specifically says that it should match C&rsquo;s speed.</p>
<p>Julia is fast because of its design decisions.
One of the major reasons why Julia is fast is because of the choice of compiler
that it uses: <a href="https://llvm.org/">LLVM</a>.</p>
<p>LLVM originally stood for <strong>l</strong>ow <strong>l</strong>evel <strong>v</strong>irtual <strong>m</strong>achine.
Despite its name, LLVM has little to do with traditional virtual machines.
LLVM can take <a href="https://en.wikipedia.org/wiki/Intermediate_representation">intermediate representation (IR)</a>
code and compile it into machine-dependent instructions.
It has <a href="https://foundation.llvm.org/docs/sponsors/">support and sponsorship</a>
from a lot of big-tech corporations,
such as Apple, Google, IBM, Meta, Arm, Intel, AMD, Nvidia, and so on.
It is a pretty fast compiler that can do wonders in optimizing IR code to a
plethora of computer architectures.</p>
<p>In a sense, Julia is a front-end for LLVM.
It turns your easy-to-read and easy-to-write Julia code into LLVM IR code.
Take this for-loop example inside a function:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">function</span> <span class="n">sum_10</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">acc</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="mi">10</span>
</span></span><span class="line"><span class="cl">        <span class="n">acc</span> <span class="o">+=</span> <span class="n">i</span>
</span></span><span class="line"><span class="cl">    <span class="k">end</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">acc</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><p>Let&rsquo;s check what Julia generates as LLVM IR code for this function.
We can do that with the <code>@code_llvm</code> macro.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="nd">@code_llvm</span> <span class="n">debuginfo</span><span class="o">=</span><span class="ss">:none</span> <span class="n">sum_10</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">define</span> <span class="n">i64</span> <span class="nd">@julia_sum_10_172</span><span class="p">()</span> <span class="c">#0 {</span>
</span></span><span class="line"><span class="cl"><span class="n">top</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">  <span class="n">ret</span> <span class="n">i64</span> <span class="mi">55</span>
</span></span><span class="line"><span class="cl"><span class="err">}</span>
</span></span></code></pre></div><p>You can&rsquo;t easily fool the compiler.
Julia understands that the answer is 55,
and the LLVM IR generated code is pretty much just &ldquo;return 55 as a 64-bit integer&rdquo;.</p>
<p>Let&rsquo;s also check the machine-dependent instructions with the <code>@code_native</code> macro.
I am using an Apple Silicon machine, so these instructions might differ from yours:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="nd">@code_native</span> <span class="n">debuginfo</span><span class="o">=</span><span class="ss">:none</span> <span class="n">sum_10</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="o">.</span><span class="n">section</span>        <span class="n">__TEXT</span><span class="p">,</span><span class="n">__text</span><span class="p">,</span><span class="n">regular</span><span class="p">,</span><span class="n">pure_instructions</span>
</span></span><span class="line"><span class="cl">        <span class="o">.</span><span class="n">build_version</span> <span class="n">macos</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="o">.</span><span class="n">globl</span>  <span class="n">_julia_sum_10_214</span>               <span class="p">;</span> <span class="o">--</span> <span class="n">Begin</span> <span class="k">function</span> <span class="n">julia_sum_10_214</span>
</span></span><span class="line"><span class="cl">        <span class="o">.</span><span class="n">p2align</span>        <span class="mi">2</span>
</span></span><span class="line"><span class="cl"><span class="n">_julia_sum_10_214</span><span class="o">:</span>                      <span class="p">;</span> <span class="nd">@julia_sum_10_214</span>
</span></span><span class="line"><span class="cl">        <span class="o">.</span><span class="n">cfi_startproc</span>
</span></span><span class="line"><span class="cl"><span class="p">;</span> <span class="o">%</span><span class="n">bb</span><span class="mf">.0</span><span class="o">:</span>                                <span class="p">;</span> <span class="o">%</span><span class="n">top</span>
</span></span><span class="line"><span class="cl">        <span class="n">mov</span>     <span class="n">w0</span><span class="p">,</span> <span class="c">#55</span>
</span></span><span class="line"><span class="cl">        <span class="n">ret</span>
</span></span><span class="line"><span class="cl">        <span class="o">.</span><span class="n">cfi_endproc</span>
</span></span><span class="line"><span class="cl">                                        <span class="p">;</span> <span class="o">--</span> <span class="n">End</span> <span class="k">function</span>
</span></span><span class="line"><span class="cl"><span class="o">.</span><span class="n">subsections_via_symbols</span>
</span></span></code></pre></div><p>The only important instruction for our argument here is the <code>mov w0, #55</code>.
This means &ldquo;move the value 55 into the <code>w0</code> register&rdquo;,
where <code>w0</code> is one of registers available in ARM-based architectures
(which Apple Silicon chips are).</p>
<p>This is a <strong>zero-cost abstraction</strong>!
I don&rsquo;t need to give up for-loops, because they might be slow and inefficient;
like some Python users suggest newcomers.
I can have the full convenience and expressiveness of for-loops without
paying performance costs.
Pretty much the definition of a zero-cost abstraction from above.</p>
<p>Using LLVM as a compiler backend is not something unique to Julia.
Rust also uses LLVM under the hood.
Take for example this simple Rust code:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="c1">// main.rs
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">pub</span><span class="w"> </span><span class="k">fn</span> <span class="nf">sum_10</span><span class="p">()</span><span class="w"> </span>-&gt; <span class="kt">i32</span> <span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="k">mut</span><span class="w"> </span><span class="n">acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="mi">1</span><span class="o">..=</span><span class="mi">10</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">acc</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">i</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">acc</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">fn</span> <span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="fm">println!</span><span class="p">(</span><span class="s">&#34;sum_10: </span><span class="si">{}</span><span class="s">&#34;</span><span class="p">,</span><span class="w"> </span><span class="n">sum_10</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></div><p>We can inspect both LLVM IR code and machine instructions with the
<a href="https://github.com/pacak/cargo-show-asm"><code>cargo-show-asm</code></a> crate:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">$ cargo asm --llvm <span class="s2">&#34;sum_10::main&#34;</span> <span class="p">|</span> grep <span class="m">55</span>
</span></span><span class="line"><span class="cl">    Finished release <span class="o">[</span>optimized<span class="o">]</span> target<span class="o">(</span>s<span class="o">)</span> in 0.00s
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  store i32 55, ptr %_9, align <span class="m">4</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">$ cargo asm <span class="s2">&#34;sum_10::main&#34;</span> <span class="p">|</span> grep <span class="m">55</span>
</span></span><span class="line"><span class="cl">    Finished release <span class="o">[</span>optimized<span class="o">]</span> target<span class="o">(</span>s<span class="o">)</span> in 0.00s
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        mov w8, <span class="c1">#55</span>
</span></span></code></pre></div><p>No coincidence that the LLVM IR code is very similar,
with the difference that integers, by default,
in Julia are 64 bits and in Rust 32 bits.
However, the machine code is <strong>identical</strong>:
&ldquo;move the value 55 into a <code>w</code> something register&rdquo;.</p>
<h3 id="enums">Enums</h3>
<p>Another zero-cost abstraction, in Julia and Rust, is <strong>enums</strong>.</p>
<p>In Julia all enums, by default have a <code>BaseType</code> of <code>Int32</code>:
a signed 32-bit integer.
However, we can override this with type annotations:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="nd">@enum</span> <span class="n">Thing</span><span class="o">::</span><span class="kt">Bool</span> <span class="n">One</span> <span class="n">Two</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="n">Base</span><span class="o">.</span><span class="n">summarysize</span><span class="p">(</span><span class="n">Thing</span><span class="p">(</span><span class="nb">false</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="mi">1</span>
</span></span></code></pre></div><p>Here we have an enum <code>Thing</code> with two variants: <code>One</code> and <code>Two</code>.
Since we can safely represent all the possible variant space of <code>Thing</code>
with a boolean type, we override the <code>BaseType</code> of <code>Thing</code> to be the <code>Bool</code> type.
Unsurprised, any object of <code>Thing</code> occupies 1 byte in memory.</p>
<p>We can achieve the same with Rust:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="c1">// main.rs
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">use</span><span class="w"> </span><span class="n">std</span>::<span class="n">mem</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="cp">#[allow(dead_code)]</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">enum</span> <span class="nc">Thing</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">One</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">Two</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">fn</span> <span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="fm">println!</span><span class="p">(</span><span class="s">&#34;Size of Thing: </span><span class="si">{}</span><span class="s"> byte&#34;</span><span class="p">,</span><span class="w"> </span><span class="n">mem</span>::<span class="n">size_of</span>::<span class="o">&lt;</span><span class="n">Thing</span><span class="o">&gt;</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">$ cargo run --release
</span></span><span class="line"><span class="cl">   Compiling enum_size v0.1.0
</span></span><span class="line"><span class="cl">    Finished release <span class="o">[</span>optimized<span class="o">]</span> target<span class="o">(</span>s<span class="o">)</span> in 0.09s
</span></span><span class="line"><span class="cl">     Running <span class="sb">`</span>target/release/enum_size<span class="sb">`</span>
</span></span><span class="line"><span class="cl">Size of Thing: <span class="m">1</span> byte
</span></span></code></pre></div><p>However, contrary to Julia, Rust compiler automatically detects the enum&rsquo;s
variant space size and adjust accordingly.
So, no need of overrides.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Zero-cost abstractions are a joy to have in a programming language.
It enables you, as a programmer, to just focus on what&rsquo;s important:
write expressive code that is easy to read, maintain, debug, and build upon.</p>
<p>It is no wonder that zero-cost abstractions is a pervasive feature
of two of my top-favorite languages:
<a href="https://julialang.org">Julia</a>
and <a href="https://rust-lang.org">Rust</a>.</p>
<h2 id="license">License</h2>
<p>This post is licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International</a>.</p>
<p><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img loading="lazy" src="https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png" alt="CC BY-NC-SA 4.0"  />
</a></p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>this post is somehow connected to my <a href="../2023-11-10-2023-11-13-soydev/">soydev rant</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>and that&rsquo;s not a compliment.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>technically, we can represent a boolean with just one bit.
However, the short answer is still one byte,
because that&rsquo;s <a href="https://en.wikipedia.org/wiki/Byte">smallest addressable unit of memory</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>and modifying <code>.gitattributes</code> is cheating.
Yes, I am talking to you <a href="https://github.com/numpy/numpy/blob/06d7bdfbb585264dcf23d4322be7aee449733ca2/.gitattributes#L6-L7">NumPy</a>!&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p><a href="https://github.com/LuxDL/Lux.jl"><code>Lux.jl</code></a> doesn&rsquo;t even have a <code>.gitattributes</code> file.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>if you compare runtime execution.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content>
      </entry>
      <entry>
        <title>Lindley&#39;s Paradox, or The consistency of Bayesian Thinking</title>
        <link rel="alternate" href="https://storopoli.io/2023-11-23-lindley_paradox/" />
        <id>https://storopoli.io/2023-11-23-lindley_paradox/</id>
        <published>2023-11-22T07:06:59-03:00</published>
        <updated>2024-02-11T15:55:02-03:00</updated>
        <summary type="html">Warning: This post has KaTeX enabled, so if you want to view the rendered math formulas, you&amp;rsquo;ll have to unfortunately enable JavaScript.
Dennis Lindley, one of my many heroes, was an English statistician, decision theorist and leading advocate of Bayesian statistics. He published a pivotal book, Understanding Uncertainty, that changed my view on what is and how to handle uncertainty in a coherent1 way. He is responsible for one of my favorites quotes: &amp;ldquo;Inside every non-Bayesian there is a Bayesian struggling to get out&amp;rdquo;; and one of my favorite heuristics around prior probabilities: Cromwell&amp;rsquo;s Rule2.</summary>
          <content type="html"><![CDATA[<p><img loading="lazy" src="lindley.jpg#center" alt="Dennis Lindley"  />
</p>
<blockquote>
<p>Warning: This post has <a href="https://katex.org/">KaTeX</a> enabled,
so if you want to view the rendered math formulas,
you&rsquo;ll have to unfortunately enable JavaScript.</p>
</blockquote>
<p><a href="https://en.wikipedia.org/wiki/Dennis_Lindley">Dennis Lindley</a>,
one of my many heroes,
was an English statistician,
decision theorist and leading advocate of Bayesian statistics.
He published a pivotal book,
<a href="https://onlinelibrary.wiley.com/doi/book/10.1002/9781118650158">Understanding Uncertainty</a>,
that changed my view on what is and how to handle uncertainty in a
coherent<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> way.
He is responsible for one of my favorites quotes:
&ldquo;Inside every non-Bayesian there is a Bayesian struggling to get out&rdquo;;
and one of my favorite heuristics around prior probabilities:
<a href="https://en.wikipedia.org/wiki/Cromwell%27s_rule">Cromwell&rsquo;s Rule</a><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.
Lindley predicted in 1975 that &ldquo;Bayesian methods will indeed become pervasive,
enabled by the development of powerful computing facilities&rdquo; (Lindley, 1975).
You can find more about all of Lindley&rsquo;s achievements in his <a href="https://www.theguardian.com/science/2014/mar/16/dennis-lindley">obituary</a>.</p>
<h2 id="lindleys-paradox">Lindley&rsquo;s Paradox</h2>
<p>Lindley&rsquo;s paradox<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> is a counterintuitive situation in statistics
in which the Bayesian and frequentist approaches to a hypothesis testing problem
give different results for certain choices of the prior distribution.</p>
<p>More formally, the paradox is as follows.
We have some parameter $\theta$ that we are interested in.
Then, we proceed with an experiment to test two competing hypotheses:</p>
<ol>
<li>$H_0$ (also known as <em>null hypothesis</em>):
there is no &ldquo;effect&rdquo;, or, more specifically,
$\theta = 0$.</li>
<li>$H_a$ (also known as <em>alternative hypothesis</em>):
there is an &ldquo;effect&rdquo;, or, more specifically,
$\theta \ne 0$.</li>
</ol>
<p>The paradox occurs when two conditions are met:</p>
<ol>
<li>The result of the experiment is <em>significant</em> by a frequentist test of $H_0$,
which indicates sufficient evidence to reject $H_0$, at a certain threshold of
probability<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>.</li>
<li>The posterior probability (Bayesian approach) of $H_0 \mid \theta$
(null hypothesis given $\theta$) is high,
which indicates strong evidence that $H_0$ should be favored over $H_a$,
that is, to <em>not</em> reject $H_0$.</li>
</ol>
<p>These results can occur at the same time when $H_0$ is very specific,
$H_a$ more diffuse,
and the prior distribution does not strongly favor one or the other.
These conditions are pervasive across science
and common in traditional null-hypothesis significance testing approaches.</p>
<p>This is a duel of frequentist versus Bayesian approaches,
and one of the many in which Bayesian emerges as the most coherent.
Let&rsquo;s give a example and go over the analytical result with a ton of math,
but also a computational result with <a href="https://julialang.org">Julia</a>.</p>
<h2 id="example">Example</h2>
<p>Here&rsquo;s the setup for the example.
In a certain city 49,581 boys and 48,870 girls have been
born over a certain time period.
The observed proportion of male births is thus
$\frac{49,581}{98,451} \approx 0.5036$.</p>
<p>We assume that the birth of a child is independent with a certain probability
$\theta$.
Since our data is a sequence of $n$ independent <a href="https://en.wikipedia.org/wiki/Bernoulli_trial">Bernoulli trials</a>,
i.e., $n$ independent random experiments with exactly two possible outcomes:
&ldquo;success&rdquo; and &ldquo;failure&rdquo;,
in which the probability of success is the same every time the
experiment is conducted.
We can safely assume that it follows a <a href="https://en.wikipedia.org/wiki/Binomial_distribution">binomial distribution</a>
with parameters:</p>
<ul>
<li>$n$: the number of &ldquo;trials&rdquo; (or the total number of births).</li>
<li>$\theta$: the probability of male births.</li>
</ul>
<p>We then set up our two competing hypotheses:</p>
<ol>
<li>$H_0$: $\theta = 0.5$.</li>
<li>$H_a$: $\theta \ne 0.5$.</li>
</ol>
<h3 id="analytical-solution">Analytical Solution</h3>
<p>This is a toy-problem and, like most toy problems,
we can solve it analytically<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> for both the frequentist and the Bayesian approaches.</p>
<h4 id="analytical-solutions----frequentist-approach">Analytical Solutions &ndash; Frequentist Approach</h4>
<p>The frequentist approach to testing $H_0$ is to compute a $p$-value<sup id="fnref1:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>,
the probability of observing births of boys at least as large as 49,581
assuming $H_0$ is true.
Because the number of births is very large,
we can use a normal approximation<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> for the
binomial-distributed number of male births.
Let&rsquo;s define $X$ as the total number of male births,
then $X$ follows a normal distribution:</p>
<p>$$X \sim \text{Normal}(\mu, \sigma)$$</p>
<p>where $\mu$ is the mean parameter,
$n \theta$ in our case,
and $\sigma$ is the standard deviation parameter,
$\sqrt{n \theta (1 - \theta)}$.
We need to calculate the conditional probability of
$X \geq \frac{49,581}{98,451} \approx 0.5036$
given $\mu = n \theta = 98,451 \cdot \frac{1}{2} = 49,225.5$
and
$\sigma = \sqrt{n \theta (1 - \theta)} = \sqrt{98,451 \cdot \frac{1}{2} \cdot (1 - \frac{1}{2})}$:</p>
<p>$$P(X \ge 0.5036 \mid \mu = 49,225.5, \sigma = \sqrt{24.612.75})$$</p>
<p>This is basically a
<a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">cumulative distribution function (CDF)</a>
of $X$ on the interval $[49,225.5, 98,451]$:</p>
<p>$$\int_{49,225.5}^{98,451} \frac{1}{\sqrt{2 \pi \sigma^2}} e^{- \frac{\left( \frac{x - \mu}{\sigma} \right)^2}{2}} dx$$</p>
<p>After inserting the values and doing some arithmetic,
our answer is approximately $0.0117$.
Note that this is a one-sided test,
since it is symmetrical,
the two-sided test would be
$0.0117 \cdot 2 = 0.0235$.
Since we don&rsquo;t deviate from the Fisher&rsquo;s canon,
this is well below the 5% threshold.
Hooray! We rejected the null hypothesis!
Quick! Grab a frequentist celebratory cigar!
But, wait. Let&rsquo;s check the Bayesian approach.</p>
<h4 id="analytical-solutions----bayesian-approach">Analytical Solutions &ndash; Bayesian Approach</h4>
<p>For the Bayesian approach, we need to set prior probabilities on both hypotheses.
Since we do not favor one from another, let&rsquo;s set equal prior probabilities:</p>
<p>$$P(H_0) = P(H_a) = \frac{1}{2}$$</p>
<p>Additionally, all parameters of interest need a prior distribution.
So, let&rsquo;s put a prior distribution on $\theta$.
We could be fancy here, but let&rsquo;s not.
We&rsquo;ll use a uniform distribution on $[0, 1]$.</p>
<p>We have everything we need to compute the posterior probability of $H_0$ given
$\theta$.
For this, we&rsquo;ll use <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes theorem</a><sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>:</p>
<p>$$P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)}$$</p>
<p>Now again let&rsquo;s plug in all the values:</p>
<p>$$P(H_0 \mid \theta) = \frac{P(\theta \mid H_0) P(H_0)}{P(\theta)}$$</p>
<p>Note that by the <a href="https://en.wikipedia.org/wiki/Probability_axioms">axioms of probability</a>
and by the <a href="https://en.wikipedia.org/wiki/Chain_rule_(probability)">product rule of probability</a>
we can decompose $P(\theta)$ into:</p>
<p>$$P(\theta) = P(\theta \mid H_0) P(H_0) + P(\theta \mid H_a) P(H_a)$$</p>
<p>Again, we&rsquo;ll use the normal approximation:</p>
<p>$$
\begin{aligned}
&amp;P \left( \theta = 0.5 \mid \mu = 49,225.5, \sigma = \sqrt{24.612.75} \right) \\
&amp;= \frac{
\frac{1}{\sqrt{2 \pi \sigma^2}} e^{- \left( \frac{(\mu - \mu \cdot 0.5)}{2 \sigma} \right)^2} \cdot 0.5
}
{
\frac{1}{\sqrt{2 \pi \sigma^2}} e^{ \left( -\frac{(\mu - \mu \cdot 0.5)}{2 \sigma} \right)^2} \cdot 0.5 +
\int_0^1 \frac {1}{\sqrt{2 \pi \sigma^2} } e^{- \left( \frac{\mu - \mu \cdot \theta)}{2 \sigma} \right)^2}d \theta \cdot 0.5
} \\
&amp;= 0.9505
\end{aligned}
$$</p>
<p>The likelihood of the alternative hypothesis,
$P(\theta \mid H_a)$,
is just the CDF of all possible values of $\theta \ne 0.5$.</p>
<p>$$P(H_0 \mid \text{data}) = P \left( \theta = 0.5 \mid \mu = 49,225.5, \sigma = \sqrt{24.612.75} \right) &gt; 0.95$$</p>
<p>And we fail to reject the null hypothesis, in frequentist terms.
However, we can also say in Bayesian terms, that we strongly favor $H_0$
over $H_a$.</p>
<p>Quick! Grab the Bayesian celebratory cigar!
The null is back on the game!</p>
<h3 id="computational-solutional">Computational Solutional</h3>
<p>For the computational solution, we&rsquo;ll use <a href="https://julialang.org">Julia</a>
and the following packages:</p>
<ul>
<li><a href="https://github.com/JuliaStats/HypothesisTests.jl"><code>HypothesisTest.jl</code></a></li>
<li><a href="https://turinglang.org/"><code>Turing.jl</code></a></li>
</ul>
<h4 id="computational-solutions----frequentist-approach">Computational Solutions &ndash; Frequentist Approach</h4>
<p>We can perform a <a href="https://juliastats.org/HypothesisTests.jl/stable/nonparametric/#Binomial-test"><code>BinomialTest</code></a>
with <code>HypothesisTest.jl</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="k">using</span> <span class="n">HypothesisTests</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="n">BinomialTest</span><span class="p">(</span><span class="mi">49_225</span><span class="p">,</span> <span class="mi">98_451</span><span class="p">,</span> <span class="mf">0.5036</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">Binomial</span> <span class="n">test</span>
</span></span><span class="line"><span class="cl"><span class="o">-------------</span>
</span></span><span class="line"><span class="cl"><span class="n">Population</span> <span class="n">details</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">parameter</span> <span class="n">of</span> <span class="n">interest</span><span class="o">:</span>   <span class="n">Probability</span> <span class="n">of</span> <span class="n">success</span>
</span></span><span class="line"><span class="cl">    <span class="n">value</span> <span class="n">under</span> <span class="n">h_0</span><span class="o">:</span>         <span class="mf">0.5036</span>
</span></span><span class="line"><span class="cl">    <span class="n">point</span> <span class="n">estimate</span><span class="o">:</span>          <span class="mf">0.499995</span>
</span></span><span class="line"><span class="cl">    <span class="mi">95</span><span class="o">%</span> <span class="n">confidence</span> <span class="n">interval</span><span class="o">:</span> <span class="p">(</span><span class="mf">0.4969</span><span class="p">,</span> <span class="mf">0.5031</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">Test</span> <span class="n">summary</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">outcome</span> <span class="n">with</span> <span class="mi">95</span><span class="o">%</span> <span class="n">confidence</span><span class="o">:</span> <span class="n">reject</span> <span class="n">h_0</span>
</span></span><span class="line"><span class="cl">    <span class="n">two</span><span class="o">-</span><span class="n">sided</span> <span class="n">p</span><span class="o">-</span><span class="n">value</span><span class="o">:</span>           <span class="mf">0.0239</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">Details</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">number</span> <span class="n">of</span> <span class="n">observations</span><span class="o">:</span> <span class="mi">98451</span>
</span></span><span class="line"><span class="cl">    <span class="n">number</span> <span class="n">of</span> <span class="n">successes</span><span class="o">:</span>    <span class="mi">49225</span>
</span></span></code></pre></div><p>This is the two-sided test,
and I had to round $49,225.5$ to $49,225$
since <code>BinomialTest</code> do not support real numbers.
But the results match with the analytical solution,
we still reject the null.</p>
<h4 id="computational-solutions----bayesian-approach">Computational Solutions &ndash; Bayesian Approach</h4>
<p>Now, for the Bayesian computational approach,
I&rsquo;m going to use a generative modeling approach,
and one of my favorites probabilistic programming languages,
<code>Turing.jl</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="k">using</span> <span class="n">Turing</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="nd">@model</span> <span class="k">function</span> <span class="n">birth_rate</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">           <span class="n">Î¸</span> <span class="o">~</span> <span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">           <span class="n">total_births</span> <span class="o">=</span> <span class="mi">98_451</span>
</span></span><span class="line"><span class="cl">           <span class="n">male_births</span> <span class="o">~</span> <span class="n">Binomial</span><span class="p">(</span><span class="n">total_births</span><span class="p">,</span> <span class="n">Î¸</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">       <span class="k">end</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">birth_rate</span><span class="p">()</span> <span class="o">|</span> <span class="p">(;</span> <span class="n">male_births</span> <span class="o">=</span> <span class="mi">49_225</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">NUTS</span><span class="p">(</span><span class="mi">1_000</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span> <span class="n">MCMCThreads</span><span class="p">(),</span> <span class="mi">1_000</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">Chains</span> <span class="n">MCMC</span> <span class="n">chain</span> <span class="p">(</span><span class="mi">1000</span><span class="o">Ã—</span><span class="mi">13</span><span class="o">Ã—</span><span class="mi">4</span> <span class="kt">Array</span><span class="p">{</span><span class="kt">Float64</span><span class="p">,</span> <span class="mi">3</span><span class="p">})</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">Iterations</span>        <span class="o">=</span> <span class="mi">1001</span><span class="o">:</span><span class="mi">1</span><span class="o">:</span><span class="mi">2000</span>
</span></span><span class="line"><span class="cl"><span class="kt">Number</span> <span class="n">of</span> <span class="n">chains</span>  <span class="o">=</span> <span class="mi">4</span>
</span></span><span class="line"><span class="cl"><span class="n">Samples</span> <span class="n">per</span> <span class="n">chain</span> <span class="o">=</span> <span class="mi">1000</span>
</span></span><span class="line"><span class="cl"><span class="n">Wall</span> <span class="n">duration</span>     <span class="o">=</span> <span class="mf">0.2</span> <span class="n">seconds</span>
</span></span><span class="line"><span class="cl"><span class="n">Compute</span> <span class="n">duration</span>  <span class="o">=</span> <span class="mf">0.19</span> <span class="n">seconds</span>
</span></span><span class="line"><span class="cl"><span class="n">parameters</span>        <span class="o">=</span> <span class="n">Î¸</span>
</span></span><span class="line"><span class="cl"><span class="n">internals</span>         <span class="o">=</span> <span class="n">lp</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">is_accept</span><span class="p">,</span> <span class="n">acceptance_rate</span><span class="p">,</span> <span class="n">log_density</span><span class="p">,</span> <span class="n">hamiltonian_energy</span><span class="p">,</span> <span class="n">hamiltonian_energy_error</span><span class="p">,</span> <span class="n">max_hamiltonian_energy_error</span><span class="p">,</span> <span class="n">tree_depth</span><span class="p">,</span> <span class="n">numerical_error</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">nom_step_size</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">Summary</span> <span class="n">Statistics</span>
</span></span><span class="line"><span class="cl">  <span class="n">parameters</span>      <span class="n">mean</span>       <span class="n">std</span>      <span class="n">mcse</span>    <span class="n">ess_bulk</span>    <span class="n">ess_tail</span>      <span class="n">rhat</span>   <span class="n">ess_per_sec</span>
</span></span><span class="line"><span class="cl">      <span class="kt">Symbol</span>   <span class="kt">Float64</span>   <span class="kt">Float64</span>   <span class="kt">Float64</span>     <span class="kt">Float64</span>     <span class="kt">Float64</span>   <span class="kt">Float64</span>       <span class="kt">Float64</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">           <span class="n">Î¸</span>    <span class="mf">0.4999</span>    <span class="mf">0.0016</span>    <span class="mf">0.0000</span>   <span class="mf">1422.2028</span>   <span class="mf">2198.1987</span>    <span class="mf">1.0057</span>     <span class="mf">7368.9267</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">Quantiles</span>
</span></span><span class="line"><span class="cl">  <span class="n">parameters</span>      <span class="mf">2.5</span><span class="o">%</span>     <span class="mf">25.0</span><span class="o">%</span>     <span class="mf">50.0</span><span class="o">%</span>     <span class="mf">75.0</span><span class="o">%</span>     <span class="mf">97.5</span><span class="o">%</span>
</span></span><span class="line"><span class="cl">      <span class="kt">Symbol</span>   <span class="kt">Float64</span>   <span class="kt">Float64</span>   <span class="kt">Float64</span>   <span class="kt">Float64</span>   <span class="kt">Float64</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">           <span class="n">Î¸</span>    <span class="mf">0.4969</span>    <span class="mf">0.4988</span>    <span class="mf">0.4999</span>    <span class="mf">0.5011</span>    <span class="mf">0.5031</span>
</span></span></code></pre></div><p>We can see from the output of the quantiles that the 95% quantile for $\theta$ is
the interval $(0.4969, 0.5031)$.
Although it overlaps zero, that is not the equivalent of a hypothesis test.
For that, we&rsquo;ll use the
<a href="https://en.wikipedia.org/wiki/highest_posterior_density_interval">highest posterior density interval (HPDI)</a>,
which is defined as &ldquo;choosing the narrowest interval&rdquo; that
captures a certain posterior density threshold value.
In this case, we&rsquo;ll use a threshold interval of 95%,
i.e. an $\alpha = 0.05$:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="n">hpd</span><span class="p">(</span><span class="n">chain</span><span class="p">;</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">HPD</span>
</span></span><span class="line"><span class="cl">  <span class="n">parameters</span>     <span class="n">lower</span>     <span class="n">upper</span>
</span></span><span class="line"><span class="cl">      <span class="kt">Symbol</span>   <span class="kt">Float64</span>   <span class="kt">Float64</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">           <span class="n">Î¸</span>    <span class="mf">0.4970</span>    <span class="mf">0.5031</span>
</span></span></code></pre></div><p>We see that we fail to reject the null,
$\theta = 0.5$ at $\alpha = 0.05$ which is in accordance with the analytical
solution.</p>
<h2 id="why-the-frequentist-and-bayesian-approaches-disagree">Why the Frequentist and Bayesian Approaches Disagree</h2>
<p>Why do the approaches disagree?
What is going on under the hood?</p>
<p>The answer is disappointing<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>.
The main problem is that the frequentist approach only allows fixed significance
levels with respect to sample size.
Whereas the Bayesian approach is consistent and robust to sample size variations.</p>
<p>Taken to extreme, in some cases, due to huge sample sizes,
the $p$-value is pretty much a <em>proxy</em> for sample size
and have little to no utility on hypothesis testing.
This is known as $p$-hacking<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>.</p>
<h2 id="license">License</h2>
<p>This post is licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International</a>.</p>
<p><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img loading="lazy" src="https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png" alt="CC BY-NC-SA 4.0"  />
</a></p>
<h2 id="references">References</h2>
<p>Lindley, Dennis V. &ldquo;The future of statistics: A Bayesian 21st century&rdquo;.
<em>Advances in Applied Probability</em> 7 (1975): 106-115.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>as far as I know there&rsquo;s only one coherent approach to uncertainty,
and it is the Bayesian approach.
Otherwise, as de Finetti and Ramsey proposed,
you are susceptible to a <a href="https://en.wikipedia.org/wiki/Dutch_book">Dutch book</a>.
This is a topic for another blog post&hellip;&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Cromwell&rsquo;s rule states that the use of prior probabilities of 1
(&ldquo;the event will definitely occur&rdquo;) or 0 (&ldquo;the event will definitely not occur&rdquo;)
should be avoided, except when applied to statements that are logically true or false.
Hence, anything that is not a math theorem should have priors in $(0,1)$.
The reference comes from <a href="https://en.wikipedia.org/wiki/Oliver_Cromwell">Oliver Cromwell</a>,
asking, very politely, for the Church of Scotland to consider that their prior probability
might be wrong.
This footnote also deserves a whole blog post&hellip;&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><a href="https://en.wikipedia.org/wiki/Stigler%27s_law_of_eponymy">Stigler&rsquo;s law of eponymy</a>
states that no scientific discovery is named after its original discoverer.
The paradox was already was discussed in <a href="https://en.wikipedia.org/wiki/Harold_Jeffreys">Harold Jeffreys</a>'
1939 textbook.
Also, fun fact, Stigler&rsquo;s is not the original creator of such law&hellip;
Now that&rsquo;s a self-referential paradox, and a broad version of the <a href="https://en.wikipedia.org/wiki/Halting_problem">Halting problem</a>,
which should earn its own footnote.
Nevertheless, we are getting into self-referential danger zone here with
footnotes&rsquo; of footnotes&rsquo; of footnotes&rsquo;&hellip;&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>this is called $p$-value and can be easily defined as
&ldquo;the probability of sampling data from a target population given that $H_0$
is true as the number of sampling procedures $\to \infty$&rdquo;.
Yes, it is not that intuitive, and it deserves not a blog post,
but a full curriculum to hammer it home.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>that is not true for most of the real-world problems.
For Bayesian approaches,
we need to run computational asymptotic exact approximations using a class
of methods called <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">Markov chain Monte Carlo (MCMC)</a>.
Furthermore, for some nasty problems we need to use different set of methods
called <a href="https://en.wikipedia.org/wiki/Variational_Inference">variational inference (VI)</a>
or <a href="https://en.wikipedia.org/wiki/Approximate_Bayesian_computation">approximate Bayesian computation (ABC)</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>if you are curious about how this approximation works,
check the backup slides of my
<a href="https://github.com/storopoli/Bayesian-Statistics">open access and open source graduate course on Bayesian statistics</a>.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Bayes&rsquo; theorem is officially called Bayes-Price-Laplace theorem.
Bayes was trying to disprove David Hume&rsquo;s argument that miracles did not exist
(How dare he?).
He used the probabilistic approach of trying to quantify the probability of a parameter
(god exists) given data (miracles happened).
He died without publishing any of his ideas.
His wife probably freaked out when she saw the huge pile of notes that he had
and called his buddy Richard Price to figure out what to do with it.
Price struck gold and immediately noticed the relevance of Bayes&rsquo; findings.
He read it aloud at the Royal Society.
Later, Pierre-Simon Laplace, unbeknownst to the work of Bayes,
used the same probabilistic approach to perform statistical inference using France&rsquo;s
first census data in the early-Napoleonic era.
Somehow we had the answer to statistical inference back then,
and we had to rediscover everything again in the late-20th century&hellip;&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>disappointing because most of
published scientific studies suffer from this flaw.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>and, like all footnotes here, it deserves its own blog post&hellip;&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content>
      </entry>
      <entry>
        <title>Word Embeddings</title>
        <link rel="alternate" href="https://storopoli.io/2023-11-20-word_embeddings/" />
        <id>https://storopoli.io/2023-11-20-word_embeddings/</id>
        <published>2023-11-19T22:49:51-03:00</published>
        <updated>2024-02-11T15:55:02-03:00</updated>
        <summary type="html">Warning: This post has KaTeX enabled, so if you want to view the rendered math formulas, you&amp;rsquo;ll have to unfortunately enable JavaScript.
I wish I could go back in time and tell my younger self that you can make a machine understand human language with trigonometry. That would definitely have made me more aware and interested in the subject during my school years. I would have looked at triangles, circles, sines, cosines, and tangents in a whole different way.</summary>
          <content type="html"><![CDATA[<p><img loading="lazy" src="euclid.jpg#center" alt="Euclid of Alexandria"  />
</p>
<blockquote>
<p>Warning: This post has <a href="https://katex.org/">KaTeX</a> enabled,
so if you want to view the rendered math formulas,
you&rsquo;ll have to unfortunately enable JavaScript.</p>
</blockquote>
<p>I wish I could go back in time and tell my younger self
that you can make a machine understand human language with trigonometry.
That would definitely have made me more aware and interested in the
subject during my school years.
I would have looked at triangles, circles, sines, cosines, and tangents
in a whole different way.
Alas, better late than never.</p>
<p>In this post, we&rsquo;ll learn how to represent words using word embeddings,
and how to use basic trigonometry to play around with them.
Of course, we&rsquo;ll use <a href="https://julialang.org">Julia</a>.</p>
<h2 id="word-embeddings">Word Embeddings</h2>
<p><strong><a href="https://en.wikipedia.org/wiki/Word_embedding">Word embeddings</a> is a way to
represent words as a real-valued vector that encodes the meaning of the word
in such a way that words that are closer in the vector space are expected
to be similar in meaning</strong>.</p>
<p>Ok, let&rsquo;s unwrap the above definition.
First, a <strong>real-valued vector</strong> is any vector which its elements belong to the real
numbers.
Generally we denote vectors with a bold lower-case letter,
and we denote its elements (also called components) using square brackets.
Hence, a vector $\bold{v}$ that has 3 elements, $1$, $2$, and $3$,
can be written as</p>
<p>$$\bold{v} = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}$$</p>
<p>Next, what &ldquo;close&rdquo; means for vectors?
We can use distance functions to get a measurable value.
The most famous and commonly used distance function is the <strong>Euclidean distance</strong>,
in honor of <a href="https://en.wikipedia.org/wiki/Euclid">Euclid</a>, the &ldquo;father of geometry&rdquo;,
and the guy pictured in the image at the top of this post.
The Euclidean distance is defined in trigonometry for 2-D and 3-D spaces.
However, it can be generalized to any dimension $n &gt; 1$ by using vectors.</p>
<p>Since every word is represented by an $n$-dimensional vector,
we can use distances to compute a metric that represent similarity between vectors.
And, more interesting, we can add and subtract words
(or any other linear combination of one or more words) to generate new words.</p>
<p>Before we jump to code and examples, a quick note about how word embeddings
are constructed.
They are trained like a regular machine learning algorithm,
where the cost function measures the difference between
some vector distance between the vectors and a &ldquo;semantic distance&rdquo;.
The goal is to iteratively find good vector values that minimize the cost.
So, if a vector is close to another vector measured by a distance function,
but far apart measured by some semantic distance on the words that these
vectors represent, then the cost function will be higher.
The algorithm cannot change the semantic distance, it is treated as a fixed value.
However, it can change the vector elements&rsquo; values so that the vector distance function
closely resembles the semantic distance function.
Lastly, generally the dimensionality of the vectors used in word embeddings
are high, $n &gt; 50$, since it needs a proper amount of dimensions in order to
represent all the semantic information of words with vectors.</p>
<h2 id="pre-trained-word-embeddings">Pre-Trained Word Embeddings</h2>
<p>Generally we don&rsquo;t train our own word embeddings from scratch,
we use pre-trained ones.
Here is a list of some of the most popular ones:</p>
<ul>
<li><a href="https://code.google.com/archive/p/word2vec/">Word2Vec</a>:
One of the first public available word embeddings,
made by Google in 2013.
Only supports English.</li>
<li><a href="https://nlp.stanford.edu/projects/glove/">GloVe</a>:
made by Stanford in 2014.
Only supports English.</li>
<li><a href="https://fasttext.cc/">FastText</a>:
From Facebook, released in 2016.
Supports hundreds of languages.</li>
</ul>
<h2 id="julia-code">Julia Code</h2>
<p>We will use the <a href="https://github.com/JuliaText/Embeddings.jl"><code>Embeddings.jl</code></a>
package to easily load word embeddings as vectors,
and the <a href="https://github.com/JuliaStats/Distances.jl"><code>Distances.jl</code></a>
package for the convenience of several distance functions.
This is a nice example of the Julia package ecosystem composability,
where one package can define types, another can define functions,
and another can define custom behavior of these functions on types that
are defined in other packages.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-jl" data-lang="jl"><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="k">using</span> <span class="n">Embeddings</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="k">using</span> <span class="n">Distances</span>
</span></span></code></pre></div><p>Let&rsquo;s load the <a href="https://nlp.stanford.edu/projects/glove/">GloVe</a>
word embeddings.
First, let&rsquo;s check what we have in store to choose from
GloVe&rsquo;s English language embeddings:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-jl" data-lang="jl"><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="n">language_files</span><span class="p">(</span><span class="kt">GloVe</span><span class="p">{</span><span class="ss">:en</span><span class="p">})</span>
</span></span><span class="line"><span class="cl"><span class="mi">20</span><span class="o">-</span><span class="n">element</span> <span class="kt">Vector</span><span class="p">{</span><span class="kt">String</span><span class="p">}</span><span class="o">:</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.6B/glove.6B.50d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.6B/glove.6B.100d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.6B/glove.6B.200d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.6B/glove.6B.300d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.42B.300d/glove.42B.300d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.840B.300d/glove.840B.300d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.twitter.27B/glove.twitter.27B.25d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.twitter.27B/glove.twitter.27B.50d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.twitter.27B/glove.twitter.27B.100d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.twitter.27B/glove.twitter.27B.200d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.6B/glove.6B.50d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.6B/glove.6B.100d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.6B/glove.6B.200d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.6B/glove.6B.300d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.42B.300d/glove.42B.300d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.840B.300d/glove.840B.300d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.twitter.27B/glove.twitter.27B.25d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.twitter.27B/glove.twitter.27B.50d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.twitter.27B/glove.twitter.27B.100d.txt&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="s">&#34;glove.twitter.27B/glove.twitter.27B.200d.txt&#34;</span>
</span></span></code></pre></div><p>I&rsquo;ll use the <code>&quot;glove.6B/glove.6B.50d.txt&quot;</code>.
This means that it was trained with 6 billion tokens,
and it provides embeddings with 50-dimensional vectors.
The <code>load_embeddings</code> function takes an optional second positional
argument as an <code>Int</code> to choose from which index of the <code>language_files</code> to use.
Finally, I just want the words &ldquo;king&rdquo;, &ldquo;queen&rdquo;, &ldquo;man&rdquo;, &ldquo;woman&rdquo;;
so I am passing these words as a <code>Set</code> to the <code>keep_words</code> keyword argument:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-jl" data-lang="jl"><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="k">const</span> <span class="n">glove</span> <span class="o">=</span> <span class="n">load_embeddings</span><span class="p">(</span><span class="kt">GloVe</span><span class="p">{</span><span class="ss">:en</span><span class="p">},</span> <span class="mi">1</span><span class="p">;</span> <span class="n">keep_words</span><span class="o">=</span><span class="kt">Set</span><span class="p">([</span><span class="s">&#34;king&#34;</span><span class="p">,</span> <span class="s">&#34;queen&#34;</span><span class="p">,</span> <span class="s">&#34;man&#34;</span><span class="p">,</span> <span class="s">&#34;woman&#34;</span><span class="p">]));</span>
</span></span><span class="line"><span class="cl"><span class="n">Embeddings</span><span class="o">.</span><span class="kt">EmbeddingTable</span><span class="p">{</span><span class="kt">Matrix</span><span class="p">{</span><span class="kt">Float32</span><span class="p">},</span> <span class="kt">Vector</span><span class="p">{</span><span class="kt">String</span><span class="p">}}(</span><span class="kt">Float32</span><span class="p">[</span><span class="o">-</span><span class="mf">0.094386</span> <span class="mf">0.50451</span> <span class="o">-</span><span class="mf">0.18153</span> <span class="mf">0.37854</span><span class="p">;</span> <span class="mf">0.43007</span> <span class="mf">0.68607</span> <span class="mf">0.64827</span> <span class="mf">1.8233</span><span class="p">;</span> <span class="o">â€¦</span> <span class="p">;</span> <span class="mf">0.53135</span> <span class="o">-</span><span class="mf">0.64426</span> <span class="mf">0.48764</span> <span class="mf">0.0092753</span><span class="p">;</span> <span class="o">-</span><span class="mf">0.11725</span> <span class="o">-</span><span class="mf">0.51042</span> <span class="o">-</span><span class="mf">0.10467</span> <span class="o">-</span><span class="mf">0.60284</span><span class="p">],</span> <span class="p">[</span><span class="s">&#34;man&#34;</span><span class="p">,</span> <span class="s">&#34;king&#34;</span><span class="p">,</span> <span class="s">&#34;woman&#34;</span><span class="p">,</span> <span class="s">&#34;queen&#34;</span><span class="p">])</span>
</span></span></code></pre></div><p>Watch out with the order that we get back.
If you see the output of <code>load_embeddings</code>,
the order is <code>&quot;man&quot;, &quot;king&quot;, &quot;woman&quot;, &quot;queen&quot;]</code>
Let&rsquo;s see how a word is represented:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-jl" data-lang="jl"><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="n">queen</span> <span class="o">=</span> <span class="n">glove</span><span class="o">.</span><span class="n">embeddings</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="mi">50</span><span class="o">-</span><span class="n">element</span> <span class="kt">Vector</span><span class="p">{</span><span class="kt">Float32</span><span class="p">}</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">  <span class="mf">0.37854</span>
</span></span><span class="line"><span class="cl">  <span class="mf">1.8233</span>
</span></span><span class="line"><span class="cl"> <span class="o">-</span><span class="mf">1.2648</span>
</span></span><span class="line"><span class="cl">  <span class="o">â‹®</span>
</span></span><span class="line"><span class="cl"> <span class="o">-</span><span class="mf">2.2839</span>
</span></span><span class="line"><span class="cl">  <span class="mf">0.0092753</span>
</span></span><span class="line"><span class="cl"> <span class="o">-</span><span class="mf">0.60284</span>
</span></span></code></pre></div><p>They are 50-dimensional vectors of <code>Float32</code>.</p>
<p>Now, here&rsquo;s the fun part:
let&rsquo;s add words and check the similarity between the
result and some other word.
A classical example is to start with the word &ldquo;king&rdquo;,
subtract the word &ldquo;men&rdquo;,
add the word &ldquo;woman&rdquo;,
and check the distance of the result to the word &ldquo;queen&rdquo;:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-jl" data-lang="jl"><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="n">man</span> <span class="o">=</span> <span class="n">glove</span><span class="o">.</span><span class="n">embeddings</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="mi">1</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="n">king</span> <span class="o">=</span> <span class="n">glove</span><span class="o">.</span><span class="n">embeddings</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="mi">2</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="n">woman</span> <span class="o">=</span> <span class="n">glove</span><span class="o">.</span><span class="n">embeddings</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="mi">3</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="n">cosine_dist</span><span class="p">(</span><span class="n">king</span> <span class="o">-</span> <span class="n">man</span> <span class="o">+</span> <span class="n">woman</span><span class="p">,</span> <span class="n">queen</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mf">0.13904202f0</span>
</span></span></code></pre></div><p>This is less than 1/4 of the distance of &ldquo;woman&rdquo; to &ldquo;king&rdquo;:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-jl" data-lang="jl"><span class="line"><span class="cl"><span class="n">julia</span><span class="o">&gt;</span> <span class="n">cosine_dist</span><span class="p">(</span><span class="n">woman</span><span class="p">,</span> <span class="n">king</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mf">0.58866215f0</span>
</span></span></code></pre></div><p>Feel free to play around with others words.
If you want suggestions, another classical example is:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">cosine_dist</span><span class="p">(</span><span class="n">Madrid</span> <span class="o">-</span> <span class="n">Spain</span> <span class="o">+</span> <span class="n">France</span><span class="p">,</span> <span class="n">Paris</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="conclusion">Conclusion</h2>
<p>I think that by allying interesting applications to abstract math topics
like trigonometry is the vital missing piece in STEM education.
I wish every new kid that is learning math could have the opportunity to contemplate
how new and exciting technologies have some amazing simple math under the hood.
If you liked this post, you would probably like <a href="https://en.wikipedia.org/wiki/Linear_algebra">linear algebra</a>.
I would highly recommend <a href="https://math.mit.edu/~gs/">Gilbert Strang&rsquo;s books</a>
and <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">3blue1brown series on linear algebra</a>.</p>
<h2 id="license">License</h2>
<p>This post is licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International</a>.</p>
<p><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img loading="lazy" src="https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png" alt="CC BY-NC-SA 4.0"  />
</a></p>
]]></content>
      </entry>

</feed>


