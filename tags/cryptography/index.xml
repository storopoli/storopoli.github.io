<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Cryptography on Jose Storopoli, PhD</title>
    <link>https://storopoli.io/tags/cryptography/</link>
    <description>Recent content in Cryptography on Jose Storopoli, PhD</description>
    <generator>Hugo -- 0.136.5</generator>
    <language>en-us</language>
    <copyright>CC BY-NC-SA 4.0</copyright>
    <lastBuildDate>Sun, 09 Jun 2024 08:34:22 -0300</lastBuildDate>
    <atom:link href="https://storopoli.io/tags/cryptography/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Zero-Knowledge Proofs</title>
      <link>https://storopoli.io/2024-06-08-zkp/</link>
      <pubDate>Sat, 08 Jun 2024 15:48:33 -0300</pubDate>
      <guid>https://storopoli.io/2024-06-08-zkp/</guid>
      <description>&lt;figure&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;zkp_meme.jpg#center&#34;
         alt=&#34;Zero-Knowledge Proofs and the Meaning of Life&#34; width=&#34;500&#34;/&gt; &lt;figcaption&gt;
            Zero-Knowledge Proofs and the Meaning of Life
        &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;blockquote&gt;
&lt;p&gt;Warning: This post has &lt;a href=&#34;https://katex.org/&#34;&gt;KaTeX&lt;/a&gt;
and &lt;a href=&#34;https://mermaid.js.org&#34;&gt;&lt;code&gt;mermaid.js&lt;/code&gt;&lt;/a&gt; enabled,
so if you want to view the rendered math formulas,
and diagrams,
you&amp;rsquo;ll have to unfortunately enable JavaScript.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Lately, I&amp;rsquo;ve been diving a little into the world of &lt;strong&gt;Zero-Knowledge Proofs&lt;/strong&gt;.
The idea is to prove that you know something without revealing what you know.
More specifically, a &lt;strong&gt;Zero-Knowledge Proof&lt;/strong&gt; is a cryptographic protocol that allows
a &lt;strong&gt;prover&lt;/strong&gt; to convince a &lt;strong&gt;verifier&lt;/strong&gt; that a statement is true without revealing
any information beyond the validity of the statement.
In essence, by the end of the protocol, the verifier is convinced that the prover knows the secret,
and the &lt;strong&gt;verifier hasn&amp;rsquo;t learned anything (zero-knowledge) about the secret&lt;/strong&gt;.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<figure>
    <img loading="lazy" src="zkp_meme.jpg#center"
         alt="Zero-Knowledge Proofs and the Meaning of Life" width="500"/> <figcaption>
            Zero-Knowledge Proofs and the Meaning of Life
        </figcaption>
</figure>

<blockquote>
<p>Warning: This post has <a href="https://katex.org/">KaTeX</a>
and <a href="https://mermaid.js.org"><code>mermaid.js</code></a> enabled,
so if you want to view the rendered math formulas,
and diagrams,
you&rsquo;ll have to unfortunately enable JavaScript.</p>
</blockquote>
<p>Lately, I&rsquo;ve been diving a little into the world of <strong>Zero-Knowledge Proofs</strong>.
The idea is to prove that you know something without revealing what you know.
More specifically, a <strong>Zero-Knowledge Proof</strong> is a cryptographic protocol that allows
a <strong>prover</strong> to convince a <strong>verifier</strong> that a statement is true without revealing
any information beyond the validity of the statement.
In essence, by the end of the protocol, the verifier is convinced that the prover knows the secret,
and the <strong>verifier hasn&rsquo;t learned anything (zero-knowledge) about the secret</strong>.</p>
<p><strong>Zero-Knowledge Proofs</strong> (ZKPs) are kinda hot right now,
since a lot of new Bitcoin innovations are being built on top of them.
It allows for a higher level of privacy and potential scalability improvements
in the Bitcoin network.</p>
<p>Zero-knowledge proofs are advantageous in a myriad of application,
including (refer to <a href="https://arxiv.org/abs/1906.07221" title="Petkus, M. (2019). Why and How zk-SNARK works. arXiv preprint 1906.07221.">Petkus19</a>):</p>
<ul>
<li>
<p><strong>Proving statement on private data</strong>:</p>
<ul>
<li>Person $A$ has more than $X$ in his bank account</li>
<li>In the last year, a bank did not transact with an entity $Y$</li>
<li>Matching DNA without revealing full DNA</li>
<li>One has a credit score higher than $Z$</li>
</ul>
</li>
<li>
<p><strong>Anonymous authorization</strong>:</p>
<ul>
<li>Proving that requester $R$ has right to access web-site&rsquo;s restricted area without revealing its identity (e.g., login, password)</li>
<li>Prove that one is from the list of allowed countries/states without revealing from which one exactly</li>
<li>Prove that one owns a monthly pass to a subway/metro without revealing card&rsquo;s id</li>
</ul>
</li>
<li>
<p><strong>Anonymous payments</strong>:</p>
<ul>
<li>Payment with full detachment from any kind of identity</li>
<li>Paying taxes without revealing one&rsquo;s earnings</li>
</ul>
</li>
<li>
<p><strong>Outsourcing computation</strong>:</p>
<ul>
<li>Outsource an expensive computation and validate that the result is correct without redoing the execution;
it opens up a category of trustless computing</li>
<li>Changing a blockchain model from everyone computes the same to one party computes and everyone verifies</li>
</ul>
</li>
</ul>
<p>The idea behind this post is to give a general overview of Zero-Knowledge Proofs,
while providing further resources,
especially which papers to read,
to dive deeper into the subject.
As always, I&rsquo;ll try to keep it simple and intuitive.
However, as you might guess, the subject is quite complex,
and I&rsquo;ll try to simplify it as much as possible;
but some mathematical background is necessary.</p>
<h2 id="what-are-zkps">What are ZKPs?</h2>
<p>Let&rsquo;s formalize the concept of <strong>Zero-Knowledge Proofs</strong>.
A formal definition of zero-knowledge has to use some computational model,
and without loss of generality,
we can use the <a href="https://en.wikipedia.org/wiki/Turing_machine">Turing Machine</a>
model.
So let&rsquo;s create three Turing machines:</p>
<ul>
<li>$P$ (the <strong>prover</strong>),</li>
<li>$V$ (the <strong>verifier</strong>),</li>
<li>and $S$ (the <strong>simulator</strong>).</li>
</ul>
<p>Let&rsquo;s also spicy things up a bit and introduce an <strong>adversary</strong> $A$,
and assume that it is also a Turing machine.
<strong>The secret we want to prove knowledge without revealing is $x$</strong>.</p>
<p>The prover $P$ wants to prove to the verifier $V$ that it knows the secret $x$.
They both share a common simulator $S$.
The adversary $A$ is trying to fool the verifier $V$ into believing that it knows the secret $x$,
without actually knowing it.</p>
<p>The prover $P$ generates a proof $\pi = P(S, x)$,
and sends it to the verifier $V$.
The verifier $V$ then checks the proof $\pi$,
and decides whether to accept or reject it.</p>
<p>The tuple $(P, V, S)$ is a <strong>Zero-Knowledge Proof</strong> if the following properties hold:</p>
<ol>
<li>
<p><strong>Completeness</strong>: If the statement is true, the verifier will accept the proof.</p>
<p>$$ \Pr\big[V(S, \pi) = \text{accept} \big] = 1. $$</p>
<p>Here $\Pr\big[V(S, \pi) = \text{accept} \big]$ denotes the probability that the verifier accepts the proof given a simulator $S$ and a proof $\pi$.</p>
</li>
<li>
<p><strong>Soundness</strong>: If the statement is true, no cheating prover can convince an honest verifier that it is true,
except with some negligible probability <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>$$ \forall A, \forall x, \forall \pi: \Pr\big[V(A, S, \pi) = \text{accept} \big] &lt; \text{negligible}. $$</p>
<p>Here $\Pr\big[V(A, S, \pi) = \text{accept} \big]$ denotes the probability that the verifier accepts the proof given an adversary $A$, a simulator $S$, and a proof $\pi$.</p>
</li>
<li>
<p><strong>Zero-Knowledge</strong>: If the statement is true, the verifier learns nothing about the secret $x$.
A proof is zero-knowledge if there exists a simulator $S$ that can simulate the verifier&rsquo;s view
without knowing the secret $x$.</p>
<p>$$ \forall x: \text{View}_V\big[P(x) \leftrightarrow V(\pi)\big] = S(x, \pi). $$</p>
<p>Here $\text{View}_V$ is the view of the verifier $V$,
and $\leftrightarrow$ denotes the interaction between the prover and the verifier.</p>
</li>
</ol>
<p>If you come up from a scheme that satisfies these properties,
congratulations, you have a <strong>Zero-Knowledge Proof</strong> scheme
and you can name it whatever you want,
just like a Pokemon!</p>
<h2 id="zkps-taxonomy">ZKPs Taxonomy</h2>
<p>We can classify <strong>Zero-Knowledge Proofs</strong> into two broad categories:</p>
<ol>
<li>
<p><strong>Interactive Zero-Knowledge Proofs</strong>: In this case, the prover and the verifier interact multiple times.
The prover sends a proof to the verifier,
and the verifier sends a challenge to the prover,
and this interaction continues until the verifier is convinced.
The Fiat-Shamir Heuristic can transform an interactive ZKP into a non-interactive ZKP.</p>
</li>
<li>
<p><strong>Non-Interactive Zero-Knowledge Proofs</strong>: In this case, the prover sends a proof to the verifier,
and the verifier accepts or rejects the proof.
No further interaction is needed.</p>
</li>
</ol>
<p>Additionally,
the setup of the <strong>simulator $S$ with respect to the data it uses</strong>
can be further classified into three categories.
Generally speaking, the data used by $S$ is some random bits.
In trusted setups, if the data is compromised,
the security of the proof is also compromised.
In other words, anyone with the hold of the data can prove anything to anyone.
This is bad, and we want to avoid it.</p>
<ol>
<li><strong>Trusted Setup</strong>: $S$ uses data that must be kept secret.</li>
<li><strong>Trusted but Universal Setup</strong>: $S$ uses data that must be kept private,
but it only uses for the initial setup.
Future proofs can be verified without the need for the initial data,
and can be considered transparent.</li>
<li><strong>Transparent Setup</strong>: $S$ uses no data at all.
This is the best setup, as it doesn&rsquo;t require any data to be used by $S$.</li>
</ol>
<p>Some of the most popular Zero-Knowledge Proof systems are:</p>
<ul>
<li><strong>zk-SNARKs</strong>: Zero-Knowledge Succinct Non-Interactive Argument of Knowledge.
This is a non-interactive ZKP system with a trusted setup.</li>
<li><strong>Bulletproofs</strong>: A non-interactive ZKP system with a transparent setup.</li>
<li><strong>zk-STARKs</strong>: Zero-Knowledge Scalable Transparent Argument of Knowledge.
This is a non-interactive ZKP system with a transparent setup,
with an additional property of being (plausibly) post-quantum secure.</li>
</ul>
<h2 id="zk-snarks">zk-SNARKs</h2>
<p><strong>zk-SNARKs</strong> are the most popular Zero-Knowledge Proof system.
They are used in the Zcash protocol,
and the defunct Tornado Cash smart contract.
Ethereum also uses zk-SNARKs in its Layer 2 scaling solution,
the zk-Rollups.
<a href="https://bitvm.org/">BitVM</a> also uses a SNARK-based VM to run smart contracts
on top of Bitcoin.</p>
<p>Let&rsquo;s go over the concepts behind zk-SNARKs<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<h3 id="the-first-idea-proving-knowledge-of-a-polynomial">The first idea: Proving Knowledge of a Polynomial</h3>
<p>First some polynomial primer.
<strong>A polynomial $f(x)$ is a function that can be written as</strong>:</p>
<p>$$ f(x) = c_d x^d + \ldots + c_1 x^1 + c_0 x^0 $$</p>
<p>where $c_d, \ldots, c_1, c_0$ are the coefficients of the polynomial,
and $d$ is the degree of the polynomial.</p>
<p>Now, the <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_algebra">Fundamental Theorem of Algebra</a> states that
<strong>a polynomial of degree $d$ can have at most $d$ (real-valued-only) roots<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></strong>.</p>
<p>This can be extended to the concept that <strong>two non-equal polynomials of degree $d$ can have at most $d$ points of intersection</strong>.</p>
<p>The idea of proving knowledge of a polynomial is to show that you know the polynomial,
without revealing the polynomial itself.</p>
<p>This simple protocol can be done in four steps,
note that both the prover and the verifier have knowledge of the polynomial:</p>
<ol>
<li>Verifier chooses a random value for $x$ and evaluates his polynomial locally</li>
<li>Verifier gives $x$ to the prover and asks to evaluate the polynomial in question</li>
<li>Prover evaluates his polynomial at $x$ and gives the result to the verifier</li>
<li>Verifier checks if the local result is equal to the prover&rsquo;s result,
and if so then the statement is proven with a high confidence</li>
</ol>
<p>How much is &ldquo;high confidence&rdquo;?
Suppose that the verifier chooses an $x$ at random from a set of $2^{256}$ values,
that is a 256-bit number.
According to <a href="https://www.wolframalpha.com/input?i2d=true&amp;i=Power%5B2%2C256%5D">Wolfram Alpha</a>,
the decimal approximation is $\approx 1.16 \times 10^{77}$.
This is almost the <a href="https://en.wikipedia.org/wiki/Observable_universe#Matter_content%E2%80%94number_of_atoms">number of atoms in the observable universe</a>!
The number of points where evaluations are different is $10^{77} - d$,
where $d$ is the degree of the polynomial.
Therefore, we can assume with overwhelming probability that the prover knows the polynomial.
This is due to the fact that an adversary has $\frac{d}{10^{77}}$ chance of guessing the polynomial<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>,
which we can safely consider negligible<sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<h3 id="the-second-idea-proving-knowledge-of-a-polynomial-without-revealing-the-polynomial">The second idea: Proving Knowledge of a Polynomial without Revealing the Polynomial</h3>
<p>The protocol above has some implications,
mainly that the protocol works only for a certain polynomial,
and the verifier has to know the polynomial in advance.
Which is not practical at all since we want to prove knowledge
of a secret without revealing the secret itself.</p>
<p>We can do better, we can use the fact,
also stated in the <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_algebra">Fundamental Theorem of Algebra</a>,
that any polynomial can be factored into linear polynomials,
i.e. a set of degree-1 polynomials representing a line.
We can represent any valid polynomial as a product of its linear-polynomial factors:</p>
<p>$$ (x - a_0) (x - a_1) \ldots (x - a_d) = 0 $$</p>
<p>where $a_0, \ldots, a_{d}$ are the roots of the polynomial.
If you wanna prove knowledge of a polynomial, it is just a matter of proving knowledge of its roots.
But how do we do that without disclosing the polynomial itself?
This can be accomplished by proving that a polynomial $p(x)$ is the multiplication
of the factors $t(x) = (x - a_0) \ldots (x - a_d)$, called the <strong>target polynomial</strong>,
and some arbitrary polynomial $h(x)$, called the <strong>residual polynomial</strong>:</p>
<p>$$ p(x) = t(x) \cdot h(x). $$</p>
<p>The prover can show that exists some polynomial $h(x)$ such that
$p(x)$ can be made equal to $t(x)$.
You can find $h(x)$ by simply dividing $p(x)$ by $t(x)$:</p>
<p>$$ h(x) = \frac{p(x)}{t(x)}. $$</p>
<p>Now we can create a protocol that can work for any polynomial $p(x)$
with only three steps:</p>
<ol>
<li>Verifier samples a random value $r$, calculates $t = t(r)$ and gives $r$ to the
prover</li>
<li>Prover calculates $h(x) = \frac{p(x)}{t(x)}$ and evaluates $p = p(r)$ and $h = h(r)$;
the resulting values $p$, $h$ are provided to the verifier</li>
<li>Verifier then checks that $p = t \cdot h$, if so those polynomials are equal,
meaning that $p(x)$ has $t(x)$ as a cofactor.</li>
</ol>
<p>Note that the verifier has no clue about the polynomial $p(x)$,
and can be convinced that the prover knows the polynomial $p(x)$.</p>
<p>For example, let&rsquo;s consider two polynomials $p(x)$ and $t(x)$ of degree $3$:</p>
<ul>
<li>$p(x) = x^3 - 3x^2 + 2x$</li>
<li>$t(x) = (x - 1) (x - 2)$</li>
</ul>
<p>An example protocol interaction in this case could be:</p>
<ol>
<li>Verifier samples a random value $23$, calculates $t = t(23) = (23 − 1)(23 − 2) = 462$ and
gives $23$ to the prover</li>
<li>Prover calculates $h(x) = \frac{p(x)}{t(x)} = x$, evaluates $p = p(23) = 10626$ and $h = h(23) = 23$
and provides $p$, $h$ to the verifier</li>
<li>Verifier then checks that $p = t \cdot h$, i.e. $10626 = 462 \cdot 23$,
which is true, and therefore the statement is proven</li>
</ol>
<p>Great! We can prove stuff without revealing the stuff itself!
Noice!
We know only need to find a trick to represent
any sort of computation as a polynomial.</p>
<h3 id="the-third-idea-representing-computations-as-polynomials">The third idea: Representing Computations as Polynomials</h3>
<p>We can <strong>represent any computation as a polynomial by using <a href="https://en.wikipedia.org/wiki/Arithmetic_circuit">Arithmetic Circuits</a></strong>.
An arithmetic circuit is a directed acyclic graph (DAG) where:</p>
<ul>
<li>Every indegree<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>-zero node is an input gate that represents a variable $x_i$</li>
<li>Every node with indegree $&gt;1$ is either:
<ul>
<li>an addition gate, $+$, that represents the sum of its children</li>
<li>a multiplication gate, $\times$, that represents the product of its children</li>
</ul>
</li>
</ul>
<p>Here&rsquo;s an example of an arithmetic circuit that represents the polynomial $p(x_1, x_2) = x_2^3 + x_1 x_2^2 + x_2^2 + x_1 x_2$:</p>
<div class="mermaid" style="text-align: center">
---

title: Arithmetic Circuit for p(x)
---

graph BT
  X1(x₁) --> Plus1(+)
  X2(X₂) --> Plus1
  X2 --> Plus2(+)
  One(1) --> Plus2
  Plus1 --> Times(⨉)
  Plus2 --> Times
  X2 --> Times
  
</div>

<p>In the circuit above, the input gates compute (from left to right)
$x_{1},x_{2}$ and $1$,
the sum gates compute $x_{1}+x_{2}$
and $x_{2}+1$,
and the product gate computes $(x_{1}+x_{2})x_{2}(x_{2}+1)$
which evaluates to $x_{2}^{3}+x_{1}x_{2}^{2}+x_{2}^{2}+x_{1}x_{2}$.</p>
<p>The idea is to prove that the output of the circuit is equal to some target polynomial $t(x)$.
This can be done by proving that the output of the circuit is equal to the target polynomial $t(x)$
multiplied by some arbitrary polynomial $h(x)$,
as we did in the previous section.</p>
<h2 id="remarks">Remarks</h2>
<p>This is a very high-level overview of Zero-Knowledge Proofs.
The subject is quite complex and requires a lot of mathematical background.
I tried to simplify it as much as possible,
to give a general intuition of how Zero-Knowledge Proofs work.
Please check the resources below for more in-depth information.</p>
<h2 id="resources">Resources</h2>
<p>We have tons of papers on the subject.
Here are some selected few.</p>
<p>The whole idea of ZKPs as discussed above in three properties
(Completeness, Soundness, and Zero-Knowledge)
was first conceived by [<a href="https://epubs.siam.org/doi/10.1137/0218012" title="Goldwasser, S., Micali, S., &amp; Rackoff, C. (1985). The knowledge complexity of interactive proof systems. SIAM Journal on computing, 18(1), 186-208.">SMR85</a>].
Later [<a href="https://dl.acm.org/doi/abs/10.1145/129712.129782" title="Kilian, J. (1992). A note on efficient zero-knowledge proofs and arguments (extended abstract). In Proceedings of the twenty-fourth annual ACM symposium on Theory of computing (pp. 723-732).">Kil92</a>] showed that some of the properties&rsquo; assumptions can be relaxed,
more specifically using computational soundness instead of statistical soundness.
[<a href="https://ieeexplore.ieee.org/abstract/document/365746/" title="Micali, S. (1994). CS proofs (extended abstract). In Proceedings 35th Annual Symposium on Foundations of Computer Science (pp. 436-445).">Mic94</a>] applied the <a href="https://en.wikipedia.org/wiki/Fiat%E2%80%93Shamir_heuristic">Fiat-Shamir Heuristic</a>
to [<a href="https://dl.acm.org/doi/abs/10.1145/129712.129782" title="Kilian, J. (1992). A note on efficient zero-knowledge proofs and arguments (extended abstract). In Proceedings of the twenty-fourth annual ACM symposium on Theory of computing (pp. 723-732).">Kil92</a>]&rsquo;s contributions to show that you can create any non-interactive ZKP system into
a non-interactive ZKP system using the <a href="https://en.wikipedia.org/wiki/Random_oracle_model">Random Oracle Model</a>.</p>
<p>Going to the zk-SNARKs side,
the term was introduced by [<a href="https://eprint.iacr.org/2011/443" title="Bitansky, N., Canetti, R., &amp; Goldwasser, S. (2011). From Extractable Collision Resistance to Succinct Non-Interactive Arguments of Knowledge, and Back Again. In Proceedings of the 3rd innovations in theoretical computer science conference (pp. 326-349).">Bit11</a>]
and the first protocol, the Pinocchio protocol,
was introduced by [<a href="https://eprint.iacr.org/2012/215" title="Gennaro, R., Gentry, C., Parno, B., &amp; Raykova, M. (2013). Quadratic span programs and succinct NIZKs without PCPs. In Advances in Cryptology–EUROCRYPT 2013: 32nd Annual International Conference on the Theory and Applications of Cryptographic Techniques, Athens, Greece, May 26-30, 2013. Proceedings 32 (pp. 626-645).">Gen12</a>] and [<a href="https://eprint.iacr.org/2013/279" title="Parno, B., Gentry, C., Howell, J., &amp; Raykova, M. (2013). Pinocchio: Nearly practical verifiable computation. In Proceedings of the 2013 IEEE Symposium on Security and Privacy (SP) (pp. 238-252).">Par13</a>].
The Bulletproofs protocol was introduced by [<a href="https://ieeexplore.ieee.org/document/8418611" title="Bünz, B., Bootle, J., Boneh, D., Poelstra, A., Wuille, P., &amp; Maxwell, G. (2018). Bulletproofs: Short Proofs for Confidential Transactions and More. In Proceedings of the 2018 IEEE Symposium on Security and Privacy (SP) (pp. 315-334).">Bunz18</a>],
followed by the Bulletproofs++ protocol by [<a href="https://link.springer.com/chapter/10.1007/978-3-031-58740-5_9" title="Bulletproofs++: next generation confidential transactions via reciprocal set membership arguments. In Annual International Conference on the Theory and Applications of Cryptographic Techniques (pp. 249-279).">Eagen24</a>].</p>
<p>zk-STARKs were introduced by [<a href="https://link.springer.com/chapter/10.1007/978-3-030-26954-8_23" title="Ben-Sasson, E., Bentov, I., Horesh, Y., &amp; Riabzev, M. (2019). Scalable zero knowledge with no trusted setup. In Advances in Cryptology–CRYPTO 2019: 39th Annual International Cryptology Conference, Santa Barbara, CA, USA, August 18–22, 2019, Proceedings, Part III 39 (pp. 701-732).">Ben-Sasson19</a>].</p>
<p>Finally, if you want an intuitive but very comprehensive explanation of zk-SNARKs,
then you should read [<a href="https://arxiv.org/abs/1906.07221" title="Petkus, M. (2019). Why and How zk-SNARK works. arXiv preprint 1906.07221.">Petkus19</a>].</p>
<p>The following video from YouTube is from the
<a href="https://rdi.berkeley.edu/">Blockchain Web3 MOOC from Berkeley University</a>.
It provides a good introduction to Zero-Knowledge Proofs,
while being quite accessible to beginners.</p>
<style>
  .embed-container {
    position: relative;
    padding-bottom: 56.25%;
    height: 0;
    overflow: hidden;
    max-width: 100%;
  }
  .embed-container iframe,
  .embed-container object,
  .embed-container embed {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
  }
</style>
<div class="embed-container">
  <iframe
    src="https://www.youtube.com/embed/gcKCW7CNu_M"
    frameborder="0"
    allowfullscreen
  ></iframe>
</div>

<br />

<p>This <a href="https://youtu.be/iRQw2RpQAVc">video from YouTube</a>
explains the math behind the Arithmetic Circuits
and how to encode them as polynomials.
I can&rsquo;t embed the video here, since the video owner has disabled embedding.</p>
<h2 id="license">License</h2>
<p>This post is licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International</a>.</p>
<p><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img loading="lazy" src="https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png" alt="CC BY-NC-SA 4.0"  />
</a></p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>A function $f$ is negligible if for every polynomial $p$,
there exists an $N$ such that for all $n &gt; N$,
$$ f(n) &lt; \frac{1}{p(n)}. $$
If you want to learn more about negligible functions,
read Chapter 3, Section 3.1 of the book <a href="https://doi.org/10.1201/9781420010756">Introduction to Modern Cryptography</a> by Katz &amp; Lindell.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>most of this section is based on <a href="https://arxiv.org/abs/1906.07221" title="Petkus, M. (2019). Why and How zk-SNARK works. arXiv preprint 1906.07221.">Petkus19</a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>the &ldquo;at most&rdquo; is because we are talking about real-valued-only roots.
If we consider complex roots, then a polynomial of degree $d$ has exactly $d$ roots.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>the <a href="https://en.wikipedia.org/wiki/Birthday_problem">Birthday paradox</a>
states that any collision resistance scheme has a probability of $\frac{1}{2}$ of collision,
hence we take the square root of the number of possible values.
So, the security of the polynomial proof is $\sqrt{10^{77}} = 10^{38.5}$,
which is still a huge number.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>the number of edges entering a node&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    <item>
      <title>Shamir&#39;s Secret Sharing</title>
      <link>https://storopoli.io/2024-04-14-shamir-secret-sharing/</link>
      <pubDate>Sun, 14 Apr 2024 10:37:02 -0300</pubDate>
      <guid>https://storopoli.io/2024-04-14-shamir-secret-sharing/</guid>
      <description>&lt;figure&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;polynomial_king.webp#center&#34;
         alt=&#34;The Polynomial king and he can do anything!&#34; width=&#34;500&#34;/&gt; &lt;figcaption&gt;
            The Polynomial king and he can do anything!
        &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;blockquote&gt;
&lt;p&gt;Warning: This post has &lt;a href=&#34;https://katex.org/&#34;&gt;KaTeX&lt;/a&gt; enabled,
so if you want to view the rendered math formulas,
you&amp;rsquo;ll have to unfortunately enable JavaScript.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this post, we&amp;rsquo;ll talk about
&lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing&#34;&gt;Shamir&amp;rsquo;s Secret Sharing&lt;/a&gt;
(SSS)&lt;/strong&gt;, a cryptographic algorithm that allows us to &lt;strong&gt;split a secret into multiple parts,
called shares, in such a way that the secret can only be reconstructed
if a certain number of shares are combined&lt;/strong&gt;.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<figure>
    <img loading="lazy" src="polynomial_king.webp#center"
         alt="The Polynomial king and he can do anything!" width="500"/> <figcaption>
            The Polynomial king and he can do anything!
        </figcaption>
</figure>

<blockquote>
<p>Warning: This post has <a href="https://katex.org/">KaTeX</a> enabled,
so if you want to view the rendered math formulas,
you&rsquo;ll have to unfortunately enable JavaScript.</p>
</blockquote>
<p>In this post, we&rsquo;ll talk about
<strong><a href="https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing">Shamir&rsquo;s Secret Sharing</a>
(SSS)</strong>, a cryptographic algorithm that allows us to <strong>split a secret into multiple parts,
called shares, in such a way that the secret can only be reconstructed
if a certain number of shares are combined</strong>.</p>
<p>The idea is to give a visual intuition of how the algorithm works,
and describe the mathematical details behind it.</p>
<p>The code for all the plots in this post can be found in
<a href="https://github.com/storopoli/shamir-secret-sharing"><code>storopoli/shamir-secret-sharing</code></a>.</p>
<h2 id="polynomial-interpolation">Polynomial Interpolation</h2>
<p><strong>If you have two points you can draw a <em>unique</em> line that passes through them</strong>.
Suppose that you have the points $(3,3)$ and $(4,4)$.
Hence, there is only one line that passes through these two points.
See the plot below.</p>
<figure>
    <img loading="lazy" src="line.svg#center"
         alt="A line passing through two points" width="600"/> <figcaption>
            A line passing through two points
        </figcaption>
</figure>

<p><strong>If you have three points you can draw a <em>unique</em> parabola that passes through them</strong>.
Suppose that you have the points $(-4,16)$, $(1,1)$, and $(4,16)$.
Hence, there is only one parabola that passes through these three points.</p>
<figure>
    <img loading="lazy" src="quadratic.svg#center"
         alt="A parabola passing through three points" width="600"/> <figcaption>
            A parabola passing through three points
        </figcaption>
</figure>

<p><strong>If you have four points you can draw a <em>unique</em> cubic polynomial that passes through them</strong>.
Suppose that you have the points $(-2,8)$, $(-1,1)$, $(1,1)$, and $(2,8)$.
Hence, there is only one cubic polynomial that passes through these four points.</p>
<figure>
    <img loading="lazy" src="cubic.svg#center"
         alt="A cubic polynomial passing through four points" width="600"/> <figcaption>
            A cubic polynomial passing through four points
        </figcaption>
</figure>

<p>As you might have guessed, <strong>if you have $n$ points you can draw a <em>unique</em> polynomial of degree $n-1$ that passes through them</strong>.
This is called <strong>polynomial interpolation</strong><sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>More formally, say that we have a polynomial $f(x)$ of degree $n$:</p>
<p>$$ f(x) = a_n x^n + a_{n-1} x^{n-1} + \ldots + a_1x + a_0 $$</p>
<p>and we have $n$ points $(x_1, y_1)$, $(x_2, y_2)$, $\ldots$, $(x_n, y_n)$.
Then, there is a unique polynomial $f(x)$ of degree $n-1$ such that $f(x_i) = y_i$ for $i = 1, 2, \ldots, n$.</p>
<h2 id="shamirs-secret-sharing">Shamir&rsquo;s Secret Sharing</h2>
<p>Ok now let&rsquo;s connect this idea to Shamir&rsquo;s Secret Sharing.
Suppose you encode a <strong>secret $k$ as a number</strong>.
Let&rsquo;s say a private key for a Bitcoin wallet.
As you&rsquo;ve already know, a private key is just a <a href="../2024-02-05-crypto-basics/">very big number</a>.</p>
<p>You want to split this secret into <strong>$N$ parts</strong>, called <strong>shares</strong>.
You also want to specify a <strong>threshold $T$</strong> such that the <strong>secret $k$ can only be reconstructed if at <em>least</em> $T$ shares are combined</strong>.
Here&rsquo;s how you can use polynomial interpolation to achieve this.</p>
<p>The idea is to use polynomial interpolation to generate a polynomial $f(x)$ of degree $T-1$ such that $f(0) = k$.
In other words, the polynomial $f(x)$ when evaluated at $x = 0$ should give you the secret $k$.
Then, you can <strong>generate $N$ shares by evaluating $f(x)$ at $N$ different points</strong>.</p>
<p>Here&rsquo;s an example with $T = 4$ and $N = 5$.
Our secret is $k = 5$ and since $T = 4$, we generate a polynomial of degree $T-1 = 3$.
We&rsquo;ve chosen the polynomial $f(x) = 2x^3 - 3x^2 + 2x + 5 $.
Then, we evaluate $f(x)$ at $N = 5$ different points to generate the shares.</p>
<figure>
    <img loading="lazy" src="shamir.svg#center"
         alt="Shamir&#39;s Secret Sharing with N=5 and T=4" width="600"/> <figcaption>
            Shamir&#39;s Secret Sharing N=5 and T=4
        </figcaption>
</figure>

<p>Now this polynomial is <strong>guaranteed to pass through the point $(0, k)$</strong>.
Hence if you evaluate <strong>$f(0)$ you get the secret $k$</strong>.
To know the secret, you <strong>need to know the polynomial $f(x)$</strong>.
And to know the polynomial $f(x)$, you <strong>need to know at least $T$ shares</strong>.
Otherwise, you <strong>can&rsquo;t reconstruct the polynomial and hence the secret</strong>.</p>
<p>In this setup we generate addresses from the extended public key (xpub) of a Bitcoin wallet that has the private key $k$.
Then, we split the private key into shares and distribute them to different people.
Only if at least $T$ people come together, they can reconstruct the private key and spend the funds.</p>
<h2 id="rotating-shares">Rotating Shares</h2>
<p>Note that there&rsquo;s nothing special about the points</p>
<ul>
<li>$(-2, f(-2))$</li>
<li>$(-1, f(-1))$</li>
<li>$(\frac{1}{2}, f(\frac{1}{2}))$</li>
<li>$(1, f(1))$</li>
<li>$(2, f(2))$</li>
</ul>
<p>that we&rsquo;ve used in the previous example.
You could have chosen <strong>any other $N$ points and the polynomial would still be the same</strong>.</p>
<p>Suppose now that your share buddy has lost his share.
Then, the participants can get together and <strong>generate a new polynomial evaluation at any point $n \notin \{ -2, -1, \frac{1}{2}, 1, 2 \}$</strong>.</p>
<p>This is exactly what the image below shows:</p>
<figure>
    <img loading="lazy" src="shamir_alternate_single.svg#center"
         alt="Shamir&#39;s Secret Sharing with N=5 and T=4" width="600"/> <figcaption>
            Shamir&#39;s Secret Sharing N=5 and T=4
        </figcaption>
</figure>

<p>Here we&rsquo;ve replaced the point $(-2, f(-2))$ with the point $(3, f(3))$.
We also assume that the point $(-2, f(-2))$ is lost.
The <strong>polynomial is still the same</strong>, and the secret can still be reconstructed if at least $T$ shares are combined.</p>
<p>We can also <strong>rotate all the shares</strong>.
This is shown in the image below:</p>
<figure>
    <img loading="lazy" src="shamir_alternate_multiple.svg#center"
         alt="Shamir&#39;s Secret Sharing with N=5 and T=4" width="600"/> <figcaption>
            Shamir&#39;s Secret Sharing N=5 and T=4
        </figcaption>
</figure>

<p>Here <strong>all previous points have been replaced by new points</strong>.</p>
<h2 id="the-polynomial-king">The Polynomial King</h2>
<blockquote>
<p>I am the <a href="https://youtu.be/ashTaoGrR2o?t=642"><del>Lizard</del> Polynomial King, I can do anything!</a></p>
<p>Jim Morrison</p>
</blockquote>
<p>In the end <strong>if you somehow know the polynomial $f(x)$, you can do anything</strong>.
You can rug-pull all you share buddies and take all the funds.</p>
<p>There are several ways that a malicious actor could learn the polynomial.
For example, if the shares are generated in a predictable way, an attacker could guess the polynomial.
Or, during the reconstruction phase, an attacker could learn the polynomial by observing the shares.
Additionally, during a distributed share generation, an attacker could disrupt the process and force the participants to reveal their shares<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In this post, <strong>we&rsquo;ve seen how polynomial interpolation can be used to split a secret into multiple shares</strong>.
We&rsquo;ve also seen how the <strong>secret can be reconstructed if a certain number of shares are combined</strong>.
This is the basic idea behind <strong>Shamir&rsquo;s Secret Sharing (SSS)</strong>.</p>
<p>Note that the devil is in the details.
A lot of the complexities of SSS come from the <strong>details of how the shares are generated and how the secret is reconstructed</strong>.
There are <strong>several types of attacks that can be done by a malicious actor</strong>.
Especially during the share generation and reconstruction phases.</p>
<p>The intent of this blog post is to show how <strong>elegant, simple and powerful the idea behind SSS is</strong>.</p>
<h2 id="license">License</h2>
<p>This post is licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International</a>.</p>
<p><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img loading="lazy" src="https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png" alt="CC BY-NC-SA 4.0"  />
</a></p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>and steams from the <a href="https://en.wikipedia.org/wiki/Lagrange_polynomial">Lagrange interpolation</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>or force them to reuse nonces. Then, &ldquo;poof&rdquo;, private keys are gone.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    <item>
      <title>Seed Phrases and Entropy</title>
      <link>https://storopoli.io/2024-02-11-mnemonic/</link>
      <pubDate>Sun, 11 Feb 2024 15:59:02 +0000</pubDate>
      <guid>https://storopoli.io/2024-02-11-mnemonic/</guid>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;password_strength.png#center&#34; alt=&#34;Password Meme&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Warning: This post has &lt;a href=&#34;https://katex.org/&#34;&gt;KaTeX&lt;/a&gt; enabled,
so if you want to view the rendered math formulas,
you&amp;rsquo;ll have to unfortunately enable JavaScript.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this post, let&amp;rsquo;s dive into a topic that is very important for anyone who uses the internet: &lt;strong&gt;passwords&lt;/strong&gt;.
We&amp;rsquo;ll cover what the hell is &lt;strong&gt;Entropy&lt;/strong&gt;,
good &lt;strong&gt;password practices&lt;/strong&gt;,
and how it relates to &lt;strong&gt;Bitcoin &amp;ldquo;seed phrases&amp;rdquo;&lt;/strong&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h2 id=&#34;entropy&#34;&gt;Entropy&lt;/h2&gt;
&lt;p&gt;Before we go into passwords,
I&amp;rsquo;ll introduce the concept of &lt;strong&gt;&lt;em&gt;Entropy&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p><img loading="lazy" src="password_strength.png#center" alt="Password Meme"  />
</p>
<blockquote>
<p>Warning: This post has <a href="https://katex.org/">KaTeX</a> enabled,
so if you want to view the rendered math formulas,
you&rsquo;ll have to unfortunately enable JavaScript.</p>
</blockquote>
<p>In this post, let&rsquo;s dive into a topic that is very important for anyone who uses the internet: <strong>passwords</strong>.
We&rsquo;ll cover what the hell is <strong>Entropy</strong>,
good <strong>password practices</strong>,
and how it relates to <strong>Bitcoin &ldquo;seed phrases&rdquo;</strong><sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<h2 id="entropy">Entropy</h2>
<p>Before we go into passwords,
I&rsquo;ll introduce the concept of <strong><em>Entropy</em></strong>.</p>
<p><a href="https://en.wikipedia.org/wiki/Entropy">Entropy</a>
is a measure of the <strong>amount of disorder in a system</strong>.
It has its origins in <strong>Thermodynamics</strong>,
where it&rsquo;s used to measure the amount of energy in a system that is not available to do work.</p>
<p>The etymology of the word &ldquo;Entropy&rdquo; is after the Greek word for &ldquo;transformation&rdquo;.</p>
<p>It was given a proper statistical definition by <a href="https://en.wikipedia.org/wiki/Ludwig_Boltzmann">Ludwig Boltzmann</a> in 1870s.
while establishing the field of <a href="https://en.wikipedia.org/wiki/Statistical_dynamics">Statistical Dynamics</a>,
a field of physics that studies the behavior of large collections of particles.</p>
<figure>
    <img loading="lazy" src="boltzmann.jpg#center"
         alt="Ludwig Boltzmann" width="300"/> <figcaption>
            Ludwig Boltzmann
        </figcaption>
</figure>

<p>In the context of Statistical Dynamics,
<strong>Entropy is a measure of the number of ways a system can be arranged</strong>.
The more ways a system can be arranged,
the higher its Entropy.
Specifically, <strong>Entropy is a logarithmic measure of the number of system states with significant probability of being occupied</strong>:</p>
<p>$$S = -k \cdot \sum_i p_i \ln p_i$$</p>
<p>Where:</p>
<ul>
<li>$S$: Entropy.</li>
<li>$k$: Boltzmann&rsquo;s constant, a physical constant that relates temperature to energy.</li>
<li>$p_i$: probability of the system being in state $i$.</li>
</ul>
<p>In this formula, if all states are equally likely,
i.e $p_i = \frac{1}{N}$,
where $N$ is the number of states,
then the entropy is maximized.
You can see this since a probability $p$ is a real number between 0 and 1,
and as $N$ approaches infinity,
the sum of the logarithms approaches negative infinity.
Then, multiplying by $-k$ yields positive infinity.</p>
<h3 id="how-the-hell-physics-came-to-passwords">How the hell Physics came to Passwords?</h3>
<p>There&rsquo;s once a great men called <a href="https://en.wikipedia.org/wiki/Claude_Shannon">Claude Shannon</a>,
who single-handedly founded the field of <a href="https://en.wikipedia.org/wiki/Information_theory"><strong>Information Theory</strong></a>,
invented the concept of a <a href="https://en.wikipedia.org/wiki/Bit"><strong>Bit</strong></a>,
and was the first to think about Boolean algebra in the context of electrical circuits.
He laid the foundation for the <a href="https://en.wikipedia.org/wiki/Digital_Revolution"><strong>Digital Revolution</strong></a>.</p>
<p>If you are happy using your smartphone, laptop, or any other digital device,
in you high speed fiber internet connection,
through a wireless router to send cats pictures to your friends,
then you should thank Claude Shannon.</p>
<figure>
    <img loading="lazy" src="shannon.jpg#center"
         alt="Claude Shannon" width="300"/> <figcaption>
            Claude Shannon
        </figcaption>
</figure>

<p>He was trying to find a formula to quantify the amount of information in a message.
He wanted three things:</p>
<ol>
<li>The measure should be a <strong>function of the probability of the message</strong>.
Messages that are more likely should have less information.</li>
<li>The measure should be <strong>additive</strong>.
The information in a message should be the sum of the information in its parts.</li>
<li>The measure should be <strong>continuous</strong>.
Small changes in the message should result in small changes in the measure.</li>
</ol>
<p>He pretty much found that the formula for Entropy in statistical mechanics
was a good measure of information.
He called it <em>Entropy</em> to honor Boltzmann&rsquo;s work.
To differentiate it from the Statistical Dynamics&rsquo; Entropy,
he changed the letter to $H$,
in honor of <a href="https://en.wikipedia.org/wiki/H-theorem">Boltzmann&rsquo;s $H$-theorem</a>.
So the formula for the Entropy of a message is:</p>
<p>$$H(X) = −\Sigma_{x \in X} P(x_i​) \log ​P(x_i​)$$</p>
<p>Where:</p>
<ul>
<li>$X$: random discrete variable.</li>
<li>$H(X)$: Entropy of $X$</li>
<li>$P(x_i)$: probability of the random variable $X$ taking the value $x_i$.
Also known as the probability mass function (PMF) of the discrete random variable $X$.</li>
<li>$\log$: base 2 logarithm, to measure the Entropy in bits.</li>
</ul>
<p>In information theory,
the <strong>Entropy of a random variable is the average level of &ldquo;information&rdquo;, &ldquo;surprise&rdquo;,
or &ldquo;uncertainty&rdquo; inherent to the variable&rsquo;s possible outcomes</strong><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>Let&rsquo;s take the simple example of a fair coin.
The Entropy of the random variable $X$ that represents the outcome of a fair coin flip is:</p>
<p>$$H(X) = −\Sigma_{x \in X} P(x_i​) \log ​P(x_i​) = -\left(\frac{1}{2} \log \frac{1}{2} + \frac{1}{2} \log \frac{1}{2}\right) = 1 \text{ bit}$$</p>
<p>So the outcome of a fair coin flip has 1 bit of Entropy.
This means that the outcome of a fair coin flip has 1 bit of information,
or 1 bit of uncertainty.
Once the message is received,
that the coin flip was heads or tails,
the receiver has 1 bit of information about the outcome.</p>
<p>Alternatively, we only need 1 bit to encode the outcome of a fair coin flip.
Hence, there&rsquo;s a connection between Entropy, search space, and information.</p>
<p>Another good example is the outcome of a fair 6-sided die.
The Entropy of the random variable $X$ that represents the outcome of a fair 6-sided die is:</p>
<p>$$H(X) = −\Sigma_{x \in X} P(x_i​) \log ​P(x_i​) = - \sum_{i=1}^6\left(\frac{1}{6} * \log \frac{1}{6} \right) \approx 2.58 \text{ bits}$$</p>
<p>This means that the outcome of a fair 6-sided die has 2.58 bits of Entropy.
we need $\operatorname{ceil}(2.58) = 3$ bits to encode the outcome of a fair 6-sided die.</p>
<h3 id="entropy-and-passwords">Entropy and Passwords</h3>
<p>Ok now we come full circle.
Let&rsquo;s talk, finally, about passwords.</p>
<p>In the context of passwords, <strong>Entropy</strong> is a measure of how unpredictable a password is.
The higher the Entropy, the harder it is to guess the password.
The Entropy of a password is measured in bits,
and it&rsquo;s calculated using the formula:</p>
<p>$$H = L \cdot \log_2(N)$$</p>
<p>Where:</p>
<ul>
<li>$H$: Entropy in bits</li>
<li>$N$: number of possible characters in the password</li>
<li>$L$: length of the password</li>
<li>$\log_2$:​ (N) calculates how many bits are needed to represent each character from the set.</li>
</ul>
<p>For example,
if we have a password with 8 characters and each character can be any of the 26 lowercase letters,
the standard english alphabet,
the Entropy would be:</p>
<p>$$H = 8 \cdot \log_2(26) \approx 37.6 \text{ bits}$$</p>
<p>This means that an attacker would need to try $2^{37.6} \approx 2.01 \cdot 10^{11}$ combinations<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> to guess the password.</p>
<p>If the password were to include uppercase letters, numbers, and symbols
(let&rsquo;s assume 95 possible characters in total),
the Entropy for an 8-character password would be:</p>
<p>$$H = 8 \cdot \log_2(95) \approx 52.6 \text{ bits}$$</p>
<p>This means that an attacker would need to try $2^{52.6} \approx 6.8 \cdot 10^{15}$ combinations to guess the password.</p>
<p>This sounds a lot but it&rsquo;s not that much.</p>
<p>For the calculations below, we&rsquo;ll assume that the attacker now your dictionary set,
i.e. the set of characters you use to create your password,
and the password length.</p>
<p>If an attacker get a hold of an NVIDIA RTX 4090,
MSRP USD 1,599, which can do
<a href="https://www.tomshardware.com/news/rtx-4090-password-cracking-comparison">300 GH/s (300,000,000,000 hashes/second)</a>,
i.e. $3 \cdot 10^{11}$ hashes/second,
it would take:</p>
<ol>
<li>8-length lowercase-only password:</li>
</ol>
<p>$$\frac{2.01 \cdot 10^{11}}{3 \cdot 10^{11}} \approx 0.67 \text{ seconds}$$</p>
<ol>
<li>8-length password with uppercase letters, numbers, and symbols:</li>
</ol>
<p>$$\frac{6.8 \cdot 10^{15}}{3 \cdot 10^{11}} \approx 22114 \text{ seconds} \approx 6.14 \text{ hours}$$</p>
<p>So, the first password would be cracked in less than a second,
while the second would take a few hours.
This with just one 1.5k USD GPU.</p>
<h2 id="bitcoin-seed-phrases">Bitcoin Seed Phrases</h2>
<p>Now that we understand Entropy and how it relates to passwords,
let&rsquo;s talk about bitcoin seed phrases<sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>Remember that our private key is a big-fucking number?
If not, check my <a href="../2024-02-05-crypto-basics/">post on cryptographics basics</a>.</p>
<p><a href="https://github.com/bitcoin/bips/blob/master/bip-0039.mediawiki">BIP-39</a>
specifies how to use easy-to-remember seed phrases to store and recover
private keys.
The <a href="https://github.com/bitcoin/bips/blob/master/bip-0039/english.txt">wordlist</a>
adheres to the following principles:</p>
<ol>
<li><strong>smart selection of words</strong>:
the wordlist is created in such a way that it&rsquo;s enough to type the first four
letters to unambiguously identify the word.</li>
<li><strong>similar words avoided</strong>:
word pairs like &ldquo;build&rdquo; and &ldquo;built&rdquo;, &ldquo;woman&rdquo; and &ldquo;women&rdquo;, or &ldquo;quick&rdquo; and &ldquo;quickly&rdquo;
not only make remembering the sentence difficult but are also more error
prone and more difficult to guess.</li>
</ol>
<p>Here is a simple 7-word seed phrase: <code>brave sadness grocery churn wet mammal tube</code>.
Surprisingly enough, this badboy here gives you $77$ bits of Entropy,
while also being easy to remember.
This is due to the fact that the wordlist has 2048 words,
so each word gives you $\log_2(2048) = 11$ bits of Entropy<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>.</p>
<p>There&rsquo;s a minor caveat to cover here.
The last word in the seed phrase is a checksum,
which is used to verify that the phrase is valid.</p>
<p>So, if you have a 12-word seed phrase,
you have $11 \cdot 11 = 121$ bits of Entropy.
And for a 24-word seed phrase,
you have $23 \cdot 11 = 253$ bits of Entropy.</p>
<p>The National Institute of Standards and Technology (NIST) recommends a
<a href="https://crypto.stackexchange.com/a/87059">minimum of 112 bits of Entropy for all things cryptographic</a>.
And Bitcoin has a <a href="https://bitcoin.stackexchange.com/a/118929">minimum of 128 bits of Entropy</a>.</p>
<p>Depending on your threat model,
<a href="https://www.nytimes.com/2013/08/18/magazine/laura-poitras-snowden.html">&ldquo;Assume that your adversary is capable of a trillion guesses per second&rdquo;</a>,
it can take a few years to crack a 121-bit Entropy seed phrase:</p>
<p>$$\frac{2^{121}}{10^{12}} \approx 2.66 \cdot 10^{24} \text{ seconds} \approx 3.08 \cdot 10^{19} \text{ days} \approx 8.43 \cdot 10^{16} \text{ years}$$</p>
<p>That&rsquo;s a lot of years.
Now for a 253-bit Entropy seed phrase:</p>
<p>$$\frac{2^{253}}{10^{12}} \approx 1.45 \cdot 10^{64} \text{ seconds} \approx 1.68 \cdot 10^{59} \text{ days} \approx 4.59 \cdot 10^{56} \text{ years}$$</p>
<p>That&rsquo;s another huge number of years.</p>
<h2 id="seed-phrases-and-passwords">Seed Phrases and Passwords</h2>
<p>You can also use a seed phrase as a password.
The bonus point is that you don&rsquo;t need to use the last word as a checksum,
so you get 11 bits of Entropy free, compared to a Bitcoin seed phrase.</p>
<p>Remember the 7-words badboy seed phrase we generated earlier?
<code>brave sadness grocery churn wet mammal tube</code>.</p>
<p>It has $66$ bits of Entropy.
This would take, assuming
<a href="https://www.nytimes.com/2013/08/18/magazine/laura-poitras-snowden.html">&ldquo;that your adversary is capable of a trillion guesses per second&rdquo;</a>:</p>
<p>$$\frac{2^{77}}{10^{12}} \approx 1.51 \cdot 10^{11} \text{ seconds} \approx 1.75 \cdot 10^{6} \text{ days} \approx 4.79 \cdot 10^{3} \text{ years}$$</p>
<p>That&rsquo;s why tons of people use seed phrases as passwords.
Even if you know the dictionary set and the length of the password,
i.e. the number of words in the seed phrase,
it would take a lot of years to crack it.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Entropy is a measure of the amount of disorder in a system.
In the context of passwords, it&rsquo;s a measure of how unpredictable a password is.
The higher the Entropy, the harder it is to guess the password.</p>
<p>Bitcoin seed phrases are a great way to store and recover private keys.
They are easy to remember and have a high amount of Entropy.
You can even use a seed phrase as a password.</p>
<p>Even it your attacker is capable of a trillion guesses per second,
like the <a href="https://www.nytimes.com/2013/08/18/magazine/laura-poitras-snowden.html">NSA</a>,
it would take them a lot of years to crack even a 7-word seed phrase.</p>
<p>If you want to generate a seed phrase,
you can use <a href="https://keepassxc.org/">KeePassXC</a>,
which is a great open-source <strong><em>offline</em></strong> password manager that supports seed phrases<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>.</p>
<h2 id="license">License</h2>
<p>This post is licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International</a>.</p>
<p><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img loading="lazy" src="https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png" alt="CC BY-NC-SA 4.0"  />
</a></p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>seed phrases are technically called &ldquo;mnemonic phrases&rdquo;,
but I&rsquo;ll use the term &ldquo;seed phrases&rdquo; for the rest of the post.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>there is a Bayesian argument about
the use of priors that should adhere to the
<a href="https://en.wikipedia.org/wiki/Principle_of_maximum_entropy">Principle of Maximal Entropy</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>technically, we need to divide the number of combinations by 2,
since we are assuming that the attacker is using a brute-force attack,
which means that the attacker is trying all possible combinations,
and the password could be at the beginning or at the end of the search space.
This is called the <a href="https://en.wikipedia.org/wiki/Birthday_problem">birthday paradox</a>,
and it assumes that the password is uniformly distributed in the search space.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>remember that $2^{11} = 2048$.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>technically, KeePassXC uses the <a href="https://www.eff.org/files/2016/07/18/eff_large_wordlist.txt">EFF wordlist</a>,
which has 7,776 words, so each word gives you $\log_2(7776) \approx 12.9$ bits of Entropy.
They were created to be easy to use with 6-sided dice.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    <item>
      <title>Cryptography Basics</title>
      <link>https://storopoli.io/2024-02-05-crypto-basics/</link>
      <pubDate>Mon, 05 Feb 2024 18:53:28 -0300</pubDate>
      <guid>https://storopoli.io/2024-02-05-crypto-basics/</guid>
      <description>&lt;figure&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;euclid.webp&#34;
         alt=&#34;Euclid&amp;#39;s one-way function&#34;/&gt; &lt;figcaption&gt;
            &lt;p&gt;Euclid&amp;rsquo;s one-way function&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;blockquote&gt;
&lt;p&gt;Warning: This post has &lt;a href=&#34;https://katex.org/&#34;&gt;KaTeX&lt;/a&gt; enabled,
so if you want to view the rendered math formulas,
you&amp;rsquo;ll have to unfortunately enable JavaScript.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is the companion post to the &lt;a href=&#34;https://github.com/storopoli/cryptography-workshop&#34;&gt;cryptography workshop&lt;/a&gt;
that I gave at a local BitDevs.
Let&amp;rsquo;s explore the basics of cryptography.
We&amp;rsquo;ll go through the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One-way functions&lt;/li&gt;
&lt;li&gt;Hash functions&lt;/li&gt;
&lt;li&gt;Public-key cryptography&lt;/li&gt;
&lt;li&gt;DSA&lt;/li&gt;
&lt;li&gt;Schnorr&lt;/li&gt;
&lt;li&gt;Why we don&amp;rsquo;t reuse nonces?&lt;/li&gt;
&lt;li&gt;Why we can combine Schnorr Signatures and not DSA?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;one-way-functions&#34;&gt;One-way functions&lt;/h2&gt;
&lt;p&gt;A one-way function is a &lt;strong&gt;function that is easy to compute on every input,
but hard to invert given the image&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; of a random input&lt;/strong&gt;.
For example, imagine an omelet.
It&amp;rsquo;s easy to make an omelet from eggs,
but it&amp;rsquo;s hard to make eggs from an omelet.
In a sense we can say that the function $\text{omelet}$ is a one-way function&lt;/p&gt;</description>
      <content:encoded><![CDATA[<figure>
    <img loading="lazy" src="euclid.webp"
         alt="Euclid&#39;s one-way function"/> <figcaption>
            <p>Euclid&rsquo;s one-way function</p>
        </figcaption>
</figure>

<blockquote>
<p>Warning: This post has <a href="https://katex.org/">KaTeX</a> enabled,
so if you want to view the rendered math formulas,
you&rsquo;ll have to unfortunately enable JavaScript.</p>
</blockquote>
<p>This is the companion post to the <a href="https://github.com/storopoli/cryptography-workshop">cryptography workshop</a>
that I gave at a local BitDevs.
Let&rsquo;s explore the basics of cryptography.
We&rsquo;ll go through the following topics:</p>
<ul>
<li>One-way functions</li>
<li>Hash functions</li>
<li>Public-key cryptography</li>
<li>DSA</li>
<li>Schnorr</li>
<li>Why we don&rsquo;t reuse nonces?</li>
<li>Why we can combine Schnorr Signatures and not DSA?</li>
</ul>
<h2 id="one-way-functions">One-way functions</h2>
<p>A one-way function is a <strong>function that is easy to compute on every input,
but hard to invert given the image<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> of a random input</strong>.
For example, imagine an omelet.
It&rsquo;s easy to make an omelet from eggs,
but it&rsquo;s hard to make eggs from an omelet.
In a sense we can say that the function $\text{omelet}$ is a one-way function</p>
<p>$$\text{omelet}^{-1}(x) = \ldots$$</p>
<p>That is, we don&rsquo;t know how to invert the function $\text{omelet}$ to get the original eggs back.
Or, even better, <strong>the benefit we get from reverting the omelet to eggs is not worth the effort,
either in time or money</strong>.</p>
<p>Not all functions are one-way functions.
The exponential function, $f(x) = e^x$, is not a one-way function.
It is easy to undo the exponential function by taking the natural logarithm,</p>
<p>$$f^{-1}(x) = \ln(x)$$</p>
<p>To showcase one-way functions, let&rsquo;s take a look at the following example.
Let&rsquo;s play around with some numbers.
Not any kind of numbers, but very special numbers called <strong>primes</strong>.
A prime number is a natural number greater than 1 that has no positive divisors other than 1 and itself.</p>
<p>If I give you a big number $n$ and ask you to find its prime factors,
and point a gun at your head,
you&rsquo;ll pretty much screwed.
There&rsquo;s no known efficient algorithm<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> to factorize a big number into its prime factors.
You&rsquo;ll be forced to test all numbers from 2 to $\sqrt{n}$ to see if they divide $n$.</p>
<p>Here&rsquo;s a number:</p>
<p>$$90809$$</p>
<p>What are its prime factors?
It&rsquo;s $1279 \cdot 71$.
Easy to check, right?
Hard to find.
That&rsquo;s because prime factorization, if you choose a fucking big number, is a one-way function.</p>
<h2 id="hash-functions">Hash Functions</h2>
<p>Let&rsquo;s spice things up.
There is a special class of one-way functions called <strong>hash functions</strong>.</p>
<p><strong>A hash function is any function that can be used to map data of arbitrary size to fixed-size values</strong>.</p>
<p>But we are most interested in <strong><em>cryptographic</em> hash functions</strong>,
which are hash functions that have statistical properties desirable for cryptographic application:</p>
<ul>
<li><strong>One-way function</strong>: easy to compute $y = f(x)$, hard as fuck to do the opposite, $x = f^{-1}(y)$.</li>
<li><strong>Deterministic</strong>: given a function that maps elements from set $X$ to set $Y$, $f: X \to Y$,
for every $x \in X$ there&rsquo;s <em>at least one</em> $y \in Y$<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.
This means that if I give you a certain input, it will always map to the same output.
It is deterministic.</li>
<li><strong>Collision resistance</strong>: the possible values of $f: X \to Y$ follows a uniform distribution,
that is, given the size of the set $Y$,
it is hard to find two $x_1, x_2 \in X$ that have the same $y \in Y$ value<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>.
This property is really important because if an attacker wants to brute-force the
hash function, there&rsquo;s no option than searching uniformly across the whole possible
space of possible values that the hash function outputs<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>.</li>
</ul>
<p>These properties make enable cryptographic hash functions to be used in a wide range of applications,
including but not limited to:</p>
<ul>
<li>
<p><strong>Digital signatures</strong>: Hash functions are used to create a digest of the message to be signed.
The digital signature is then generated using the hash, rather than the message itself,
to ensure integrity and non-repudiation.</p>
</li>
<li>
<p><strong>Password hashing</strong>: Storing passwords as hash values instead of plain text.
Even if the hash values are exposed,
the original passwords remain secure due to the pre-image resistance property.</p>
</li>
<li>
<p><strong>Blockchain and cryptocurrency</strong>: Hash functions are used to maintain the integrity of the blockchain.
Each block contains the hash of the previous block, creating a secure link.
Cryptographic hashes also underpin various aspects of cryptocurrency transactions.</p>
</li>
<li>
<p><strong>Data integrity verification</strong>: Hash functions are used to ensure that files, messages,
or data blocks have not been altered.
By comparing hash values computed before and after transmission or storage,
any changes in the data can be detected.</p>
</li>
</ul>
<p>We&rsquo;ll cover just the <strong>digital signatures</strong> part in this post.</p>
<h3 id="sha-2-and-its-variants">SHA-2 and its variants</h3>
<p>The Secure Hash Algorithm 2 (SHA-2) is a set of cryptographic hash functions designed by the National Security Agency (NSA).
It was first published in 2001.</p>
<p>It is composed of six hash functions with digests that are 224, 256, 384, 512, 512/224, and 512/256 bits long:</p>
<ul>
<li><code>SHA-224</code></li>
<li><code>SHA-256</code></li>
<li><code>SHA-384</code></li>
<li><code>SHA-512</code></li>
<li><code>SHA-512/224</code></li>
<li><code>SHA-512/256</code></li>
</ul>
<p>Amongst these, let&rsquo;s focus on SHA-256, which is the most widely used while also being notoriously adopted by bitcoin.</p>
<p>SHA-256 does not have any known vulnerabilities and is considered secure.
It comprises of 32-bit words and operates on 64-byte blocks.
The algorithm does 64 rounds of the following operations:</p>
<ul>
<li><code>AND</code>: bitwise boolean AND</li>
<li><code>XOR</code>: bitwise boolean XOR</li>
<li><code>OR</code>: bitwise boolean OR</li>
<li><code>ROT</code>: right rotation bit shift</li>
<li><code>ADD</code>: addition modulo $2^{32}$</li>
</ul>
<p>You can check <a href="https://en.wikipedia.org/wiki/SHA-2#Pseudocode">SHA-256 Pseudocode on Wikipedia</a>.
It really scrambles the input message in a way that is very hard to reverse.</p>
<p>These operations are non-linear and very difficult to keep track of.
In other words, you can&rsquo;t reverse-engineer the hash to find the original message.
There&rsquo;s no <a href="https://en.wikipedia.org/wiki/Automatic_differentiation">&ldquo;autodiff&rdquo;</a> for hash functions.</p>
<p>Since it is a cryptographic hash function,
if we change just one bit of the input,
the output will be completely different.
Check this example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">$ <span class="nb">echo</span> <span class="s2">&#34;The quick brown fox jumps over the lazy dog&#34;</span> <span class="p">|</span> shasum -a <span class="m">256</span>
</span></span><span class="line"><span class="cl">c03905fcdab297513a620ec81ed46ca44ddb62d41cbbd83eb4a5a3592be26a69  -
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ <span class="nb">echo</span> <span class="s2">&#34;The quick brown fox jumps over the lazy dog.&#34;</span> <span class="p">|</span> shasum -a <span class="m">256</span>
</span></span><span class="line"><span class="cl">b47cc0f104b62d4c7c30bcd68fd8e67613e287dc4ad8c310ef10cbadea9c4380  -
</span></span></code></pre></div><p>Here we are only adding a period at the end of the sentence,
and the hash is completely different.
This is due to the property of collision resistance that we mentioned earlier.</p>
<h2 id="fields">Fields</h2>
<p>Before we dive into public-key cryptography,
we need a brief interlude on fields.</p>
<p><strong><a href="https://en.wikipedia.org/wiki/Field_(mathematics)">Fields</a> are sets with two binary operations,
called addition $+$ and multiplication $\times$</strong>.
We write</p>
<p>$$F = (F, +, \times)$$</p>
<p>to denote a field,
where $F$ is the set, $+$ is the addition operation,
and $\times$ is the multiplication operation.</p>
<p>Addition and multiplication behave similar to the addition and multiplication of real numbers.
For example, addition is <strong>commutative</strong> and <strong>associative</strong></p>
<p>$$a + b = b + a,$$</p>
<p>and multiplication is <strong>distributive</strong></p>
<p>$$a \times (b + c) = a \times b + a \times c.$$</p>
<p>Also, there are two special elements in the field,
called the <strong>additive identity</strong> $-a$ and the <strong>multiplicative identity</strong> $a^{-1}$,
such that</p>
<p>$$a + (-a) = I,$$</p>
<p>and</p>
<p>$$a \times a^{-1} = I,$$</p>
<p>where $I$ is the identity element.</p>
<p>Note that this allows us to define <strong>subtraction</strong></p>
<p>$$a - b = a + (-b),$$</p>
<p>and <strong>division</strong></p>
<p>$$a \div b = a \times b^{-1}.$$</p>
<h3 id="finite-fields">Finite Fields</h3>
<p>Now we are ready for finite fields.
A <a href="https://en.wikipedia.org/wiki/Finite_field"><em>finite field</em></a>, also called a Galois field (in honor of Évariste Galois),
is a <strong>field with a finite number of elements.
As with any field, a finite field is a set on which the operations of multiplication,
addition, subtraction and division are defined and satisfy the rules above for fields</strong>.</p>
<p>Finite fields is a very rich topic in mathematics,
and there are many ways to construct them.
The easiest way to construct a finite field is to take the <strong>integers modulo a prime number $p$</strong>.
For example $\mathbb{Z}_5$ is a finite field with 5 elements:</p>
<p>$$\mathbb{Z}_5 = \lbrace 0, 1, 2, 3, 4 \rbrace.$$</p>
<p>In general, $\mathbb{Z}_n$ is a finite field with $n$ elements:</p>
<p>$$\mathbb{Z}_n = \lbrace 0, 1, 2, \ldots, n - 1 \rbrace.$$</p>
<p><strong>The number of elements in a finite field is called the <em>order</em> of the field</strong>.
The order of a finite field is <strong>always a prime number $p$</strong>.
The $\mathbb{Z}_5$ example above is a finite field of order 5.
However, $\mathbb{Z}_4$ is not a finite field,
because 4 is not a prime number, but rather a composite number.</p>
<p>$$4 = 2 \times 2.$$</p>
<p>And we can write $\mathbb{Z}_4$ as</p>
<p>$$\mathbb{Z}_4 = 2 \times \mathbb{Z}_2.$$</p>
<p>This means that every element in $a \in \mathbb{Z}_4$ can be written as</p>
<p>$$a = 2 \times b,$$</p>
<p>where $b$ is an element in $\mathbb{Z}_2$.</p>
<p>Hence, not every element of $\mathbb{Z}_4$ is unique, and they are equivalent to the elements in $\mathbb{Z}_2$.</p>
<p>In general if $n$ is a composite number,
then $\mathbb{Z}_n$ is not a finite field.
However, if $n = r \times s$ where $r$ and $s$ are prime numbers,
and $r &lt; s$,
then $\mathbb{Z}_n$ is a finite field of order $r$.</p>
<h4 id="operations-in-finite-fields">Operations in Finite Fields</h4>
<p><strong>Addition</strong> in finite fields is defined as the remainder of the sum of two elements modulo the order of the
field.</p>
<p>For example, in $\mathbb{Z}_3$,</p>
<p>$$1 + 2 = 3 \mod 3 = 0.$$</p>
<p>We can also define subtraction in finite fields as the remainder of the difference of two elements modulo the order of the field.</p>
<p>For example, in $\mathbb{Z}_3$,</p>
<p>$$1 - 2 = -1 \mod 3 = 2.$$</p>
<p>Multiplication in finite fields can be written as multiple additions.
For example, in $\mathbb{Z}_3$,</p>
<p>$$2 \times 2 = 2 + 2 = 4 \mod 3 = 1.$$</p>
<p>Exponentiation in finite fields can be written as multiple multiplications.
For example, in $\mathbb{Z}_3$,</p>
<p>$$2^2 = 2 \times 2 = 4 \mod 3 = 1.$$</p>
<p>As you can see addition, subtraction, and multiplication becomes linear operations.
This is very trivial for any finite field.</p>
<p>However, for division we are pretty much screwed.
It is really hard to find the multiplicative inverse of an element in a finite field.
For example, suppose that we have numbers $a,b$ in a very large finite field $\mathbb{Z}_p$,
such that</p>
<p>$$c = a \times b \mod p.$$</p>
<p>Then we can write division as</p>
<p>$$a = c \div b = c \times b^{-1} \mod p.$$</p>
<p>Now we need to find $b^{-1}$, which is the multiplicative inverse of $b$.
This is called the <a href="https://en.wikipedia.org/wiki/Discrete_logarithm"><strong><em>discrete logarithm problem</em></strong></a>.
Because we need to find $b^{-1}$ such that</p>
<p>$$b^{-1} = \log_b c \mod p.$$</p>
<p>Since this number is a discrete number and not a real number,
that&rsquo;s why it&rsquo;s called the discrete logarithm problem.</p>
<p>Good luck my friend, no efficient method is known for computing them in general.
You can try brute force, but that&rsquo;s not efficient.</p>
<h4 id="why-the-discrete-logarithm-problem-is-hard-as-fuck">Why the Discrete Logarithm Problem is Hard as Fuck</h4>
<p>To get a feeling why the discrete logarithm problem is difficult,
let&rsquo;s add one more concept to our bag of knowledge.
Every finite field has <em><strong>generators</strong></em>,
also known as <em><strong>primitive roots</strong></em>,
which is also a member of the group,
such that applying multiplication to this one single element
makes possible to generate the whole finite field.</p>
<p>Let&rsquo;s illustrate this with an example.
Below we have a table of all the results of the following operation</p>
<p>$$b^x \mod 7$$</p>
<p>for every possible value of $x$.
As you&rsquo;ve guessed right this is the $\mathbb{Z}_7$ finite field.</p>
<table>
  <thead>
      <tr>
          <th style="text-align: center">$b$</th>
          <th style="text-align: center">$b^1 \mod 7$</th>
          <th style="text-align: center">$b^2 \mod 7$</th>
          <th style="text-align: center">$b^3 \mod 7$</th>
          <th style="text-align: center">$b^4 \mod 7$</th>
          <th style="text-align: center">$b^5 \mod 7$</th>
          <th style="text-align: center">$b^6 \mod 7$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">$1$</td>
          <td style="text-align: center">$1$</td>
          <td style="text-align: center">$1$</td>
          <td style="text-align: center">$1$</td>
          <td style="text-align: center">$1$</td>
          <td style="text-align: center">$1$</td>
          <td style="text-align: center">$1$</td>
      </tr>
      <tr>
          <td style="text-align: center">$2$</td>
          <td style="text-align: center">$2$</td>
          <td style="text-align: center">$4$</td>
          <td style="text-align: center">$1$</td>
          <td style="text-align: center">$2$</td>
          <td style="text-align: center">$4$</td>
          <td style="text-align: center">$1$</td>
      </tr>
      <tr>
          <td style="text-align: center">$3$</td>
          <td style="text-align: center">$3$</td>
          <td style="text-align: center">$2$</td>
          <td style="text-align: center">$6$</td>
          <td style="text-align: center">$4$</td>
          <td style="text-align: center">$5$</td>
          <td style="text-align: center">$1$</td>
      </tr>
      <tr>
          <td style="text-align: center">$4$</td>
          <td style="text-align: center">$4$</td>
          <td style="text-align: center">$2$</td>
          <td style="text-align: center">$1$</td>
          <td style="text-align: center">$4$</td>
          <td style="text-align: center">$2$</td>
          <td style="text-align: center">$1$</td>
      </tr>
      <tr>
          <td style="text-align: center">$5$</td>
          <td style="text-align: center">$5$</td>
          <td style="text-align: center">$4$</td>
          <td style="text-align: center">$6$</td>
          <td style="text-align: center">$2$</td>
          <td style="text-align: center">$3$</td>
          <td style="text-align: center">$1$</td>
      </tr>
      <tr>
          <td style="text-align: center">$6$</td>
          <td style="text-align: center">$6$</td>
          <td style="text-align: center">$1$</td>
          <td style="text-align: center">$6$</td>
          <td style="text-align: center">$1$</td>
          <td style="text-align: center">$1$</td>
          <td style="text-align: center">$1$</td>
      </tr>
  </tbody>
</table>
<p>You see that something interesting is happening here.
For specific values of $b$, such as $b = 3$, and $b = 5$, we are able to <strong>generate the whole finite field</strong>.
Hence, say that $3$ and $5$ are <em><strong>generators</strong></em> or <em><strong>primitive roots</strong></em> of $\mathbb{Z}_7$.</p>
<p>Now suppose I ask you to find $x$ in the following equation</p>
<p>$$3^x \mod p = 11$$</p>
<p>where $p$ is a very large prime number.
Then you don&rsquo;t have any other option than brute forcing it.
<strong>You&rsquo;ll need to try each exponent $x \in \mathbb{Z}_p$ until you find the one that satisfies the equation</strong>.</p>
<p>Notice that this operation is very asymmetric.
It is very easy to compute $3^x \mod p$ for any $x$,
but it is very hard to find $x$ given $3^x \mod p$.</p>
<p>Now we are ready to dive into public-key cryptography.</p>
<h4 id="numerical-example-of-the-discrete-logarithm-problem">Numerical Example of the Discrete Logarithm Problem</h4>
<p>Let&rsquo;s illustrate the discrete logarithm problem with a numerical example.</p>
<ol>
<li><strong>Choose a prime number $p$</strong>. Let&rsquo;s pick $p = 17$.</li>
<li><strong>Choose a generator $g$ of the group</strong>.
For $p = 17$, we can choose $g = 3$ because $3$ is a primitive root of $\mathbb{Z}_{17}$.</li>
<li><strong>Choose an element $x$</strong>.
Let&rsquo;s pick $x = 15$.</li>
</ol>
<p>The discrete logarithm problem is to find $x$ given $g^x \mod p$.
So let&rsquo;s plug in the numbers; find $x$ in</p>
<p>$$3^x = 15 \mod 17 $$</p>
<p>Try to find it.
Good luck<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<h2 id="public-key-cryptography">Public-key cryptography</h2>
<p>Public-key cryptography, or asymmetric cryptography, is a cryptographic system that uses pairs of keys:
private and public.
The public key you can share with anyone,
but the private key you must keep secret.
The keys are related mathematically,
but it is computationally infeasible to derive the private key from the public key.
In other words, the public key is a one-way function of the private key.</p>
<p>Before we dive into the details of the public-key cryptography, and signing and verifying messages,
let me introduce some notation:</p>
<ul>
<li>$p$: big fucking huge prime number (4096 bits or more)</li>
<li>$\mathbb{Z}_p$: the finite field of order $p$</li>
<li>$g$: a generator of $\mathbb{Z}_p$</li>
<li>$S_k$: secret key, a random integer in the finite field $\mathbb{Z}_p$</li>
<li>$P_k$: public key derived by $P_k = g^{S_k}$</li>
</ul>
<p>If you know $S_k$ and $g$ (which is almost always part of the spec),
then it&rsquo;s easy to derive the $P_k$.
However, if you only know $g$ and $P_k$, good luck finding $S_k$.
It&rsquo;s the discrete log problem again.
And as long $p$ is HUGE you are pretty confident that no one will find your secret key
from your public key.</p>
<p>Now what we can do with these keys and big prime numbers?
We&rsquo;ll we can sign a message with our secret key and everyone can verify the authenticity of
the message using our public key.
The message in our case it is commonly a hash function of the &ldquo;original message&rdquo;.
Due to the collision resistance property, we can definitely assert that:</p>
<ol>
<li>the message has not been altered</li>
<li>the message was signed by the owner of the private key</li>
</ol>
<p>Fun fact, I once gave a recommendation letter to a very bright student,
that was only a plain text file signed with my private key.
I could rest assured that the letter was not altered,
and the student and other people could verify that I was the author of the letter.</p>
<p>Next, we&rsquo;ll dive into the details of the Digital Signature Algorithm (DSA)
and the Schnorr signature algorithm.</p>
<h2 id="dsa">DSA</h2>
<p>DSA stands for <a href="https://en.wikipedia.org/wiki/Digital_Signature_Algorithm">Digital Signature Algorithm</a>.
It was first proposed by the National Institute of Standards and Technology (NIST) in 1991.
Note that <a href="https://lwn.net/Articles/958048/">OpenSSH announced that DSA is scheduled for removal in 2025</a>.</p>
<p>Here&rsquo;s how you can sign a message using DSA:</p>
<ol>
<li>Choose two prime numbers $p, q$ such that $p - 1 \mod q = 0$ (e.g., 1279 and 71).</li>
<li>Choose your private key $S_k$ as a random integer $\in [1, q-1]$.</li>
<li>Choose a generator $g$.</li>
<li>Compute your public key $P_k$: $g^{S_k} \mod p$.</li>
<li>Choose your nonce $k$: as a random integer $\in [1, q-1]$.</li>
<li>Compute your &ldquo;public nonce&rdquo; $K$: $(g^k \mod p) \mod q$ (also known as $r$).</li>
<li>Get your message ($m$) through a cryptographic hash function $H$: $H(m)$.</li>
<li>Compute your signature $s$: $(k^{-1} (H(m) + S_k K)) \mod q$.</li>
<li>Send to your buddy $(p, q, g)$, $P_k$, and $(K, s)$.</li>
</ol>
<p>And here&rsquo;s how you can verify the signature:</p>
<ol>
<li>Compute $w = s^{-1} \mod q$.</li>
<li>Compute $u_1 = H{m} \cdot w \mod q$.</li>
<li>Compute $u_2 = K \cdot w \mod q$.</li>
<li>Compute $K^* = {g^{u_1} P^{u_2}_k \mod p} \mod q$.</li>
<li>Assert $K = K^*$.</li>
</ol>
<p>How this works?
Let&rsquo;s go through a proof of correctness.
I added some comments to every operation in parentheses to make it easier to follow.</p>
<ol>
<li>$s = k^{-1} \cdot {H + S_k K} \mod q$ ($\mod p$ and $H(m)$ implicit).</li>
<li>$k = s^{-1} \cdot {H + S_k K} \mod q$ (move $s$ to $k$).</li>
<li>$k = H \cdot s^{-1} + S_k K \cdot s^{-1} \mod q$ (distribute $s^{-1}$).</li>
<li>$k = H \cdot w + S_k K \cdot w \mod q$ ($w = s^{-1}$).</li>
<li>$g^k = g^{H \cdot w + S_k K \cdot w \mod q}$ (put $g$ in both sides).</li>
<li>$g^k = g^{H \cdot w \mod q} \cdot g^{S_k K \cdot w \mod q}$ (product of the exponents).</li>
<li>$g^k = g^{H \cdot w \mod q} \cdot P^{K \cdot w \mod q}_k$ ($P_k = g^{S_k}$).</li>
<li>$g^k = g^{u_1} \cdot P^{u_2}_k$ (replace $u_1$ and $u_2$).</li>
<li>$K = K^*$ (replace $K$ and $K^*$).</li>
</ol>
<p>There you go.
This attest that the signature is correct and the message was signed by the owner of the private key.</p>
<h2 id="schnorr">Schnorr</h2>
<p><a href="https://en.wikipedia.org/wiki/Schnorr_signature">Schnorr signature algorithm</a>
is a very similar algorithm to DSA.
It was proposed by Claus-Peter Schnorr in 1989.
It is considered to be more secure than DSA and is also more efficient.
The patent for Schnorr signatures expired in 2008,
just in time for Satoshi to include it in Bitcoin.
However, it was probably not included due to the fact that there wasn&rsquo;t
good battle-tested software implementations of it at the time.
However, it was added to Bitcoin in the Taproot upgrade<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>.</p>
<p>Schnorr is a marvelous algorithm.
It is so much simpler than DSA.
Here&rsquo;s how you sign a message using Schnorr:</p>
<ol>
<li>Choose a prime number $p$.</li>
<li>Choose your private key $S_k$ as a random integer $\in [1, p-1]$.</li>
<li>Choose a generator $g$.</li>
<li>Compute your public key $P_k$: $g^{S_k}$.</li>
<li>Choose your nonce $k$: as a random integer $\in [1, p-1]$.</li>
<li>Compute your &ldquo;public nonce&rdquo; $K$: $g^k \mod p$ (also known as $r$).</li>
<li>Get your message ($m$) through a cryptographic hash function $H$ concatenating with $K$: $e = H(K || m)$.</li>
<li>Compute your signature $s$: $k - S_k e$.</li>
<li>Send to your buddy $(p, g)$, $P_k$, and $(K, s)$.</li>
</ol>
<p>And here&rsquo;s how you can verify the signature:</p>
<ol>
<li>Compute $e = H(K || m)$.</li>
<li>Compute $K^* = g^s P_k^e$.</li>
<li>Compute $e^* = H(K^* || m)$.</li>
<li>Assert $e = e^*$.</li>
</ol>
<p>How this works?
Let&rsquo;s go through a proof of correctness.
As before, I added some comments to every operation in parentheses to make it easier to follow.</p>
<ol>
<li>$K^* = g^s P_k^e$ ($\mod p$ implicit).</li>
<li>$K^* = g^{k - S_k e} g^{S_k e}$ ($s = k - S_k e$ and $P_k = g^{S_k}$).</li>
<li>$K^* = g^k$ (cancel $S_k e$ in the exponent of $g$).</li>
<li>$K^* = K$ ($K = g^k$).</li>
<li>Hence $H(K^* || m) = H(K || m)$.</li>
</ol>
<p>There you go.
This attest that the signature is correct and the message was signed by the owner of the private key.</p>
<h2 id="why-we-dont-reuse-nonces">Why we don&rsquo;t reuse nonces?</h2>
<p>Never, ever, reuse a nonce.
Why?
First, because nonce is short for &ldquo;number used once&rdquo;.
It is supposed to be used only once.
Because if you reuse a nonce, then you are pretty much screwed.
An attacker can derive your private key from two signatures with the same nonce.
This is called the &ldquo;nonce reuse attack&rdquo;.</p>
<p>Fun fact: this is what happened to the
<a href="https://en.wikipedia.org/wiki/PlayStation_3_homebrew#Private_key_compromised">PlayStation 3</a>.</p>
<p>Let&rsquo;s see how we can derive the private key from two signatures with the same nonce.
Here we are in a context that we have two signatures $s$ and $s^\prime$,
both using the same nonce $k = k^\prime$.</p>
<p>First, let&rsquo;s do the <del>ugly</del> DSA math:</p>
<p>$$
\begin{aligned}
s^\prime - s &amp;= (k^{\prime {-1}} (H(m_1) + S_k K&rsquo;)) - (k^{-1} (H(m_2) + S_k K)) \\
s^\prime - s &amp;= k^{-1} (H(m_1) - H(m_2)) \\
k &amp;= (H(m_1) - H(m_2)) (s^\prime - s)^{-1}
\end{aligned}
$$</p>
<p>Now remember you know $s$, $s^\prime$, $H(m_1)$, $H(m_2)$ $K$, and $K^\prime$.
Let&rsquo;s do the final step and solve for $S_k$:</p>
<p>$$S_k = K^{-1}  (k s - H(m_1))$$</p>
<p>Now let&rsquo;s do the Schnorr math.
But in Schnorr, everything is simpler.
Even nonce reuse attacks.</p>
<p>$$s^\prime - s = (k^\prime - k) - S_k (e^\prime - e)$$</p>
<p>If $k^\prime = k$ (nonce reuse) then you can easily isolate $S_k$ with simple algebra.</p>
<p>Remember: you know $s^\prime, s, e, e^\prime$ and $k^\prime - k = 0$.</p>
<h2 id="why-we-can-combine-schnorr-signatures-and-not-dsa">Why we can combine Schnorr Signatures and not DSA?</h2>
<p>In Bitcoin, we can combine Schnorr signatures and not DSA.
Why?
Because Schnorr signatures are linear.
This means that you can add two Schnorr signatures and get a valid signature for the sum of the messages.
This is not possible with DSA.
This is called the &ldquo;linearity property&rdquo; of Schnorr signatures.</p>
<p>Remember that in $Z_p$ addition, multiplication, and exponentiation,
i.e anything with $+, \cdot, -$, are linear operations
However, division (modular inverse),
.i.e anything that is $^{-1}$, is not linear.
That is:</p>
<p>$$x^{-1} + y^{-1} \ne (x + y)^{-1}.$$</p>
<p>Here&rsquo;s a trivial python code that shows that modular inverse is not linear:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">71</span><span class="p">;</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">13</span><span class="p">;</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">17</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="nb">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="nb">pow</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="o">==</span> <span class="nb">pow</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="kc">False</span>
</span></span></code></pre></div><p>Let&rsquo;s revisit the signature step of DSA and Schnorr:</p>
<ul>
<li>DSA: $s = k^{-1} (H(m) + S_k K)$</li>
<li>Schnorr: $s = k - S_k H(K || m)$</li>
</ul>
<p>So if you have two Schnorr signatures $s_1$ and $s_2$ for two messages $m_1$ and $m_2$,
then you can easily compute a valid signature for the sum of the messages $m_1 + m_2$:</p>
<p>$$s = s_1 + s_2$$</p>
<p>Also note that we can combine Schnorr public keys:</p>
<p>$$P^\prime_k + P_k = g^{S^\prime_k} + g^{S_k} = g^{S_k^\prime + S_k}$$</p>
<p>And the signature $s$ for the sum of the messages $m_1 + m_2$
can be verified with the public key $P^\prime_k + P_k$.</p>
<p>This is not possible with DSA.</p>
<p>Because the signature step in DSA is not linear,
it has a $k^{-1}$ in it.</p>
<h2 id="technical-interlude-elliptic-curves">Technical Interlude: Elliptic Curves</h2>
<p>Technically speaking, Bitcoin uses the Elliptic Curve Digital Signature Algorithm (ECDSA),
and the Schnorr signature algorithm is based on the same elliptic curve (EC) as ECDSA.</p>
<p>And trivially speaking EC public-key cryptography in the end is just a finite field
on $\mathbb{Z}_p$.
It has everything that we&rsquo;ve seen so far:</p>
<ul>
<li>Addition</li>
<li>Subtraction</li>
<li>Multiplication</li>
<li>Division</li>
<li>Exponentiation</li>
<li>Generators</li>
<li>Discrete Logarithm Problem</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>I hope you enjoyed this companion post to the
<a href="https://github.com/storopoli/cryptography-workshop">cryptography workshop</a>.
Remember don&rsquo;t reuse nonces.</p>
<h2 id="license">License</h2>
<p>This post is licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International</a>.</p>
<p><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img loading="lazy" src="https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png" alt="CC BY-NC-SA 4.0"  />
</a></p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>the image of a function $f$ is the set of all values that $f$ may produce.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>the problem of factoring a number into its prime factors is not known to be in
the class of problems that can be solved in polynomial time, P.
It is not known to be NP-complete, NP, either.
Actually to find it P is NP or not is the hardest way to earn a million dollars,
<a href="https://en.m.wikipedia.org/wiki/Millennium_Prize_Problems#P_versus_NP">the P vs NP problem</a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>this is called <a href="https://en.wikipedia.org/wiki/Bijection%2C_injection_and_surjection">surjection</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>at least $\frac{1}{N}$ where $N$ is the size of $Y$.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>actually this is not true. Due to the <a href="https://en.wikipedia.org/wiki/Birthday_problem#Probability_of_a_shared_birthday_(collision)">birthday paradox</a>,
the probability of finding a collision is not $\frac{1}{N}$ but $\frac{1}{\sqrt{N}}$.
Hence the search space is actually $2^{\frac{N}{2}}$ instead of the original $2^N$.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>The answer is $x = 6$. This means that $3^6 = 15 \mod 17$.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Taproot is a proposed Bitcoin protocol upgrade that was deployed
as a forward-compatible soft fork.
The validation of Taproot is based on Schnorr signatures.
You can find more in BIPS
<a href="https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki">340</a>,
<a href="https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki">341</a>, and
<a href="https://github.com/bitcoin/bips/blob/master/bip-0342.mediawiki">342</a>.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>

</feed>


