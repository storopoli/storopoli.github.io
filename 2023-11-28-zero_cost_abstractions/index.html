<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Zero-cost Abstractions | Jose Storopoli, PhD</title>
<meta name=keywords content="programming,julia,rust,python"><meta name=description content="In programming language circles there&rsquo;s a recently trend of discussing a concept called zero-cost abstractions: the ability to use higher-levels abstractions without suffering any loss of performance.
Zero-cost abstractions allows you to write performant code without having to give up a single drop of convenience and expressiveness:
You want for-loops? You can have it. Generics? Yeah, why not? Data structures? Sure, keep&rsquo;em coming. Async operations? You bet ya! Multi-threading? Hell yes!"><meta name=author content="Jose Storopoli"><link rel=canonical href=https://storopoli.io/2023-11-28-zero_cost_abstractions/><link crossorigin=anonymous href=/assets/css/stylesheet.5d45b8bd1a3cf526e72959d51f1bdc688d8e97fa0df2a697a93df6bdc746feb4.css integrity="sha256-XUW4vRo89SbnKVnVHxvcaI2Ol/oN8qaXqT32vcdG/rQ=" rel="preload stylesheet" as=style><noscript><link crossorigin=anonymous href=/css/includes/noscript.30127fa68e36d08f5dd7f9d4e717dac42e729b844672afd0fbcacb0d9e508595.css integrity="sha256-MBJ/po420I9d1/nU5xfaxC5ym4RGcq/Q+8rLDZ5QhZU=" rel="preload stylesheet" as=style></noscript><link rel=icon href=https://storopoli.io/assets/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://storopoli.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://storopoli.io/favicon-32x32.png><link rel=apple-touch-icon href=https://storopoli.io/apple-touch-icon.png><link rel=mask-icon href=https://storopoli.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta http-equiv=Content-Security-Policy content="default-src 'none'; img-src 'self'; script-src 'self'; font-src 'self'; style-src 'self'; connect-src 'self'; form-action 'none'; block-all-mixed-content; base-uri 'none'"><meta property="og:title" content="Zero-cost Abstractions"><meta property="og:description" content="In programming language circles there&rsquo;s a recently trend of discussing a concept called zero-cost abstractions: the ability to use higher-levels abstractions without suffering any loss of performance.
Zero-cost abstractions allows you to write performant code without having to give up a single drop of convenience and expressiveness:
You want for-loops? You can have it. Generics? Yeah, why not? Data structures? Sure, keep&rsquo;em coming. Async operations? You bet ya! Multi-threading? Hell yes!"><meta property="og:type" content="article"><meta property="og:url" content="https://storopoli.io/2023-11-28-zero_cost_abstractions/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-11-28T18:19:36-03:00"><meta property="article:modified_time" content="2024-02-11T10:34:49-03:00"><meta property="og:site_name" content="Jose Storopoli, PhD"><meta name=twitter:card content="summary"><meta name=twitter:title content="Zero-cost Abstractions"><meta name=twitter:description content="In programming language circles there&rsquo;s a recently trend of discussing a concept called zero-cost abstractions: the ability to use higher-levels abstractions without suffering any loss of performance.
Zero-cost abstractions allows you to write performant code without having to give up a single drop of convenience and expressiveness:
You want for-loops? You can have it. Generics? Yeah, why not? Data structures? Sure, keep&rsquo;em coming. Async operations? You bet ya! Multi-threading? Hell yes!"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://storopoli.io/posts/"},{"@type":"ListItem","position":2,"name":"Zero-cost Abstractions","item":"https://storopoli.io/2023-11-28-zero_cost_abstractions/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Zero-cost Abstractions","name":"Zero-cost Abstractions","description":"In programming language circles there\u0026rsquo;s a recently trend of discussing a concept called zero-cost abstractions: the ability to use higher-levels abstractions without suffering any loss of performance.\nZero-cost abstractions allows you to write performant code without having to give up a single drop of convenience and expressiveness:\nYou want for-loops? You can have it. Generics? Yeah, why not? Data structures? Sure, keep\u0026rsquo;em coming. Async operations? You bet ya! Multi-threading? Hell yes!","keywords":["programming","julia","rust","python"],"articleBody":"In programming language circles there’s a recently trend of discussing a concept called zero-cost abstractions: the ability to use higher-levels abstractions without suffering any loss of performance.\nZero-cost abstractions allows you to write performant code without having to give up a single drop of convenience and expressiveness:\nYou want for-loops? You can have it. Generics? Yeah, why not? Data structures? Sure, keep’em coming. Async operations? You bet ya! Multi-threading? Hell yes!\nTo put more formally, I like this definition from StackOverflow:\nZero Cost Abstractions means adding higher-level programming concepts, like generics, collections and so on do not come with a run-time cost, only compile time cost (the code will be slower to compile). Any operation on zero-cost abstractions is as fast as you would write out matching functionality by hand using lower-level programming concepts like for loops, counters, ifs and using raw pointers.\nHere’s an analogy:\nImagine that you are going to buy a car. The sales person offers you a fancy car praising how easy it is to drive it, that you don’t need to think about RPM, clutch and stick shift, parking maneuver, fuel type, and other shenanigans. You just turn it on and drive. However, once you take a look at the car’s data sheet, you are horrified. The car is bad in every aspect except easy of use. It has dreadful fuel consumption, atrocious safety ratings, disastrous handling, and so on…\nBelieve me, you wouldn’t want to own that car.\nMetaphors aside, that’s exactly what professional developers1 and whole teams choose to use every day: unacceptable inferior tools. Tools that, not only don’t have zero-cost abstractions, rather don’t allow you to even have non-zero-cost anything!\nLet’s do some Python bashing in the meantime. I know that’s easy to bash Python, but that’s not the point. If Python wasn’t used so widely in production, I would definitely leave it alone. Don’t get me wrong, Python is the second-best language for everything2.\nThe curious case of the Python boolean I wish this meme was a joke, but it isn’t. A boolean is one of the simplest data type taking only two possible values: true or false. Just grab your nearest Python REPL:\n\u003e\u003e\u003e from sys import getsizeof \u003e\u003e\u003e getsizeof(True) 28 The function sys.getsizeof returns the size of an object in bytes. How the hell Python needs 28 bytes to represent something that needs at most 1 byte3? Imagine incurring a 28x penalty in memory size requirements for every boolean that you use. Now multiply this by every operation that your code is going to run in production over time. Again: unacceptable.\nThat’s because all objects in Python, in the sense that everything that you can instantiate, i.e. everything that you can put on the left hand-side of the = assignment, is a PyObject:\nAll Python objects ultimately share a small number of fields at the beginning of the object’s representation in memory. These are represented by the PyObject and PyVarObject types.\nPython is dynamically-typed, which means that you don’t have primitives like 8-, 16-, 32-bit (un)signed integers and so on. Everything is a huge mess allocated in the heap that must carry not only its value, but also information about its type.\nMost important, everything that is fast in Python is not Python-based. Take a look at the image below, I grabbed some popular Python libraries from GitHub, namely NumPy (linear algebra package) and PyToch (deep learning package), and checked the language codebase percentage.\nSurprise, they are not Python libraries. They are C/C++ codebases. Even if Python is the main language used in these codebases4, I still think that this is not the case due to the nature of the Python code: all docstrings are written in Python. If you have a very fast C function in your codebase that takes 50 lines of code, followed by a Python wrapper function that calls it using 10 lines of code, but with a docstring that is 50 lines of code; you have a “Python”-majority codebase.\nIn a sense the most efficient Python programmer is a C/C++ programmer…\nHere’s Julia, which is also dynamically-typed:\njulia\u003e Base.summarysize(true) 1 And to your surprise, Julia is coded in …. Julia! Check the image below for the language codebase percentage of Julia and Lux.jl5 (deep learning package).\nFinally, here’s Rust, which is not dynamically-, but static-typed:\n// main.rs use std::mem; fn main() { println!(\"Size of bool: {} byte\", mem::size_of::\u003cbool\u003e()); } $ cargo run --release Compiling size_of_bool v0.1.0 Finished release [optimized] target(s) in 0.00s Running `target/release/size_of_bool` Size of bool: 1 byte More zero-costs abstractions Let’s cover two more zero-costs abstractions, both in Julia and in Rust: for-loops and enums.\nFor-loops A friend and a Julia-advocate once told me that Julia’s master plan is to secretly “make everyone aware about compilers”. The compiler is a program that translate source code from a high-level programming language to a low-level programming language (e.g. assembly language, object code, or machine code) to create an executable program.\nPython uses CPython as the compiler. If you search around on why CPython/Python is so slow and inefficient, you’ll find that the culprits are:\nPython is dynamic-typed language. Python’s Global Interpreter Lock (GIL) restricts multi-threading capabilities. Python is interpreted, which means that Python code is executed sequentially: line-by-line. Python is garbage-collected: all memory its tracked, and allocated or deallocated which introduces overhead. I completely disagree with almost all the above reasons, except the GIL. Python is slow because of its design decisions, more specifically the way CPython works under the hood. It is not built for performance in mind. Actually, the main objective of Python was to be a “language that would be easy to read, write, and maintain”. I salute that: Python has remained true to its main objective.\nNow let’s switch to Julia:\nJulia is dynamic-typed language. Julia is interpreted, which means that Julia code is executed sequentially: line-by-line. Julia is garbage-collected: all memory its tracked, and allocated or deallocated which introduces overhead. I’ve copy-pasted all Python’s arguments for inefficiency, except the GIL. And, contrary to Python, Julia is fast! Sometimes even faster than C6. Actually, that was the goal all along since Julia’s inception. If you check the notorious Julia announcement blog post from 2012:\nWe want a language that’s open source, with a liberal license. We want the speed of C with the dynamism of Ruby. We want a language that’s homoiconic, with true macros like Lisp, but with obvious, familiar mathematical notation like Matlab. We want something as usable for general programming as Python, as easy for statistics as R, as natural for string processing as Perl, as powerful for linear algebra as Matlab, as good at gluing programs together as the shell. Something that is dirt simple to learn, yet keeps the most serious hackers happy. We want it interactive and we want it compiled.\n(Did we mention it should be as fast as C?)\nIt mentions “speed” twice. Not only that, but also specifically says that it should match C’s speed.\nJulia is fast because of its design decisions. One of the major reasons why Julia is fast is because of the choice of compiler that it uses: LLVM.\nLLVM originally stood for low level virtual machine. Despite its name, LLVM has little to do with traditional virtual machines. LLVM can take intermediate representation (IR) code and compile it into machine-dependent instructions. It has support and sponsorship from a lot of big-tech corporations, such as Apple, Google, IBM, Meta, Arm, Intel, AMD, Nvidia, and so on. It is a pretty fast compiler that can do wonders in optimizing IR code to a plethora of computer architectures.\nIn a sense, Julia is a front-end for LLVM. It turns your easy-to-read and easy-to-write Julia code into LLVM IR code. Take this for-loop example inside a function:\nfunction sum_10() acc = 0 for i in 1:10 acc += i end return acc end Let’s check what Julia generates as LLVM IR code for this function. We can do that with the @code_llvm macro.\njulia\u003e @code_llvm debuginfo=:none sum_10() define i64 @julia_sum_10_172() #0 { top: ret i64 55 } You can’t easily fool the compiler. Julia understands that the answer is 55, and the LLVM IR generated code is pretty much just “return 55 as a 64-bit integer”.\nLet’s also check the machine-dependent instructions with the @code_native macro. I am using an Apple Silicon machine, so these instructions might differ from yours:\njulia\u003e @code_native debuginfo=:none sum_10() .section __TEXT,__text,regular,pure_instructions .build_version macos, 14, 0 .globl _julia_sum_10_214 ; -- Begin function julia_sum_10_214 .p2align 2 _julia_sum_10_214: ; @julia_sum_10_214 .cfi_startproc ; %bb.0: ; %top mov w0, #55 ret .cfi_endproc ; -- End function .subsections_via_symbols The only important instruction for our argument here is the mov w0, #55. This means “move the value 55 into the w0 register”, where w0 is one of registers available in ARM-based architectures (which Apple Silicon chips are).\nThis is a zero-cost abstraction! I don’t need to give up for-loops, because they might be slow and inefficient; like some Python users suggest newcomers. I can have the full convenience and expressiveness of for-loops without paying performance costs. Pretty much the definition of a zero-cost abstraction from above.\nUsing LLVM as a compiler backend is not something unique to Julia. Rust also uses LLVM under the hood. Take for example this simple Rust code:\n// main.rs pub fn sum_10() -\u003e i32 { let mut acc = 0; for i in 1..=10 { acc += i } acc } fn main() { println!(\"sum_10: {}\", sum_10()); } We can inspect both LLVM IR code and machine instructions with the cargo-show-asm crate:\n$ cargo asm --llvm \"sum_10::main\" | grep 55 Finished release [optimized] target(s) in 0.00s store i32 55, ptr %_9, align 4 $ cargo asm \"sum_10::main\" | grep 55 Finished release [optimized] target(s) in 0.00s mov w8, #55 No coincidence that the LLVM IR code is very similar, with the difference that integers, by default, in Julia are 64 bits and in Rust 32 bits. However, the machine code is identical: “move the value 55 into a w something register”.\nEnums Another zero-cost abstraction, in Julia and Rust, is enums.\nIn Julia all enums, by default have a BaseType of Int32: a signed 32-bit integer. However, we can override this with type annotations:\njulia\u003e @enum Thing::Bool One Two julia\u003e Base.summarysize(Thing(false)) 1 Here we have an enum Thing with two variants: One and Two. Since we can safely represent all the possible variant space of Thing with a boolean type, we override the BaseType of Thing to be the Bool type. Unsurprised, any object of Thing occupies 1 byte in memory.\nWe can achieve the same with Rust:\n// main.rs use std::mem; #[allow(dead_code)] enum Thing { One, Two, } fn main() { println!(\"Size of Thing: {} byte\", mem::size_of::\u003cThing\u003e()); } $ cargo run --release Compiling enum_size v0.1.0 Finished release [optimized] target(s) in 0.09s Running `target/release/enum_size` Size of Thing: 1 byte However, contrary to Julia, Rust compiler automatically detects the enum’s variant space size and adjust accordingly. So, no need of overrides.\nConclusion Zero-cost abstractions are a joy to have in a programming language. It enables you, as a programmer, to just focus on what’s important: write expressive code that is easy to read, maintain, debug, and build upon.\nIt is no wonder that zero-cost abstractions is a pervasive feature of two of my top-favorite languages: Julia and Rust.\nLicense This post is licensed under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International.\nthis post is somehow connected to my soydev rant. ↩︎\nand that’s not a compliment. ↩︎\ntechnically, we can represent a boolean with just one bit. However, the short answer is still one byte, because that’s smallest addressable unit of memory. ↩︎\nand modifying .gitattributes is cheating. Yes, I am talking to you NumPy! ↩︎\nLux.jl doesn’t even have a .gitattributes file. ↩︎\nif you compare runtime execution. ↩︎\n","wordCount":"1965","inLanguage":"en","datePublished":"2023-11-28T18:19:36-03:00","dateModified":"2024-02-11T10:34:49-03:00","author":{"@type":"Person","name":"Jose Storopoli"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://storopoli.io/2023-11-28-zero_cost_abstractions/"},"publisher":{"@type":"Organization","name":"Jose Storopoli, PhD","logo":{"@type":"ImageObject","url":"https://storopoli.io/assets/favicon.ico"}}}</script></head><body class=dark id=top><script crossorigin=anonymous src=/assets/js/theme.b20f95bb4da41ef90a2610a557a7000b2649a3f47282ec571676da6fc0427200.js integrity="sha256-sg+Vu02kHvkKJhClV6cACyZJo/RyguxXFnbab8BCcgA="></script><header class=header><div id=progressBar></div><nav class=nav><div class=logo><a href=https://storopoli.io/ accesskey=h title="Jose Storopoli, PhD (Alt + H)">Jose Storopoli, PhD</a><div class=logo-switches><button type=button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><input name=hamburger-input id=hamburger-input type=checkbox aria-label="Navigation Menu">
<label id=hamburger-menu for=hamburger-input></label><div class=overlay></div><ul id=menu><li><a href=https://storopoli.io/about/ title=About><span>About</span></a></li><li><a href=https://storopoli.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://github.com/storopoli/cv/releases/latest/download/cv.pdf title=CV><span>CV</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://storopoli.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://storopoli.io/>Home</a>&nbsp;»&nbsp;<a href=https://storopoli.io/posts/>Blog</a></div><h1 class="post-title entry-hint-parent">Zero-cost Abstractions</h1><div class=post-meta><span title='2023-11-28 18:19:36 -0300 -0300'>November 28, 2023</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;Jose Storopoli&nbsp;|&nbsp;<a href=https://github.com/storopoli/storopoli.github.io/blob/main/content/posts/2023-11-28-zero_cost_abstractions/index.md rel="noopener noreferrer">Source code</a></div><div class=post-meta><span title="2024-02-11 10:34:49 -0300 -0300"><i>Last updated on February 11, 2024</i></span></div></header><div class="toc side"><details id=toc><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#the-curious-case-of-the-python-boolean aria-label="The curious case of the Python boolean">The curious case of the Python boolean</a></li><li><a href=#more-zero-costs-abstractions aria-label="More zero-costs abstractions">More zero-costs abstractions</a><ul><li><a href=#for-loops aria-label=For-loops>For-loops</a></li><li><a href=#enums aria-label=Enums>Enums</a></li></ul></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li><li><a href=#license aria-label=License>License</a></li></ul></div></details></div><div class=post-content><p>In programming language circles there&rsquo;s a recently trend of discussing a concept
called <strong>zero-cost abstractions</strong>:
the ability to use higher-levels abstractions without suffering any loss of performance.</p><p>Zero-cost abstractions allows you to write performant code without having to
give up a single drop of convenience and expressiveness:</p><p>You want for-loops?
<em>You can have it</em>.
Generics?
<em>Yeah, why not</em>?
Data structures?
<em>Sure, keep&rsquo;em coming</em>.
Async operations?
<em>You bet ya</em>!
Multi-threading?
<em>Hell yes</em>!</p><p>To put more formally,
I like <a href=https://stackoverflow.com/a/69178445>this definition from StackOverflow</a>:</p><blockquote><p>Zero Cost Abstractions means adding higher-level programming concepts, like generics,
collections and so on do not come with a run-time cost,
only compile time cost (the code will be slower to compile).
Any operation on zero-cost abstractions is as fast as you would write out
matching functionality by hand using lower-level programming concepts like
for loops, counters, ifs and using raw pointers.</p></blockquote><p>Here&rsquo;s an analogy:</p><blockquote><p>Imagine that you are going to buy a car.
The sales person offers you a fancy car praising how easy it is to drive it,
that you don&rsquo;t need to think about RPM, clutch and stick shift,
parking maneuver, fuel type, and other shenanigans.
You just turn it on and drive.
However, once you take a look at the car&rsquo;s data sheet, you are horrified.
The car is bad in every aspect except easy of use.
It has dreadful fuel consumption,
atrocious safety ratings,
disastrous handling, and so on&mldr;</p></blockquote><p>Believe me, you wouldn&rsquo;t want to own that car.</p><p>Metaphors aside, that&rsquo;s <strong>exactly what professional developers<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> and whole teams
choose to use every day: unacceptable inferior tools</strong>.
Tools that, not only don&rsquo;t have <strong>zero-cost abstractions</strong>,
rather don&rsquo;t allow you to even have non-zero-cost anything!</p><p>Let&rsquo;s do some Python bashing in the meantime.
I know that&rsquo;s easy to bash Python,
but that&rsquo;s not the point.
If Python wasn&rsquo;t used so widely in production,
I would definitely leave it alone.
Don&rsquo;t get me wrong, Python is the second-best language for everything<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>.</p><h2 id=the-curious-case-of-the-python-boolean>The curious case of the Python boolean<a hidden class=anchor aria-hidden=true href=#the-curious-case-of-the-python-boolean>#</a></h2><p><img loading=lazy src=non-zero-cost-abstraction.png#center alt=non-zero-cost-abstraction></p><p>I wish this meme was a joke, but it isn&rsquo;t.
A boolean is one of the simplest data type taking only two possible values:
true or false.
Just grab your nearest Python REPL:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=kn>from</span> <span class=nn>sys</span> <span class=kn>import</span> <span class=n>getsizeof</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>getsizeof</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=mi>28</span>
</span></span></code></pre></div><p>The function <a href=https://docs.python.org/3/library/sys.html#sys.getsizeof><code>sys.getsizeof</code></a>
returns the size of an object in bytes.
<strong>How the hell Python needs 28 bytes to represent something that needs at most 1 byte</strong><sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>?
Imagine incurring a 28x penalty in memory size requirements for every boolean
that you use.
Now multiply this by every operation that your code is going to run in production
over time.
Again: <strong>unacceptable</strong>.</p><p>That&rsquo;s because all objects in Python,
in the sense that everything that you can instantiate,
i.e. everything that you can put on the left hand-side of the <code>=</code> assignment,
is a <a href=https://docs.python.org/3/c-api/structures.html#c.PyObject><code>PyObject</code></a>:</p><blockquote><p>All Python objects ultimately share a small number of fields at the
beginning of the object’s representation in memory.
These are represented by the <code>PyObject</code> and <code>PyVarObject</code> types.</p></blockquote><p>Python is dynamically-typed, which means that you don&rsquo;t have primitives like
8-, 16-, 32-bit (un)signed integers and so on.
Everything is a huge mess allocated in the heap that must carry not only its value,
but also information about its type.</p><p>Most important, everything that is fast in Python is <em>not Python-based</em>.
Take a look at the image below,
I grabbed some popular Python libraries from GitHub,
namely <a href=https://github.com/numpy/numpy>NumPy</a> (linear algebra package)
and <a href=https://github.com/pytorch/pytorch>PyToch</a> (deep learning package),
and checked the
language codebase percentage.</p><p><img loading=lazy src=python-my-ass.jpg#center alt=python-my-ass></p><p>Surprise, they are <strong><em>not</em> Python libraries</strong>.
They are <strong>C/C++ codebases</strong>.
Even if Python is the main language used in these codebases<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>,
I still think that this is not the case due to the nature of the Python code:
<strong>all docstrings are written in Python</strong>.
If you have a very fast C function in your codebase that takes 50 lines of code,
followed by a Python wrapper function that calls it using 10 lines of code,
<em>but</em> with a docstring that is 50 lines of code;
you have a &ldquo;Python&rdquo;-majority codebase.</p><p>In a sense the most efficient Python programmer is a C/C++ programmer&mldr;</p><p>Here&rsquo;s <a href=https://julialang.org>Julia</a>, which is also dynamically-typed:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia><span class=line><span class=cl><span class=n>julia</span><span class=o>&gt;</span> <span class=n>Base</span><span class=o>.</span><span class=n>summarysize</span><span class=p>(</span><span class=nb>true</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=mi>1</span>
</span></span></code></pre></div><p>And to your surprise,
Julia is coded in &mldr;. Julia!
Check the image below for the language codebase percentage of
<a href=https://github.com/JuliaLang/julia>Julia</a>
and <a href=https://github.com/LuxDL/Lux.jl><code>Lux.jl</code></a><sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> (deep learning package).</p><p><img loading=lazy src=julia.jpg#center alt=julia></p><p>Finally, here&rsquo;s <a href=https://rust-lang.org>Rust</a>, which is not dynamically-,
but static-typed:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=c1>// main.rs
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>use</span><span class=w> </span><span class=n>std</span>::<span class=n>mem</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>fn</span> <span class=nf>main</span><span class=p>()</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=fm>println!</span><span class=p>(</span><span class=s>&#34;Size of bool: </span><span class=si>{}</span><span class=s> byte&#34;</span><span class=p>,</span><span class=w> </span><span class=n>mem</span>::<span class=n>size_of</span>::<span class=o>&lt;</span><span class=kt>bool</span><span class=o>&gt;</span><span class=p>());</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ cargo run --release
</span></span><span class=line><span class=cl>   Compiling size_of_bool v0.1.0
</span></span><span class=line><span class=cl>    Finished release <span class=o>[</span>optimized<span class=o>]</span> target<span class=o>(</span>s<span class=o>)</span> in 0.00s
</span></span><span class=line><span class=cl>     Running <span class=sb>`</span>target/release/size_of_bool<span class=sb>`</span>
</span></span><span class=line><span class=cl>Size of bool: <span class=m>1</span> byte
</span></span></code></pre></div><h2 id=more-zero-costs-abstractions>More zero-costs abstractions<a hidden class=anchor aria-hidden=true href=#more-zero-costs-abstractions>#</a></h2><p>Let&rsquo;s cover two more zero-costs abstractions, both in Julia and in Rust:
<strong>for-loops</strong> and <strong>enums</strong>.</p><h3 id=for-loops>For-loops<a hidden class=anchor aria-hidden=true href=#for-loops>#</a></h3><p>A friend and a Julia-advocate once told me that Julia&rsquo;s master plan is to secretly
&ldquo;make everyone aware about <em>compilers</em>&rdquo;.
The <a href=https://en.wikipedia.org/wiki/Compiler>compiler</a>
is a program that translate source code from a high-level programming language
to a low-level programming language
(e.g. assembly language, object code, or machine code) to create an
executable program.</p><p>Python uses <a href=https://github.com/python/cpython>CPython</a> as the compiler.
If you search around on why CPython/Python is so slow and inefficient,
you&rsquo;ll find that the culprits are:</p><ol><li>Python is <strong>dynamic-typed language</strong>.</li><li>Python&rsquo;s <strong>Global Interpreter Lock (GIL) restricts multi-threading capabilities</strong>.</li><li>Python is <strong>interpreted</strong>, which means that Python code is executed sequentially:
line-by-line.</li><li>Python is <strong>garbage-collected</strong>: all memory its tracked,
and allocated or deallocated which introduces overhead.</li></ol><p>I completely disagree with almost all the above reasons, except the GIL.
<strong>Python is slow because of its design decisions</strong>,
more specifically the way CPython works under the hood.
It is not built for performance in mind.
Actually, the main objective of Python was to be a
&ldquo;language that would be easy to read, write, and maintain&rdquo;.
I salute that: Python has remained true to its main objective.</p><p>Now let&rsquo;s switch to Julia:</p><ol><li>Julia is <strong>dynamic-typed language</strong>.</li><li>Julia is <strong>interpreted</strong>, which means that Julia code is executed sequentially:
line-by-line.</li><li>Julia is <strong>garbage-collected</strong>: all memory its tracked,
and allocated or deallocated which introduces overhead.</li></ol><p>I&rsquo;ve copy-pasted all Python&rsquo;s arguments for inefficiency, except the GIL.
And, contrary to Python, <a href=https://julialang.org/benchmarks/>Julia is fast</a>!
Sometimes even faster than C<sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup>.
Actually, that was the goal all along since Julia&rsquo;s inception.
If you check the <a href=https://julialang.org/blog/2012/02/why-we-created-julia/>notorious Julia announcement blog post from 2012</a>:</p><blockquote><p>We want a language that&rsquo;s open source, with a liberal license.
We want the speed of C with the dynamism of Ruby.
We want a language that&rsquo;s homoiconic, with true macros like Lisp,
but with obvious, familiar mathematical notation like Matlab.
We want something as usable for general programming as Python,
as easy for statistics as R, as natural for string processing as Perl,
as powerful for linear algebra as Matlab, as good at gluing programs together as the shell.
Something that is dirt simple to learn,
yet keeps the most serious hackers happy.
We want it interactive and we want it compiled.</p><p>(Did we mention it should be as fast as C?)</p></blockquote><p>It mentions &ldquo;speed&rdquo; twice.
Not only that, but also specifically says that it should match C&rsquo;s speed.</p><p>Julia is fast because of its design decisions.
One of the major reasons why Julia is fast is because of the choice of compiler
that it uses: <a href=https://llvm.org/>LLVM</a>.</p><p>LLVM originally stood for <strong>l</strong>ow <strong>l</strong>evel <strong>v</strong>irtual <strong>m</strong>achine.
Despite its name, LLVM has little to do with traditional virtual machines.
LLVM can take <a href=https://en.wikipedia.org/wiki/Intermediate_representation>intermediate representation (IR)</a>
code and compile it into machine-dependent instructions.
It has <a href=https://foundation.llvm.org/docs/sponsors/>support and sponsorship</a>
from a lot of big-tech corporations,
such as Apple, Google, IBM, Meta, Arm, Intel, AMD, Nvidia, and so on.
It is a pretty fast compiler that can do wonders in optimizing IR code to a
plethora of computer architectures.</p><p>In a sense, Julia is a front-end for LLVM.
It turns your easy-to-read and easy-to-write Julia code into LLVM IR code.
Take this for-loop example inside a function:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia><span class=line><span class=cl><span class=k>function</span> <span class=n>sum_10</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>acc</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=k>in</span> <span class=mi>1</span><span class=o>:</span><span class=mi>10</span>
</span></span><span class=line><span class=cl>        <span class=n>acc</span> <span class=o>+=</span> <span class=n>i</span>
</span></span><span class=line><span class=cl>    <span class=k>end</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>acc</span>
</span></span><span class=line><span class=cl><span class=k>end</span>
</span></span></code></pre></div><p>Let&rsquo;s check what Julia generates as LLVM IR code for this function.
We can do that with the <code>@code_llvm</code> macro.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia><span class=line><span class=cl><span class=n>julia</span><span class=o>&gt;</span> <span class=nd>@code_llvm</span> <span class=n>debuginfo</span><span class=o>=</span><span class=ss>:none</span> <span class=n>sum_10</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>define</span> <span class=n>i64</span> <span class=nd>@julia_sum_10_172</span><span class=p>()</span> <span class=c>#0 {</span>
</span></span><span class=line><span class=cl><span class=n>top</span><span class=o>:</span>
</span></span><span class=line><span class=cl>  <span class=n>ret</span> <span class=n>i64</span> <span class=mi>55</span>
</span></span><span class=line><span class=cl><span class=err>}</span>
</span></span></code></pre></div><p>You can&rsquo;t easily fool the compiler.
Julia understands that the answer is 55,
and the LLVM IR generated code is pretty much just &ldquo;return 55 as a 64-bit integer&rdquo;.</p><p>Let&rsquo;s also check the machine-dependent instructions with the <code>@code_native</code> macro.
I am using an Apple Silicon machine, so these instructions might differ from yours:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia><span class=line><span class=cl><span class=n>julia</span><span class=o>&gt;</span> <span class=nd>@code_native</span> <span class=n>debuginfo</span><span class=o>=</span><span class=ss>:none</span> <span class=n>sum_10</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>section</span>        <span class=n>__TEXT</span><span class=p>,</span><span class=n>__text</span><span class=p>,</span><span class=n>regular</span><span class=p>,</span><span class=n>pure_instructions</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>build_version</span> <span class=n>macos</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>globl</span>  <span class=n>_julia_sum_10_214</span>               <span class=p>;</span> <span class=o>--</span> <span class=n>Begin</span> <span class=k>function</span> <span class=n>julia_sum_10_214</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>p2align</span>        <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=n>_julia_sum_10_214</span><span class=o>:</span>                      <span class=p>;</span> <span class=nd>@julia_sum_10_214</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>cfi_startproc</span>
</span></span><span class=line><span class=cl><span class=p>;</span> <span class=o>%</span><span class=n>bb</span><span class=mf>.0</span><span class=o>:</span>                                <span class=p>;</span> <span class=o>%</span><span class=n>top</span>
</span></span><span class=line><span class=cl>        <span class=n>mov</span>     <span class=n>w0</span><span class=p>,</span> <span class=c>#55</span>
</span></span><span class=line><span class=cl>        <span class=n>ret</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>cfi_endproc</span>
</span></span><span class=line><span class=cl>                                        <span class=p>;</span> <span class=o>--</span> <span class=n>End</span> <span class=k>function</span>
</span></span><span class=line><span class=cl><span class=o>.</span><span class=n>subsections_via_symbols</span>
</span></span></code></pre></div><p>The only important instruction for our argument here is the <code>mov w0, #55</code>.
This means &ldquo;move the value 55 into the <code>w0</code> register&rdquo;,
where <code>w0</code> is one of registers available in ARM-based architectures
(which Apple Silicon chips are).</p><p>This is a <strong>zero-cost abstraction</strong>!
I don&rsquo;t need to give up for-loops, because they might be slow and inefficient;
like some Python users suggest newcomers.
I can have the full convenience and expressiveness of for-loops without
paying performance costs.
Pretty much the definition of a zero-cost abstraction from above.</p><p>Using LLVM as a compiler backend is not something unique to Julia.
Rust also uses LLVM under the hood.
Take for example this simple Rust code:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=c1>// main.rs
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>pub</span><span class=w> </span><span class=k>fn</span> <span class=nf>sum_10</span><span class=p>()</span><span class=w> </span>-&gt; <span class=kt>i32</span> <span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=kd>let</span><span class=w> </span><span class=k>mut</span><span class=w> </span><span class=n>acc</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>0</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>for</span><span class=w> </span><span class=n>i</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=mi>1</span><span class=o>..=</span><span class=mi>10</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>acc</span><span class=w> </span><span class=o>+=</span><span class=w> </span><span class=n>i</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>acc</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>fn</span> <span class=nf>main</span><span class=p>()</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=fm>println!</span><span class=p>(</span><span class=s>&#34;sum_10: </span><span class=si>{}</span><span class=s>&#34;</span><span class=p>,</span><span class=w> </span><span class=n>sum_10</span><span class=p>());</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>We can inspect both LLVM IR code and machine instructions with the
<a href=https://github.com/pacak/cargo-show-asm><code>cargo-show-asm</code></a> crate:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ cargo asm --llvm <span class=s2>&#34;sum_10::main&#34;</span> <span class=p>|</span> grep <span class=m>55</span>
</span></span><span class=line><span class=cl>    Finished release <span class=o>[</span>optimized<span class=o>]</span> target<span class=o>(</span>s<span class=o>)</span> in 0.00s
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  store i32 55, ptr %_9, align <span class=m>4</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ cargo asm <span class=s2>&#34;sum_10::main&#34;</span> <span class=p>|</span> grep <span class=m>55</span>
</span></span><span class=line><span class=cl>    Finished release <span class=o>[</span>optimized<span class=o>]</span> target<span class=o>(</span>s<span class=o>)</span> in 0.00s
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        mov w8, <span class=c1>#55</span>
</span></span></code></pre></div><p>No coincidence that the LLVM IR code is very similar,
with the difference that integers, by default,
in Julia are 64 bits and in Rust 32 bits.
However, the machine code is <strong>identical</strong>:
&ldquo;move the value 55 into a <code>w</code> something register&rdquo;.</p><h3 id=enums>Enums<a hidden class=anchor aria-hidden=true href=#enums>#</a></h3><p>Another zero-cost abstraction, in Julia and Rust, is <strong>enums</strong>.</p><p>In Julia all enums, by default have a <code>BaseType</code> of <code>Int32</code>:
a signed 32-bit integer.
However, we can override this with type annotations:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia><span class=line><span class=cl><span class=n>julia</span><span class=o>&gt;</span> <span class=nd>@enum</span> <span class=n>Thing</span><span class=o>::</span><span class=kt>Bool</span> <span class=n>One</span> <span class=n>Two</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>julia</span><span class=o>&gt;</span> <span class=n>Base</span><span class=o>.</span><span class=n>summarysize</span><span class=p>(</span><span class=n>Thing</span><span class=p>(</span><span class=nb>false</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=mi>1</span>
</span></span></code></pre></div><p>Here we have an enum <code>Thing</code> with two variants: <code>One</code> and <code>Two</code>.
Since we can safely represent all the possible variant space of <code>Thing</code>
with a boolean type, we override the <code>BaseType</code> of <code>Thing</code> to be the <code>Bool</code> type.
Unsurprised, any object of <code>Thing</code> occupies 1 byte in memory.</p><p>We can achieve the same with Rust:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=c1>// main.rs
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>use</span><span class=w> </span><span class=n>std</span>::<span class=n>mem</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=cp>#[allow(dead_code)]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>enum</span> <span class=nc>Thing</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>One</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>Two</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>fn</span> <span class=nf>main</span><span class=p>()</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=fm>println!</span><span class=p>(</span><span class=s>&#34;Size of Thing: </span><span class=si>{}</span><span class=s> byte&#34;</span><span class=p>,</span><span class=w> </span><span class=n>mem</span>::<span class=n>size_of</span>::<span class=o>&lt;</span><span class=n>Thing</span><span class=o>&gt;</span><span class=p>());</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ cargo run --release
</span></span><span class=line><span class=cl>   Compiling enum_size v0.1.0
</span></span><span class=line><span class=cl>    Finished release <span class=o>[</span>optimized<span class=o>]</span> target<span class=o>(</span>s<span class=o>)</span> in 0.09s
</span></span><span class=line><span class=cl>     Running <span class=sb>`</span>target/release/enum_size<span class=sb>`</span>
</span></span><span class=line><span class=cl>Size of Thing: <span class=m>1</span> byte
</span></span></code></pre></div><p>However, contrary to Julia, Rust compiler automatically detects the enum&rsquo;s
variant space size and adjust accordingly.
So, no need of overrides.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Zero-cost abstractions are a joy to have in a programming language.
It enables you, as a programmer, to just focus on what&rsquo;s important:
write expressive code that is easy to read, maintain, debug, and build upon.</p><p>It is no wonder that zero-cost abstractions is a pervasive feature
of two of my top-favorite languages:
<a href=https://julialang.org>Julia</a>
and <a href=https://rust-lang.org>Rust</a>.</p><h2 id=license>License<a hidden class=anchor aria-hidden=true href=#license>#</a></h2><p>This post is licensed under <a href=http://creativecommons.org/licenses/by-nc-sa/4.0/>Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International</a>.</p><p><a href=http://creativecommons.org/licenses/by-nc-sa/4.0/><img loading=lazy src=https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png alt="CC BY-NC-SA 4.0"></a></p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>this post is somehow connected to my <a href=../2023-11-10-2023-11-13-soydev/>soydev rant</a>.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>and that&rsquo;s not a compliment.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>technically, we can represent a boolean with just one bit.
However, the short answer is still one byte,
because that&rsquo;s <a href=https://en.wikipedia.org/wiki/Byte>smallest addressable unit of memory</a>.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>and modifying <code>.gitattributes</code> is cheating.
Yes, I am talking to you <a href=https://github.com/numpy/numpy/blob/06d7bdfbb585264dcf23d4322be7aee449733ca2/.gitattributes#L6-L7>NumPy</a>!&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p><a href=https://github.com/LuxDL/Lux.jl><code>Lux.jl</code></a> doesn&rsquo;t even have a <code>.gitattributes</code> file.&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p>if you compare runtime execution.&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://storopoli.io/tags/programming/>programming</a></li><li><a href=https://storopoli.io/tags/julia/>julia</a></li><li><a href=https://storopoli.io/tags/rust/>rust</a></li><li><a href=https://storopoli.io/tags/python/>python</a></li></ul><nav class=paginav><a class=prev href=https://storopoli.io/2023-11-20-word_embeddings/><span class=title>« Prev</span><br><span>Word Embeddings</span></a></nav></footer></article></main><footer class=footer><span><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></span>
<span>- Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer">Hugo</a> &
        <a href=https://github.com/Wonderfall/hugo-WonderMod/ rel=noopener>WonderMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script defer crossorigin=anonymous src=/assets/js/papermod.7ea300eda6d3653624a576fbc095ccd8a0c2977756acbe5de4114132a72cc7fa.js integrity="sha256-fqMA7abTZTYkpXb7wJXM2KDCl3dWrL5d5BFBMqcsx/o="></script></body></html>