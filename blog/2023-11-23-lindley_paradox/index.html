<!DOCTYPE html>
<html>
  <head id="head">
    <meta charset="UTF-8">
    <meta name="description" content="Jose Storopoli, PhD - personal website">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@storopoli">
    <meta name="twitter:author" content="@storopoli">
    <meta name="twitter:description" content="Jose Storopoli, PhD - personal website">
    <meta name="twitter:title" content="Lindley&apos;s Paradox, or The consistency of Bayesian Thinking | @stropoli">
    <meta name="twitter:image" content="https://storopoli.io/pp.jpg">
    <meta property="og:type" content="website">
    <meta property="og:title" content="Lindley&apos;s Paradox, or The consistency of Bayesian Thinking | @storopoli">
    <meta property="og:image" content="https://storopoli.io/pp.jpg">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title id="title">
      Lindley&apos;s Paradox, or The consistency of Bayesian Thinking
      - @storopoli
    </title>
    <link rel="stylesheet" type="text/css" href="/main.css">
    <link rel="stylesheet" type="text/css" href="/fonts.css">
    <link rel="stylesheet" type="text/css" href="/fira_code.css">
    <link rel="stylesheet" type="text/css" href="/highlight.css">
    <link type="text/css" rel="stylesheet" href="/term-highlight.css">
    
  <link
    rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
    integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0"
    crossorigin="anonymous"
  >
  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script
    defer
    src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
    integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4"
    crossorigin="anonymous"
  ></script>
  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <script
    defer
    src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05"
    crossorigin="anonymous"
    onload="renderMathInElement(document.body);"
  ></script>
  <script>
    document.addEventListener("DOMContentLoaded", function () {
      renderMathInElement(document.body, {
        delimiters: [
          { left: "$$", right: "$$", display: true },
          { left: "$", right: "$", display: false },
        ],
      });
    });
  </script>

  </head>
  <body>
    <div id="content">
      <style>
        h1,
        h2,
        h3 {
          text-align: center;
        }

        .profile-pic {
          border-radius: 50%;
          border: 5px solid lightblue;
          margin-top: 1rem;
        }
      </style>
      <div style="display:flex; flex-direction:column; align-items:center;">
        <h1 id="header" class="noupper" style="margin-bottom:0;">
          Jose Storopoli, PhD
        </h1>
        <div class="menu" style="display:flex; justify-content:center; ">
          <a href="/">Home</a>
          •
          <a href="/blog/">Blog</a>
          •
          <a href="https://github.com/storopoli" target="_blank">
            GitHub
          </a>
          •
          <a href="/publickey.txt" target="_blank">
            PGP
          </a>
          •
          <a href="/index.xml" rel="alternate" type="application/rss+xml">
            RSS
          </a>
        </div>
      </div>
      
  <h1>Lindley&apos;s Paradox, or The consistency of Bayesian Thinking</h1>
  <p class="post-byline">
    <span>November 22, 2023</span>
    •
    <span>10</span>
    min read • by
    <b>Jose Storopoli, PhD</b>
    <span></span>
  </p>
  <div id="post-description"></div>
  <div>
    <div class="toc block info">
      <h1>&nbsp;Table of Contents</h1>
      <div><ul>
<li>
<ul><li>
<a href="#lindleys-paradox"><a href="#lindleys-paradox">Lindley’s Paradox</a></li><li><a href="#example"><a href="#example">Example</a><ul><li>
<a href="#analytical-solutions"><a href="#analytical-solutions">Analytical Solution</a><ul><li>
<a href="#analytical-solutions-frequentist"><a href="#analytical-solutions-frequentist">Analytical Solutions – Frequentist Approach</a></li><li><a href="#analytical-solutions-bayesian"><a href="#analytical-solutions-bayesian">Analytical Solutions – Bayesian Approach</a></li></ul></li><li><a href="#computational-solutions"><a href="#computational-solutions">Computational Solutional</a><ul><li>
<a href="#computational-solutions-frequentist"><a href="#computational-solutions-frequentist">Computational Solutions – Frequentist Approach</a></li><li><a href="#computational-solutions-bayesian"><a href="#computational-solutions-bayesian">Computational Solutions – Bayesian Approach</a></li></ul></li></ul></li><li><a href="#why-the-frequentist-and-bayesian-approaches-disagree"><a href="#why-the-frequentist-and-bayesian-approaches-disagree">Why the Frequentist and Bayesian Approaches Disagree</a></li><li><a href="#references"><a href="#references">References</a></li></ul></ul></div>
    </div>
  </div>
  <div>
    <div class="block warning">
      <h1>&nbsp;Math Equations</h1>
      This post has
      <a href="https://katex.org/">KaTeX</a>
      enabled,
      so if you want to view the rendered math formulas,
      you'll have to unfortunately enable JavaScript.
    </div>
  </div>
  <div id="content">
    <div id="post-body"><p><figure><img src="/blog/2023-11-23-lindley_paradox/lindley.jpg" alt="">
<figcaption>Dennis Lindley</figcaption></figure></p><p><a href="https://en.wikipedia.org/wiki/Dennis_Lindley" target="_blank">Dennis Lindley</a>, one of my many heroes, was an English statistician, decision theorist and leading advocate of Bayesian statistics. He published a pivotal book, <a href="https://onlinelibrary.wiley.com/doi/book/10.1002/9781118650158" target="_blank">Understanding Uncertainty</a>, that changed my view on what is and how to handle uncertainty in a coherent way. He is responsible for one of my favorites quotes: “Inside every non-Bayesian there is a Bayesian struggling to get out”; and one of my favorite heuristics around prior probabilities: <a href="https://en.wikipedia.org/wiki/Cromwell%27s_rule" target="_blank">Cromwell’s Rule</a>. Lindley predicted in 1975 that “Bayesian methods will indeed become pervasive, enabled by the development of powerful computing facilities” (Lindley, 1975). You can find more about all of Lindley’s achievements in his <a href="https://www.theguardian.com/science/2014/mar/16/dennis-lindley" target="_blank">obituary</a>.</p><div id=lindleys-paradox><h2><a class="" href="#lindleys-paradox">Lindley’s Paradox</a></h2><p>Lindley’s paradox is a counterintuitive situation in statistics in which the Bayesian and frequentist approaches to a hypothesis testing problem give different results for certain choices of the prior distribution.</p><p>More formally, the paradox is as follows. We have some parameter $\theta$ that we are interested in. Then, we proceed with an experiment to test two competing hypotheses:</p><ol><li>$H_0$ (also known as <em>null hypothesis</em>): there is no “effect”, or, more specifically, $\theta = 0$.</li><li>$H_a$ (also known as <em>alternative hypothesis</em>): there is an “effect”, or, more specifically, $\theta \ne 0$.</li></ol><p>The paradox occurs when two conditions are met:</p><ol><li>The result of the experiment is <em>significant</em> by a frequentist test of $H_0$, which indicates sufficient evidence to reject $H_0$, at a certain threshold of probability.</li><li>The posterior probability (Bayesian approach) of $H_0 \mid \theta$ (null hypothesis given $\theta$) is high, which indicates strong evidence that $H_0$ should be favored over $H_a$, that is, to <em>not</em> reject $H_0$.</li></ol><p>These results can occur at the same time when $H_0$ is very specific, $H_a$ more diffuse, and the prior distribution does not strongly favor one or the other. These conditions are pervasive across science and common in traditional null-hypothesis significance testing approaches.</p><p>This is a duel of frequentist versus Bayesian approaches, and one of the many in which Bayesian emerges as the most coherent. Let’s give a example and go over the analytical result with a ton of math, but also a computational result with <a href="https://julialang.org" target="_blank">Julia</a>.</p></div><div id=example><h2><a class="" href="#example">Example</a></h2><p>Here’s the setup for the example. In a certain city 49,581 boys and 48,870 girls have been born over a certain time period. The observed proportion of male births is thus $\frac{49,581}{98,451} \approx 0.5036$.</p><p>We assume that the birth of a child is independent with a certain probability $\theta$. Since our data is a sequence of $n$ independent <a href="https://en.wikipedia.org/wiki/Bernoulli_trial" target="_blank">Bernoulli trials</a>, i.e., $n$ independent random experiments with exactly two possible outcomes: “success” and “failure”, in which the probability of success is the same every time the experiment is conducted. We can safely assume that it follows a <a href="https://en.wikipedia.org/wiki/Binomial_distribution" target="_blank">binomial distribution</a> with parameters:</p><ul><li>$n$: the number of “trials” (or the total number of births).</li><li>$\theta$: the probability of male births.</li></ul><p>We then set up our two competing hypotheses:</p><ol><li>$H_0$: $\theta = 0.5$.</li><li>$H_a$: $\theta \ne 0.5$.</li></ol></div><div id=analytical-solutions><h3><a class="" href="#analytical-solutions">Analytical Solution</a></h3><p>This is a toy-problem and, like most toy problems, we can solve it analytically for both the frequentist and the Bayesian approaches.</p></div><div id=analytical-solutions-frequentist><h4><a class="" href="#analytical-solutions-frequentist">Analytical Solutions – Frequentist Approach</a></h4><p>The frequentist approach to testing $H_0$ is to compute a $p$-value, the probability of observing births of boys at least as large as 49,581 assuming $H_0$ is true. Because the number of births is very large, we can use a normal approximation for the binomial-distributed number of male births. Let’s define $X$ as the total number of male births, then $X$ follows a normal distribution:</p><p>$$X \sim \text{Normal}(\mu, \sigma)$$</p><p>where $\mu$ is the mean parameter, $n \theta$ in our case, and $\sigma$ is the standard deviation parameter, $\sqrt{n \theta (1 - \theta)}$. We need to calculate the conditional probability of $X \geq \frac{49,581}{98,451} \approx 0.5036$ given $\mu = n \theta = 98,451 \cdot \frac{1}{2} = 49,225.5$ and $\sigma = \sqrt{n \theta (1 - \theta)} = \sqrt{98,451 \cdot \frac{1}{2} \cdot (1 - \frac{1}{2})}$:</p><p>$$P(X \ge 0.5036 \mid \mu = 49,225.5, \sigma = \sqrt{24.612.75})$$</p><p>This is basically a <a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function" target="_blank">cumulative distribution function (CDF)</a> of $X$ on the interval $[49,225.5, 98,451]$:</p><p>$$\int_{49,225.5}^{98,451} \frac{1}{\sqrt{2 \pi \sigma^2}} e^{- \frac{\left( \frac{x - \mu}{\sigma} \right)^2}{2}} dx$$</p><p>After inserting the values and doing some arithmetic, our answer is approximately $0.0117$. Note that this is a one-sided test, since it is symmetrical, the two-sided test would be $0.0117 \cdot 2 = 0.0235$. Since we don’t deviate from the Fisher’s canon, this is well below the 5% threshold. Hooray! We rejected the null hypothesis! Quick! Grab a frequentist celebratory cigar! But, wait. Let’s check the Bayesian approach.</p></div><div id=analytical-solutions-bayesian><h4><a class="" href="#analytical-solutions-bayesian">Analytical Solutions – Bayesian Approach</a></h4><p>For the Bayesian approach, we need to set prior probabilities on both hypotheses. Since we do not favor one from another, let’s set equal prior probabilities:</p><p>$$P(H_0) = P(H_a) = \frac{1}{2}$$</p><p>Additionally, all parameters of interest need a prior distribution. So, let’s put a prior distribution on $\theta$. We could be fancy here, but let’s not. We’ll use a uniform distribution on $[0, 1]$.</p><p>We have everything we need to compute the posterior probability of $H_0$ given $\theta$. For this, we’ll use <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" target="_blank">Bayes theorem</a>:</p><p>$$P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)}$$</p><p>Now again let’s plug in all the values:</p><p>$$P(H_0 \mid \theta) = \frac{P(\theta \mid H_0) P(H_0)}{P(\theta)}$$</p><p>Note that by the <a href="https://en.wikipedia.org/wiki/Probability_axioms" target="_blank">axioms of probability</a> and by the <a href="https://en.wikipedia.org/wiki/Chain_rule_(probability)" target="_blank">product rule of probability</a> we can decompose $P(\theta)$ into:</p><p>$$P(\theta) = P(\theta \mid H_0) P(H_0) + P(\theta \mid H_a) P(H_a)$$</p><p>Again, we’ll use the normal approximation:</p><p>$$ \begin{aligned} &P \left( \theta = 0.5 \mid \mu = 49,225.5, \sigma = \sqrt{24.612.75} \right) \<br>&= \frac{ \frac{1}{\sqrt{2 \pi \sigma^2}} e^{- \left( \frac{(\mu - \mu \cdot 0.5)}{2 \sigma} \right)^2} \cdot 0.5 } { \frac{1}{\sqrt{2 \pi \sigma^2}} e^{ \left( -\frac{(\mu - \mu \cdot 0.5)}{2 \sigma} \right)^2} \cdot 0.5 + \int_0^1 \frac {1}{\sqrt{2 \pi \sigma^2} } e^{- \left( \frac{\mu - \mu \cdot \theta)}{2 \sigma} \right)^2}d \theta \cdot 0.5 } \<br>&= 0.9505 \end{aligned} $$</p><p>The likelihood of the alternative hypothesis, $P(\theta \mid H_a)$, is just the CDF of all possible values of $\theta \ne 0.5$.</p><p>$$P(H_0 \mid \text{data}) = P \left( \theta = 0.5 \mid \mu = 49,225.5, \sigma = \sqrt{24.612.75} \right) > 0.95$$</p><p>And we fail to reject the null hypothesis, in frequentist terms. However, we can also say in Bayesian terms, that we strongly favor $H_0$ over $H_a$.</p><p>Quick! Grab the Bayesian celebratory cigar! The null is back on the game!</p></div><div id=computational-solutions><h3><a class="" href="#computational-solutions">Computational Solutional</a></h3><p>For the computational solution, we’ll use <a href="https://julialang.org" target="_blank">Julia</a> and the following packages:</p><ul><li><a href="https://github.com/JuliaStats/HypothesisTests.jl" target="_blank"><code>HypothesisTest.jl</code></a></li><li><a href="https://turinglang.org/" target="_blank"><code>Turing.jl</code></a></li></ul></div><div id=computational-solutions-frequentist><h4><a class="" href="#computational-solutions-frequentist">Computational Solutions – Frequentist Approach</a></h4><p>We can perform a <a href="https://juliastats.org/HypothesisTests.jl/stable/nonparametric/#Binomial-test" target="_blank"><code>BinomialTest</code></a> with <code>HypothesisTest.jl</code>:</p><pre><code class="python"><span class="variable">julia</span><span class="operator">&gt;</span> <span class="variable">using</span> <span class="variable">HypothesisTests</span>

<span class="variable">julia</span><span class="operator">&gt;</span> <span class="function">BinomialTest</span>(<span class="number">49_225</span>, <span class="number">98_451</span>, <span class="number">0.5036</span>)
<span class="variable">Binomial</span> <span class="variable">test</span>
<span class="operator">-</span><span class="operator">-</span><span class="operator">-</span><span class="operator">-</span><span class="operator">-</span><span class="operator">-</span><span class="operator">-</span><span class="operator">-</span><span class="operator">-</span><span class="operator">-</span><span class="operator">-</span><span class="operator">-</span><span class="operator">-</span>
<span class="variable">Population</span> <span class="variable">details</span>:
    <span class="variable">parameter</span> <span class="variable">of</span> <span class="variable">interest</span>:   <span class="variable">Probability</span> <span class="variable">of</span> <span class="variable">success</span>
    <span class="variable">value</span> <span class="variable">under</span> <span class="variable">h_0</span>:         <span class="number">0.5036</span>
    <span class="variable">point</span> <span class="variable">estimate</span>:          <span class="number">0.499995</span>
    <span class="number">95</span><span class="operator">%</span> <span class="variable">confidence</span> <span class="variable">interval</span>: (<span class="number">0.4969</span>, <span class="number">0.5031</span>)

<span class="variable">Test</span> <span class="variable">summary</span>:
    <span class="type">outcome</span> <span class="keyword">with</span> <span class="number">95</span><span class="operator">%</span> <span class="variable">confidence</span>: <span class="variable">reject</span> <span class="variable">h_0</span>
    <span class="variable">two</span><span class="operator">-</span><span class="variable">sided</span> <span class="variable">p</span><span class="operator">-</span><span class="variable">value</span>:           <span class="number">0.0239</span>

<span class="variable">Details</span>:
    <span class="variable">number</span> <span class="variable">of</span> <span class="type">observations</span>: <span class="number">98451</span>
    <span class="variable">number</span> <span class="variable">of</span> <span class="variable">successes</span>:    <span class="number">49225</span>
</code></pre>
<p>This is the two-sided test, and I had to round $49,225.5$ to $49,225$ since <code>BinomialTest</code> do not support real numbers. But the results match with the analytical solution, we still reject the null.</p></div><div id=computational-solutions-bayesian><h4><a class="" href="#computational-solutions-bayesian">Computational Solutions – Bayesian Approach</a></h4><p>Now, for the Bayesian computational approach, I’m going to use a generative modeling approach, and one of my favorites probabilistic programming languages, <code>Turing.jl</code>:</p><pre><code class="python"><span class="variable">julia</span><span class="operator">&gt;</span> <span class="variable">using</span> <span class="variable">Turing</span>

<span class="variable">julia</span><span class="operator">&gt;</span> @<span class="variable">model</span> <span class="variable">function</span> <span class="function">birth_rate</span>()
           <span class="variable">θ</span> <span class="operator">~</span> <span class="function">Uniform</span>(<span class="number">0</span>, <span class="number">1</span>)
           <span class="variable">total_births</span> <span class="operator">=</span> <span class="number">98_451</span>
           <span class="variable">male_births</span> <span class="operator">~</span> <span class="function">Binomial</span>(<span class="variable">total_births</span>, <span class="variable">θ</span>)
       <span class="variable">end</span>;

<span class="variable">julia</span><span class="operator">&gt;</span> <span class="variable">model</span> <span class="operator">=</span> <span class="function">birth_rate</span>() <span class="operator">|</span> (; <span class="variable">male_births</span> <span class="operator">=</span> <span class="number">49_225</span>);

<span class="variable">julia</span><span class="operator">&gt;</span> <span class="variable">chain</span> <span class="operator">=</span> <span class="function">sample</span>(<span class="variable">model</span>, <span class="function">NUTS</span>(<span class="number">1_000</span>, <span class="number">0.8</span>), <span class="function">MCMCThreads</span>(), <span class="number">1_000</span>, <span class="number">4</span>)
<span class="function">Chains</span> <span class="variable">MCMC</span> <span class="variable">chain</span> (<span class="number">1000</span>×<span class="number">13</span>×<span class="number">4</span> <span class="variable">Array</span>{<span class="variable">Float64</span>, <span class="number">3</span>}):

<span class="variable">Iterations</span>        <span class="operator">=</span> <span class="number">1001</span>:<span class="number">1</span>:<span class="number">2000</span>
<span class="variable">Number</span> <span class="variable">of</span> <span class="variable">chains</span>  <span class="operator">=</span> <span class="number">4</span>
<span class="variable">Samples</span> <span class="variable">per</span> <span class="variable">chain</span> <span class="operator">=</span> <span class="number">1000</span>
<span class="variable">Wall</span> <span class="variable">duration</span>     <span class="operator">=</span> <span class="number">0.2</span> <span class="variable">seconds</span>
<span class="variable">Compute</span> <span class="variable">duration</span>  <span class="operator">=</span> <span class="number">0.19</span> <span class="variable">seconds</span>
<span class="variable">parameters</span>        <span class="operator">=</span> <span class="variable">θ</span>
<span class="variable">internals</span>         <span class="operator">=</span> <span class="variable">lp</span>, <span class="variable">n_steps</span>, <span class="variable">is_accept</span>, <span class="variable">acceptance_rate</span>, <span class="variable">log_density</span>, <span class="variable">hamiltonian_energy</span>, <span class="variable">hamiltonian_energy_error</span>, <span class="variable">max_hamiltonian_energy_error</span>, <span class="variable">tree_depth</span>, <span class="variable">numerical_error</span>, <span class="variable">step_size</span>, <span class="variable">nom_step_size</span>

<span class="variable">Summary</span> <span class="variable">Statistics</span>
  <span class="variable">parameters</span>      <span class="variable">mean</span>       <span class="variable">std</span>      <span class="variable">mcse</span>    <span class="variable">ess_bulk</span>    <span class="variable">ess_tail</span>      <span class="variable">rhat</span>   <span class="variable">ess_per_sec</span>
      <span class="variable">Symbol</span>   <span class="variable">Float64</span>   <span class="variable">Float64</span>   <span class="variable">Float64</span>     <span class="variable">Float64</span>     <span class="variable">Float64</span>   <span class="variable">Float64</span>       <span class="variable">Float64</span>

           <span class="variable">θ</span>    <span class="number">0.4999</span>    <span class="number">0.0016</span>    <span class="number">0.0000</span>   <span class="number">1422.2028</span>   <span class="number">2198.1987</span>    <span class="number">1.0057</span>     <span class="number">7368.9267</span>

<span class="variable">Quantiles</span>
  <span class="variable">parameters</span>      <span class="number">2.5</span><span class="operator">%</span>     <span class="number">25.0</span><span class="operator">%</span>     <span class="number">50.0</span><span class="operator">%</span>     <span class="number">75.0</span><span class="operator">%</span>     <span class="number">97.5</span><span class="operator">%</span>
      <span class="variable">Symbol</span>   <span class="variable">Float64</span>   <span class="variable">Float64</span>   <span class="variable">Float64</span>   <span class="variable">Float64</span>   <span class="variable">Float64</span>

           <span class="variable">θ</span>    <span class="number">0.4969</span>    <span class="number">0.4988</span>    <span class="number">0.4999</span>    <span class="number">0.5011</span>    <span class="number">0.5031</span>
</code></pre>
<p>We can see from the output of the quantiles that the 95% quantile for $\theta$ is the interval $(0.4969, 0.5031)$. Although it overlaps zero, that is not the equivalent of a hypothesis test. For that, we’ll use the <a href="https://en.wikipedia.org/wiki/highest_posterior_density_interval" target="_blank">highest posterior density interval (HPDI)</a>, which is defined as “choosing the narrowest interval” that captures a certain posterior density threshold value. In this case, we’ll use a threshold interval of 95%, i.e. an $\alpha = 0.05$:</p><pre><code class="python"><span class="variable">julia</span><span class="operator">&gt;</span> <span class="function">hpd</span>(<span class="variable">chain</span>; <span class="variable">alpha</span><span class="operator">=</span><span class="number">0.05</span>)
<span class="variable">HPD</span>
  <span class="variable">parameters</span>     <span class="variable">lower</span>     <span class="variable">upper</span>
      <span class="variable">Symbol</span>   <span class="variable">Float64</span>   <span class="variable">Float64</span>

           <span class="variable">θ</span>    <span class="number">0.4970</span>    <span class="number">0.5031</span>
</code></pre>
<p>We see that we fail to reject the null, $\theta = 0.5$ at $\alpha = 0.05$ which is in accordance with the analytical solution.</p></div><div id=why-the-frequentist-and-bayesian-approaches-disagree><h2><a class="" href="#why-the-frequentist-and-bayesian-approaches-disagree">Why the Frequentist and Bayesian Approaches Disagree</a></h2><p>Why do the approaches disagree? What is going on under the hood?</p><p>The answer is disappointing. The main problem is that the frequentist approach only allows fixed significance levels with respect to sample size. Whereas the Bayesian approach is consistent and robust to sample size variations.</p><p>Taken to extreme, in some cases, due to huge sample sizes, the $p$-value is pretty much a <em>proxy</em> for sample size and have little to no utility on hypothesis testing. This is known as $p$-hacking.</p></div><div id=references><h2><a class="" href="#references">References</a></h2><p>Lindley, Dennis V. “The future of statistics: A Bayesian 21st century”. <em>Advances in Applied Probability</em> 7 (1975): 106-115.</p></div></div>
  </div>
  <hr>
  <div id="prev-next">
    <span>
      <a href="/blog/2023-11-20-word_embeddings/">←
        <span>Word Embeddings</span></a>
    </span>
    <span>&nbsp; • &nbsp;</span>
    <span>
      <a href="/blog/2023-11-28-zero_cost_abstractions/"><span>Zero-cost Abstractions</span>
        →</a>
    </span>
    <small>&nbsp; or &nbsp;</small>
    <small>
      <a href="/">Back to the Homepage</a>
    </small>
  </div>

    </div>
    <footer id="footer">
      <small class="noupper" style="color:#606060;font-weight:normal;">
        <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">
          CC-BY-SA 4.0
        </a>
        &nbsp;
        —
        &nbsp;
        <a href="https://github.com/storopoli" target="_blank">
          Jose Storopoli, PhD
        </a>
        &nbsp;
        —
        &nbsp;
        <i>made with &nbsp;
          <a href="https://zine-ssg.io" target="_blank">
            <img src="/zig-logo-light.svg" height="13">
          </a></i>
      </small>
      
    </footer>
  </body>
</html>
